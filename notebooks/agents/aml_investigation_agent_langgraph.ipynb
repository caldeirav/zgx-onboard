{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ” AML Investigation Agent (Qwen3-30B-A3B-Instruct + LangGraph)\n",
        "\n",
        "An autonomous AI Agent for investigating financial transaction graphs to identify money laundering patterns using **Qwen3-30B-A3B-Instruct-2507** (Mixture of Experts) and **LangGraph** stateful orchestration.\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "| Component | Technology | Description |\n",
        "|-----------|------------|-------------|\n",
        "| **Base Model** | Qwen3-30B-A3B-Instruct-2507 | MOE architecture with native tool calling (faster than Thinking) |\n",
        "| **Fine-Tuning** | Unsloth FastModel + LoRA | 4-bit quantization, 2x faster training (MOE optimized) |\n",
        "| **Data Processing** | Polars | High-performance dataframes |\n",
        "| **Graph Analysis** | NetworkX | Transaction network traversal |\n",
        "| **Agent Framework** | LangGraph + MemorySaver | Stateful graph with conditional routing |\n",
        "| **RL Training** | TRL GRPOTrainer | Group Relative Policy Optimization |\n",
        "| **Observability** | MLflow Tracing | Automatic LangGraph trace logging |\n",
        "| **Evaluation** | Gemini LLM-as-Judge | Strategy quality scoring |\n",
        "\n",
        "## LangGraph Agent Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        MemorySaver                              â”‚\n",
        "â”‚              (Persistent State Across Loop)                     â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                 â”‚\n",
        "â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
        "â”‚    â”‚              â”‚      â”‚   Conditional    â”‚                   â”‚\n",
        "â”‚    â”‚  Agent Node  â”‚â”€â”€â”€â”€â”€â–¶â”‚     Edge         â”‚                   â”‚\n",
        "â”‚    â”‚  (Brain)     â”‚      â”‚   (Router)       â”‚                   â”‚\n",
        "â”‚    â”‚              â”‚      â”‚                  â”‚                   â”‚\n",
        "â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
        "â”‚          â–²                        â”‚                             â”‚\n",
        "â”‚          â”‚                        â–¼                             â”‚\n",
        "â”‚          â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
        "â”‚          â”‚         â”‚  continue?  â”‚  report?   â”‚                 â”‚\n",
        "â”‚          â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
        "â”‚          â”‚                â”‚            â”‚                        â”‚\n",
        "â”‚          â”‚                â–¼            â–¼                        â”‚\n",
        "â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
        "â”‚    â”‚            â”‚   â”‚  Tool    â”‚  â”‚  END    â”‚                   â”‚\n",
        "â”‚    â”‚  (loop)    â”‚â—€â”€â”€â”‚  Node    â”‚  â”‚  Node   â”‚                   â”‚\n",
        "â”‚    â”‚            â”‚   â”‚          â”‚  â”‚         â”‚                   â”‚\n",
        "â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "## Investigation Tools\n",
        "\n",
        "| Tool | Description |\n",
        "|------|-------------|\n",
        "| `get_account_summary` | Get account metadata and risk assessment |\n",
        "| `get_recent_transactions` | Get top-5 recent transaction flows |\n",
        "| `check_sanctions_list` | Verify against OFAC watchlist |\n",
        "| `submit_sar` | **Terminal action** - Submit Suspicious Activity Report |\n",
        "\n",
        "## Win Condition\n",
        "`submit_sar` on an entity that is **both sanctioned AND reachable via a laundering path** from the seed account.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# AML INVESTIGATION AGENT (LangGraph) - Setup & Dependencies\n",
        "# ============================================================================\n",
        "\n",
        "# CRITICAL: Import Unsloth FIRST before any other ML libraries\n",
        "# This ensures all optimizations are applied correctly\n",
        "# NOTE: For MOE models (like Qwen3-30B-A3B), use FastModel instead of FastLanguageModel\n",
        "#       See: https://unsloth.ai/docs/models/qwen3-how-to-run-and-fine-tune/qwen3-2507\n",
        "from unsloth import FastModel\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Any, Tuple, Optional, Annotated, Literal, TypedDict, Sequence\n",
        "import operator\n",
        "from pathlib import Path\n",
        "\n",
        "# Numerical & Data Processing\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# ML & Deep Learning (imported AFTER unsloth)\n",
        "import torch\n",
        "\n",
        "# Environment\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Model Configuration\n",
        "# Available Qwen3-2507 models (MOE = Mixture of Experts):\n",
        "#   - \"unsloth/Qwen3-4B-Thinking-2507\"                    # ~3GB VRAM - Dense, small\n",
        "#   - \"unsloth/Qwen3-30B-A3B-Thinking-2507\"               # ~17GB VRAM - MOE (Thinking mode)\n",
        "#   - \"unsloth/Qwen3-30B-A3B-Instruct-2507\"               # ~17GB VRAM - MOE (Instruct mode)\n",
        "#   - \"unsloth/Qwen3-235B-A22B-Thinking-2507\"             # Multi-GPU - MOE (Thinking mode)\n",
        "#   - \"unsloth/Qwen3-235B-A22B-Instruct-2507\"             # Multi-GPU - MOE (Instruct mode)\n",
        "#\n",
        "# IMPORTANT: MOE models require FastModel (not FastLanguageModel)\n",
        "# Thinking models: use temperature=0.6, top_p=0.95\n",
        "# Instruct models: use temperature=0.7, top_p=0.8\n",
        "# IMPORTANT: Use Instruct model for faster inference with tool calling\n",
        "# Thinking models are VERY slow because they generate long reasoning traces\n",
        "# Instruct models are designed for fast, direct responses with tool calling support\n",
        "MODEL_NAME = \"unsloth/Qwen3-30B-A3B-Instruct-2507\"\n",
        "IS_THINKING_MODEL = \"Thinking\" in MODEL_NAME  # Auto-detect thinking vs instruct\n",
        "GEMINI_MODEL = \"gemini-2.0-flash\"    # LLM-as-Judge\n",
        "\n",
        "# Qwen3-2507 Recommended Generation Settings (from Unsloth docs)\n",
        "# https://unsloth.ai/docs/models/qwen3-how-to-run-and-fine-tune/qwen3-2507\n",
        "if IS_THINKING_MODEL:\n",
        "    # Thinking model settings\n",
        "    GENERATION_TEMPERATURE = 0.6\n",
        "    GENERATION_TOP_P = 0.95\n",
        "    GENERATION_TOP_K = 20\n",
        "    GENERATION_MIN_P = 0.0\n",
        "else:\n",
        "    # Instruct model settings\n",
        "    GENERATION_TEMPERATURE = 0.7\n",
        "    GENERATION_TOP_P = 0.8\n",
        "    GENERATION_TOP_K = 20\n",
        "    GENERATION_MIN_P = 0.0\n",
        "\n",
        "# Agent Configuration\n",
        "MAX_STEPS = 50                        # Max steps per investigation\n",
        "MAX_HISTORY_TURNS = 6                 # Conversation history limit\n",
        "\n",
        "# Training Configuration\n",
        "SFT_EPOCHS = 3\n",
        "SFT_LEARNING_RATE = 2e-4\n",
        "GRPO_EPOCHS = 1\n",
        "GRPO_LEARNING_RATE = 5e-6\n",
        "\n",
        "# LoRA Configuration\n",
        "LORA_R = 32                           # Higher rank for complex reasoning\n",
        "LORA_ALPHA = 64\n",
        "LORA_TARGET_MODULES = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "]\n",
        "\n",
        "# Evaluation Configuration\n",
        "EVAL_EPISODES = 10                    # Episodes per evaluation stage\n",
        "\n",
        "# Random Seed\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# Paths (relative to notebook location)\n",
        "NOTEBOOK_DIR = Path(\".\").resolve()\n",
        "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
        "\n",
        "# Ensure directories exist\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dataset Selection\n",
        "DATASET_SIZE = \"Small\"   # Options: \"Small\", \"Medium\", \"Large\"\n",
        "DATASET_PREFIX = \"LI\"    # Options: \"LI\" (Low Illicit), \"HI\" (High Illicit)\n",
        "\n",
        "# ============================================================================\n",
        "# RESULTS STORAGE - For comparison across training stages\n",
        "# ============================================================================\n",
        "\n",
        "evaluation_results = {\n",
        "    \"baseline\": None,\n",
        "    \"post_sft\": None,\n",
        "    \"post_grpo\": None,\n",
        "}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ” AML INVESTIGATION AGENT (LangGraph) - Configuration\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Model:           {MODEL_NAME}\")\n",
        "print(f\"  Judge:           {GEMINI_MODEL}\")\n",
        "print(f\"  Dataset:         {DATASET_PREFIX}-{DATASET_SIZE}\")\n",
        "print(f\"  Max Steps:       {MAX_STEPS}\")\n",
        "print(f\"  Eval Episodes:   {EVAL_EPISODES}\")\n",
        "print(f\"  LoRA Rank:       {LORA_R}\")\n",
        "print(f\"  LoRA Alpha:      {LORA_ALPHA}\")\n",
        "print(f\"  Random Seed:     {RANDOM_SEED}\")\n",
        "print(f\"  Project Root:    {PROJECT_ROOT}\")\n",
        "print(f\"  Data Dir:        {DATA_DIR}\")\n",
        "print(f\"  Models Dir:      {MODELS_DIR}\")\n",
        "print(f\"  GPU Available:   {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU Device:      {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory:      {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print(f\"  Thinking Model:  {IS_THINKING_MODEL}\")\n",
        "print(f\"  Temperature:     {GENERATION_TEMPERATURE}\")\n",
        "print(f\"  Top-P:           {GENERATION_TOP_P}\")\n",
        "print(f\"  Top-K:           {GENERATION_TOP_K}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading with Polars\n",
        "\n",
        "Download the IBM AML dataset from Kaggle (if not already present) and load using Polars for high-performance data manipulation.\n",
        "\n",
        "**Dataset**: [IBM Transactions for Anti Money Laundering (AML)](https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DOWNLOAD DATASET FROM KAGGLE - IBM AML Transactions Dataset\n",
        "# ============================================================================\n",
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Kaggle dataset identifier\n",
        "KAGGLE_DATASET = \"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\"\n",
        "\n",
        "# Check if required files exist\n",
        "trans_file = DATA_DIR / f\"{DATASET_PREFIX}-{DATASET_SIZE}_Trans.csv\"\n",
        "accounts_file = DATA_DIR / f\"{DATASET_PREFIX}-{DATASET_SIZE}_accounts.csv\"\n",
        "patterns_file = DATA_DIR / f\"{DATASET_PREFIX}-{DATASET_SIZE}_Patterns.txt\"\n",
        "\n",
        "files_exist = trans_file.exists() and accounts_file.exists() and patterns_file.exists()\n",
        "\n",
        "if files_exist:\n",
        "    print(f\"âœ“ Dataset already exists at {DATA_DIR}\")\n",
        "    print(f\"  - Transactions: {trans_file.name}\")\n",
        "    print(f\"  - Accounts: {accounts_file.name}\")\n",
        "    print(f\"  - Patterns: {patterns_file.name}\")\n",
        "else:\n",
        "    print(f\"ğŸ“¥ Dataset not found. Downloading from Kaggle...\")\n",
        "    print(f\"   Dataset: {KAGGLE_DATASET}\")\n",
        "    \n",
        "    # Ensure data directory exists\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        # Import and authenticate Kaggle API\n",
        "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "        \n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "        \n",
        "        print(f\"   âœ“ Kaggle API authenticated\")\n",
        "        \n",
        "        # Download dataset\n",
        "        print(f\"   Downloading dataset to {DATA_DIR}...\")\n",
        "        api.dataset_download_files(\n",
        "            dataset=KAGGLE_DATASET,\n",
        "            path=str(DATA_DIR),\n",
        "            unzip=True,\n",
        "            quiet=False\n",
        "        )\n",
        "        \n",
        "        print(f\"   âœ“ Download complete!\")\n",
        "        \n",
        "        # List downloaded files\n",
        "        print(f\"\\n   Downloaded files:\")\n",
        "        for f in sorted(DATA_DIR.glob(\"*\")):\n",
        "            size_mb = f.stat().st_size / (1024 * 1024)\n",
        "            print(f\"     - {f.name} ({size_mb:.1f} MB)\")\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"   âŒ Kaggle package not installed.\")\n",
        "        print(\"   Run: pip install kaggle\")\n",
        "        print(\"   Then set up ~/.kaggle/kaggle.json with your API credentials\")\n",
        "        raise ImportError(\"Please install kaggle package: pip install kaggle\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Error downloading dataset: {e}\")\n",
        "        print(\"\\n   Manual download instructions:\")\n",
        "        print(f\"   1. Visit: https://www.kaggle.com/datasets/{KAGGLE_DATASET}\")\n",
        "        print(f\"   2. Download and extract to: {DATA_DIR}\")\n",
        "        raise\n",
        "\n",
        "# Verify files exist after download\n",
        "assert trans_file.exists(), f\"Transaction file not found: {trans_file}\"\n",
        "assert accounts_file.exists(), f\"Accounts file not found: {accounts_file}\"\n",
        "assert patterns_file.exists(), f\"Patterns file not found: {patterns_file}\"\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"âœ“ DATASET READY: {DATASET_PREFIX}-{DATASET_SIZE}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATA LOADING - IBM AML Dataset with Polars\n",
        "# ============================================================================\n",
        "# FIX: The transactions file has LEADING ZEROS on bank IDs (e.g., \"001120\")\n",
        "# but the accounts file stores them without (e.g., \"1120\"). We normalize by\n",
        "# casting bank IDs to Int64 first, which strips leading zeros.\n",
        "\n",
        "print(\"ğŸ“Š Loading IBM AML Dataset with Polars...\")\n",
        "\n",
        "# Load transactions\n",
        "raw_trans_pl = pl.read_csv(\n",
        "    trans_file,\n",
        "    new_columns=[\n",
        "        'timestamp', 'from_bank', 'from_account', 'to_bank', 'to_account',\n",
        "        'amount_received', 'receiving_currency', 'amount_paid',\n",
        "        'payment_currency', 'payment_format', 'is_laundering'\n",
        "    ],\n",
        "    skip_rows=1\n",
        ")\n",
        "print(f\"âœ“ Loaded {len(raw_trans_pl):,} transactions\")\n",
        "\n",
        "# Load accounts\n",
        "raw_accounts_pl = pl.read_csv(accounts_file)\n",
        "print(f\"âœ“ Loaded {len(raw_accounts_pl):,} accounts\")\n",
        "\n",
        "# Process transactions - Create unique account IDs\n",
        "# CRITICAL FIX: Cast bank IDs to Int64 first to remove leading zeros, then to Utf8\n",
        "transactions_pl = raw_trans_pl.with_columns([\n",
        "    (pl.col('from_bank').cast(pl.Int64).cast(pl.Utf8) + '-' + pl.col('from_account').cast(pl.Utf8)).alias('from_account_id'),\n",
        "    (pl.col('to_bank').cast(pl.Int64).cast(pl.Utf8) + '-' + pl.col('to_account').cast(pl.Utf8)).alias('to_account_id'),\n",
        "    (pl.lit('TXN-') + pl.arange(0, pl.len()).cast(pl.Utf8)).alias('transaction_id'),\n",
        "    pl.col('is_laundering').cast(pl.Int32),\n",
        "]).select([\n",
        "    'transaction_id',\n",
        "    pl.col('from_account_id').alias('from_account'),\n",
        "    pl.col('to_account_id').alias('to_account'),\n",
        "    pl.col('amount_received').alias('amount'),\n",
        "    pl.col('receiving_currency').alias('currency'),\n",
        "    'timestamp', 'is_laundering', 'payment_format',\n",
        "])\n",
        "\n",
        "# Identify laundering destinations for sanctioned marking\n",
        "laundering_dests = set(\n",
        "    transactions_pl.filter(pl.col('is_laundering') == 1)['to_account'].unique().to_list()\n",
        ")\n",
        "print(f\"âœ“ Found {len(laundering_dests):,} laundering destination accounts\")\n",
        "\n",
        "# Process accounts - Add risk scores and sanctioned flags\n",
        "# Bank ID in accounts file is already without leading zeros, so just cast to Utf8\n",
        "accounts_pl = raw_accounts_pl.rename({\n",
        "    'Bank Name': 'bank_name', 'Bank ID': 'bank_id',\n",
        "    'Account Number': 'account_number', 'Entity ID': 'entity_id', 'Entity Name': 'entity_name'\n",
        "}).with_columns([\n",
        "    (pl.col('bank_id').cast(pl.Utf8) + '-' + pl.col('account_number').cast(pl.Utf8)).alias('account_id'),\n",
        "    pl.when(pl.col('entity_name').str.contains('Corporation')).then(pl.lit('Corporate'))\n",
        "        .when(pl.col('entity_name').str.contains('Partnership')).then(pl.lit('Partnership'))\n",
        "        .when(pl.col('entity_name').str.contains('Sole Proprietorship')).then(pl.lit('Individual'))\n",
        "        .otherwise(pl.lit('Unknown')).alias('account_type'),\n",
        "])\n",
        "\n",
        "# Add sanctioned flag (30% of laundering destinations) and risk scores\n",
        "account_ids = accounts_pl['account_id'].to_list()\n",
        "accounts_pl = accounts_pl.with_columns([\n",
        "    pl.Series('is_sanctioned', [acc in laundering_dests and random.random() < 0.3 for acc in account_ids]),\n",
        "    pl.Series('risk_score', [round(random.uniform(0.1, 0.9), 2) for _ in range(len(account_ids))]),\n",
        "]).select(['account_id', 'bank_id', 'bank_name', 'entity_id', 'entity_name', 'account_type', 'risk_score', 'is_sanctioned'])\n",
        "\n",
        "# Convert to pandas for NetworkX\n",
        "transactions_df = transactions_pl.to_pandas()\n",
        "accounts_df = accounts_pl.to_pandas()\n",
        "\n",
        "# Summary\n",
        "n_accounts, n_transactions = len(accounts_df), len(transactions_df)\n",
        "n_laundering = int(transactions_df['is_laundering'].sum())\n",
        "n_sanctioned = int(accounts_df['is_sanctioned'].sum())\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ“Š DATASET SUMMARY: {DATASET_PREFIX}-{DATASET_SIZE}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Accounts:             {n_accounts:>12,}\")\n",
        "print(f\"  Transactions:         {n_transactions:>12,}\")\n",
        "print(f\"  Laundering Txns:      {n_laundering:>12,} ({n_laundering/n_transactions*100:.2f}%)\")\n",
        "print(f\"  Sanctioned Accounts:  {n_sanctioned:>12,}\")\n",
        "print(f\"  Laundering Dests:     {len(laundering_dests):>12,}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PARSE LAUNDERING PATTERNS - Extract Pattern Seeds for Training\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class LaunderingPattern:\n",
        "    \"\"\"Represents a single money laundering pattern from the dataset.\"\"\"\n",
        "    pattern_type: str\n",
        "    pattern_info: str\n",
        "    transactions: List[dict]\n",
        "    accounts_involved: set\n",
        "    \n",
        "    @property\n",
        "    def seed_account(self) -> str:\n",
        "        return self.transactions[0].get('from_account', '') if self.transactions else ''\n",
        "    \n",
        "    @property\n",
        "    def terminal_account(self) -> str:\n",
        "        return self.transactions[-1].get('to_account', '') if self.transactions else ''\n",
        "    \n",
        "    @property\n",
        "    def total_amount(self) -> float:\n",
        "        return sum(t.get('amount', 0) for t in self.transactions)\n",
        "    \n",
        "    @property\n",
        "    def hop_count(self) -> int:\n",
        "        return len(self.transactions)\n",
        "\n",
        "\n",
        "def parse_patterns_file(filepath: Path) -> List[LaunderingPattern]:\n",
        "    \"\"\"Parse patterns file to extract laundering patterns.\"\"\"\n",
        "    patterns = []\n",
        "    current_pattern = None\n",
        "    \n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            if line.startswith('BEGIN LAUNDERING ATTEMPT'):\n",
        "                match = re.match(r'BEGIN LAUNDERING ATTEMPT - (\\w+(?:-\\w+)?):?\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current_pattern = LaunderingPattern(\n",
        "                        pattern_type=match.group(1),\n",
        "                        pattern_info=match.group(2).strip() if match.group(2) else \"\",\n",
        "                        transactions=[], accounts_involved=set()\n",
        "                    )\n",
        "            \n",
        "            elif line.startswith('END LAUNDERING ATTEMPT'):\n",
        "                if current_pattern and current_pattern.transactions:\n",
        "                    patterns.append(current_pattern)\n",
        "                current_pattern = None\n",
        "            \n",
        "            elif current_pattern and line and not line.startswith('BEGIN') and not line.startswith('END'):\n",
        "                parts = line.split(',')\n",
        "                if len(parts) >= 7:\n",
        "                    try:\n",
        "                        # CRITICAL FIX: Normalize bank IDs by converting to int first\n",
        "                        # This removes leading zeros (e.g., \"001120\" -> \"1120\")\n",
        "                        from_bank = str(int(parts[1].strip()))\n",
        "                        to_bank = str(int(parts[3].strip()))\n",
        "                        from_account = f\"{from_bank}-{parts[2].strip()}\"\n",
        "                        to_account = f\"{to_bank}-{parts[4].strip()}\"\n",
        "                        amount = float(parts[5].strip())\n",
        "                        \n",
        "                        current_pattern.transactions.append({\n",
        "                            'timestamp': parts[0].strip(),\n",
        "                            'from_account': from_account, 'to_account': to_account,\n",
        "                            'amount': amount, 'currency': parts[6].strip(),\n",
        "                        })\n",
        "                        current_pattern.accounts_involved.add(from_account)\n",
        "                        current_pattern.accounts_involved.add(to_account)\n",
        "                    except (ValueError, IndexError):\n",
        "                        pass\n",
        "    \n",
        "    return patterns\n",
        "\n",
        "\n",
        "# Parse patterns\n",
        "laundering_patterns = parse_patterns_file(patterns_file)\n",
        "\n",
        "# Statistics\n",
        "pattern_types = {}\n",
        "for p in laundering_patterns:\n",
        "    pattern_types[p.pattern_type] = pattern_types.get(p.pattern_type, 0) + 1\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ”— LAUNDERING PATTERNS PARSED\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Total Patterns: {len(laundering_patterns):,}\")\n",
        "for ptype, count in sorted(pattern_types.items(), key=lambda x: -x[1]):\n",
        "    print(f\"    - {ptype:<20} {count:>6,}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Financial Environment with LangChain Tools\n",
        "\n",
        "Build the transaction graph with NetworkX and create the `FinancialEnvironment` class with LangChain-compatible tool functions for LangGraph integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINANCIAL ENVIRONMENT - NetworkX Graph with LangChain Tools\n",
        "# ============================================================================\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@dataclass \n",
        "class FinancialEnvironment:\n",
        "    \"\"\"Financial investigation environment with path-validated SAR evaluation.\"\"\"\n",
        "    graph: nx.DiGraph = field(default_factory=nx.DiGraph)\n",
        "    accounts: Dict[str, dict] = field(default_factory=dict)\n",
        "    laundering_targets: List[str] = field(default_factory=list)\n",
        "    all_sanctioned: set = field(default_factory=set)\n",
        "    laundering_destinations: set = field(default_factory=set)\n",
        "    transitive_illicit: set = field(default_factory=set)\n",
        "    current_start_account: str = \"\"\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dataframes(cls, transactions_df: pd.DataFrame, accounts_df: pd.DataFrame) -> 'FinancialEnvironment':\n",
        "        env = cls()\n",
        "        \n",
        "        for _, row in accounts_df.iterrows():\n",
        "            env.accounts[row['account_id']] = row.to_dict()\n",
        "            env.graph.add_node(row['account_id'], **row.to_dict())\n",
        "        \n",
        "        for _, row in transactions_df.iterrows():\n",
        "            env.graph.add_edge(\n",
        "                row['from_account'], row['to_account'],\n",
        "                transaction_id=row['transaction_id'], amount=row['amount'],\n",
        "                currency=row.get('currency', 'USD'), timestamp=row['timestamp'],\n",
        "                is_laundering=row['is_laundering']\n",
        "            )\n",
        "        \n",
        "        env.all_sanctioned = set(accounts_df[accounts_df['is_sanctioned']]['account_id'])\n",
        "        laundering_txns = transactions_df[transactions_df['is_laundering'] == 1]\n",
        "        env.laundering_destinations = set(laundering_txns['to_account'].unique())\n",
        "        env._compute_transitive_illicit()\n",
        "        env.laundering_targets = list(env.all_sanctioned & env.laundering_destinations)\n",
        "        \n",
        "        return env\n",
        "    \n",
        "    def _compute_transitive_illicit(self):\n",
        "        self.transitive_illicit = set()\n",
        "        laundering_sources = set()\n",
        "        for u, v, data in self.graph.edges(data=True):\n",
        "            if data.get('is_laundering', 0) == 1:\n",
        "                laundering_sources.add(u)\n",
        "                self.transitive_illicit.add(u)\n",
        "                self.transitive_illicit.add(v)\n",
        "        \n",
        "        for source in laundering_sources:\n",
        "            visited = {source}\n",
        "            queue = [source]\n",
        "            while queue:\n",
        "                node = queue.pop(0)\n",
        "                for neighbor in self.graph.successors(node):\n",
        "                    edge_data = self.graph.edges[node, neighbor]\n",
        "                    if edge_data.get('is_laundering', 0) == 1 and neighbor not in visited:\n",
        "                        visited.add(neighbor)\n",
        "                        self.transitive_illicit.add(neighbor)\n",
        "                        queue.append(neighbor)\n",
        "    \n",
        "    def is_on_laundering_path(self, entity_id: str, max_depth: int = 10) -> bool:\n",
        "        if not self.current_start_account:\n",
        "            return False\n",
        "        try:\n",
        "            for path in nx.all_simple_paths(self.graph, self.current_start_account, entity_id, cutoff=max_depth):\n",
        "                if all(self.graph.edges[path[i], path[i+1]].get('is_laundering', 0) == 1 for i in range(len(path)-1)):\n",
        "                    return True\n",
        "            return False\n",
        "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
        "            return False\n",
        "    \n",
        "    def get_account_summary_impl(self, account_id: str) -> dict:\n",
        "        if account_id not in self.accounts:\n",
        "            return {\"error\": f\"Account {account_id} not found\"}\n",
        "        acc = self.accounts[account_id]\n",
        "        return {\n",
        "            \"account_id\": account_id, \"account_type\": acc.get('account_type', 'Unknown'),\n",
        "            \"entity_name\": acc.get('entity_name', 'Unknown'), \"bank_name\": acc.get('bank_name', 'Unknown'),\n",
        "            \"risk_score\": round(acc.get('risk_score', 0), 2), \"is_sanctioned\": acc.get('is_sanctioned', False),\n",
        "            \"transitive_illicit\": account_id in self.transitive_illicit,\n",
        "        }\n",
        "    \n",
        "    def get_recent_transactions_impl(self, account_id: str, direction: str = \"outgoing\", limit: int = 5) -> List[dict]:\n",
        "        if account_id not in self.graph:\n",
        "            return []\n",
        "        edges = list(self.graph.out_edges(account_id, data=True) if direction == \"outgoing\" \n",
        "                     else self.graph.in_edges(account_id, data=True))\n",
        "        edges = sorted(edges, key=lambda e: e[2].get('amount', 0), reverse=True)[:limit]\n",
        "        \n",
        "        results = []\n",
        "        for edge in edges:\n",
        "            target = edge[1] if direction == \"outgoing\" else edge[0]\n",
        "            results.append({\n",
        "                \"counterparty\": target, \"amount\": round(edge[2].get('amount', 0), 2),\n",
        "                \"currency\": edge[2].get('currency', 'USD'), \"is_laundering\": edge[2].get('is_laundering', 0),\n",
        "                \"high_risk_indicator\": target in self.transitive_illicit,\n",
        "            })\n",
        "        return results\n",
        "    \n",
        "    def check_sanctions_list_impl(self, entity_id: str) -> dict:\n",
        "        is_sanctioned = entity_id in self.all_sanctioned\n",
        "        return {\"entity_id\": entity_id, \"on_sanctions_list\": is_sanctioned, \"list_type\": \"OFAC SDN\" if is_sanctioned else None}\n",
        "    \n",
        "    def submit_sar_impl(self, entity_id: str, reason: str) -> dict:\n",
        "        is_sanctioned = entity_id in self.all_sanctioned\n",
        "        is_primary = entity_id in self.laundering_targets\n",
        "        on_path = self.is_on_laundering_path(entity_id)\n",
        "        correct = is_primary or (is_sanctioned and on_path)\n",
        "        \n",
        "        if is_primary:\n",
        "            eval_reason = \"PRIMARY_TARGET: sanctioned + receives laundering directly\"\n",
        "        elif is_sanctioned and on_path:\n",
        "            eval_reason = f\"VALID: sanctioned + on laundering path from {self.current_start_account}\"\n",
        "        elif is_sanctioned:\n",
        "            eval_reason = \"INVALID: sanctioned but NOT on laundering path from start\"\n",
        "        else:\n",
        "            eval_reason = \"INVALID: entity is not sanctioned\"\n",
        "        \n",
        "        return {\n",
        "            \"entity_id\": entity_id, \"reason\": reason, \"report_id\": f\"SAR-{uuid.uuid4().hex[:8].upper()}\",\n",
        "            \"correct_identification\": correct, \"is_sanctioned\": is_sanctioned,\n",
        "            \"is_primary_target\": is_primary, \"on_laundering_path\": on_path, \"evaluation_reason\": eval_reason,\n",
        "        }\n",
        "    \n",
        "    def reset_investigation(self, start_account: str):\n",
        "        self.current_start_account = start_account\n",
        "\n",
        "\n",
        "# Build environment\n",
        "env = FinancialEnvironment.from_dataframes(transactions_df, accounts_df)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ¦ FINANCIAL ENVIRONMENT BUILT\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Graph Nodes:          {env.graph.number_of_nodes():>12,}\")\n",
        "print(f\"  Graph Edges:          {env.graph.number_of_edges():>12,}\")\n",
        "print(f\"  Sanctioned Accounts:  {len(env.all_sanctioned):>12,}\")\n",
        "print(f\"  Primary Targets:      {len(env.laundering_targets):>12,}\")\n",
        "print(f\"  Transitive Illicit:   {len(env.transitive_illicit):>12,}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LANGCHAIN TOOLS - Define tools for LangGraph agent\n",
        "# ============================================================================\n",
        "\n",
        "@tool\n",
        "def get_account_summary(account_id: str) -> str:\n",
        "    \"\"\"Get account metadata and risk assessment for an account ID.\n",
        "    \n",
        "    Args:\n",
        "        account_id: The unique account identifier (format: 'bankid-accountnumber')\n",
        "    \n",
        "    Returns:\n",
        "        JSON string with account details including risk_score, is_sanctioned, transitive_illicit\n",
        "    \"\"\"\n",
        "    result = env.get_account_summary_impl(account_id)\n",
        "    return json.dumps(result, default=str)\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_recent_transactions(account_id: str, direction: str = \"outgoing\") -> str:\n",
        "    \"\"\"Get the top-5 recent transactions by amount for an account.\n",
        "    \n",
        "    Args:\n",
        "        account_id: The account to get transactions for\n",
        "        direction: Either 'outgoing' or 'incoming' to specify transaction direction\n",
        "    \n",
        "    Returns:\n",
        "        JSON string with list of transactions including counterparty, amount, high_risk_indicator\n",
        "    \"\"\"\n",
        "    result = env.get_recent_transactions_impl(account_id, direction)\n",
        "    return json.dumps(result, default=str)\n",
        "\n",
        "\n",
        "@tool\n",
        "def check_sanctions_list(entity_id: str) -> str:\n",
        "    \"\"\"Check if an entity is on the OFAC sanctions list.\n",
        "    \n",
        "    Args:\n",
        "        entity_id: The account/entity ID to check against sanctions\n",
        "    \n",
        "    Returns:\n",
        "        JSON string with on_sanctions_list boolean and list_type if sanctioned\n",
        "    \"\"\"\n",
        "    result = env.check_sanctions_list_impl(entity_id)\n",
        "    return json.dumps(result, default=str)\n",
        "\n",
        "\n",
        "@tool\n",
        "def submit_sar(entity_id: str, reason: str) -> str:\n",
        "    \"\"\"Submit a Suspicious Activity Report. THIS IS A TERMINAL ACTION.\n",
        "    \n",
        "    Only call this after confirming the entity is on the sanctions list!\n",
        "    \n",
        "    Args:\n",
        "        entity_id: The sanctioned entity to report\n",
        "        reason: Detailed justification for the SAR submission\n",
        "    \n",
        "    Returns:\n",
        "        JSON string with SAR result including correct_identification boolean\n",
        "    \"\"\"\n",
        "    result = env.submit_sar_impl(entity_id, reason)\n",
        "    return json.dumps(result, default=str)\n",
        "\n",
        "\n",
        "# Collect all tools\n",
        "aml_tools = [get_account_summary, get_recent_transactions, check_sanctions_list, submit_sar]\n",
        "tools_by_name = {tool.name: tool for tool in aml_tools}\n",
        "\n",
        "print(\"âœ“ LangChain tools defined for LangGraph agent:\")\n",
        "for t in aml_tools:\n",
        "    print(f\"  - {t.name}: {t.description[:60]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LangGraph Agent Architecture\n",
        "\n",
        "Build the stateful LangGraph agent with:\n",
        "- **State**: TypedDict holding messages and investigation context\n",
        "- **Agent Node**: The \"brain\" that decides the next action\n",
        "- **Tool Node**: Executes the 4 standard investigation tools\n",
        "- **Conditional Edge**: Routes between continuing tool usage or triggering final report\n",
        "- **MemorySaver**: Persistent checkpointing across the investigation loop\n",
        "- **MLflow Tracing**: Automatic trace logging via LangGraph integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LANGGRAPH STATE DEFINITION - Investigation Agent State\n",
        "# ============================================================================\n",
        "\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage, BaseMessage\n",
        "\n",
        "# Extended State with investigation-specific fields\n",
        "# TRAINABLE ARCHITECTURE: State tracks laundering network for model to interpret\n",
        "class InvestigationState(TypedDict):\n",
        "    \"\"\"\n",
        "    The state for the AML investigation agent.\n",
        "    \n",
        "    TRAINABLE DESIGN:\n",
        "    - State tracks raw information (accounts, transactions, sanctions)\n",
        "    - Model must learn to interpret this information\n",
        "    - Model must decide when to submit SAR (not told by system)\n",
        "    \n",
        "    Key fields for laundering path tracking:\n",
        "    - accounts_on_laundering_trail: Set of accounts reachable via is_laundering=1 transactions\n",
        "    - high_risk_counterparties: Set of accounts with high_risk_indicator=True\n",
        "    \"\"\"\n",
        "    messages: Annotated[List[BaseMessage], operator.add]  # Core message history\n",
        "    start_account: str                                     # Investigation seed\n",
        "    accounts_analyzed: Dict[str, dict]                     # Analyzed account data\n",
        "    entities_checked: Dict[str, bool]                      # Sanctions check results\n",
        "    investigation_path: List[str]                          # Linear path of exploration (for logging)\n",
        "    accounts_on_laundering_trail: List[str]               # Accounts reachable via is_laundering=1 (use list for JSON)\n",
        "    high_risk_counterparties: List[str]                   # Accounts with high_risk_indicator=True\n",
        "    total_amount_traced: float                             # Total $ traced\n",
        "    step_count: int                                        # Current step number\n",
        "    terminated: bool                                       # Whether investigation ended\n",
        "    success: bool                                          # Whether SAR was correct\n",
        "    final_result: Optional[dict]                           # Final SAR result\n",
        "\n",
        "\n",
        "def create_initial_state(start_account: str) -> InvestigationState:\n",
        "    \"\"\"Create initial investigation state for a new episode.\"\"\"\n",
        "    return {\n",
        "        \"messages\": [],\n",
        "        \"start_account\": start_account,\n",
        "        \"accounts_analyzed\": {},\n",
        "        \"entities_checked\": {},\n",
        "        \"investigation_path\": [start_account],\n",
        "        \"accounts_on_laundering_trail\": [start_account],  # Seed is always on the trail\n",
        "        \"high_risk_counterparties\": [],\n",
        "        \"total_amount_traced\": 0.0,\n",
        "        \"step_count\": 0,\n",
        "        \"terminated\": False,\n",
        "        \"success\": False,\n",
        "        \"final_result\": None,\n",
        "    }\n",
        "\n",
        "\n",
        "# System prompt for the investigation agent\n",
        "INVESTIGATION_SYSTEM_PROMPT = \"\"\"You are an expert AML (Anti-Money Laundering) investigator. Your task is to investigate financial transaction networks to identify money laundering patterns.\n",
        "\n",
        "## INVESTIGATION STRATEGY\n",
        "1. **START**: Get account summary of the seed account to understand its risk profile\n",
        "2. **EXPLORE**: Get recent transactions to find money flows and counterparties  \n",
        "3. **FOLLOW**: Investigate high-amount and high-risk counterparties\n",
        "4. **VERIFY**: Check sanctions list for suspicious entities BEFORE reporting\n",
        "5. **REPORT**: Submit SAR ONLY after confirming sanctioned status\n",
        "\n",
        "## IMPORTANT RULES\n",
        "- ALWAYS check sanctions list before submitting a SAR\n",
        "- Focus on accounts with high_risk_indicator or transitive_illicit flags\n",
        "- Follow the money trail by examining outgoing transactions\n",
        "- Submit SAR only when you have confirmed evidence of sanctions violations\n",
        "\n",
        "## AVAILABLE TOOLS\n",
        "- get_account_summary: Get account metadata and risk assessment\n",
        "- get_recent_transactions: Get top-5 recent transactions by amount\n",
        "- check_sanctions_list: Verify against OFAC watchlist\n",
        "- submit_sar: Submit Suspicious Activity Report (TERMINAL ACTION)\n",
        "\n",
        "Think step-by-step about your investigation strategy before each action.\"\"\"\n",
        "\n",
        "\n",
        "print(\"âœ“ LangGraph state definition created\")\n",
        "print(f\"  - InvestigationState with {len(InvestigationState.__annotations__)} fields\")\n",
        "print(f\"  - System prompt: {len(INVESTIGATION_SYSTEM_PROMPT)} characters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LOAD MODEL WITH UNSLOTH - Qwen3 MOE with FastModel\n",
        "# ============================================================================\n",
        "# NOTE: For MOE models like Qwen3-30B-A3B, use FastModel (not FastLanguageModel)\n",
        "#       FastModel is imported at the top of the notebook (before transformers)\n",
        "#       to ensure all Unsloth optimizations are applied correctly.\n",
        "#\n",
        "# See: https://unsloth.ai/docs/models/qwen3-how-to-run-and-fine-tune/qwen3-2507\n",
        "\n",
        "print(\"ğŸ“¥ Loading Qwen3 MOE model with Unsloth FastModel...\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Mode:  {'Thinking' if IS_THINKING_MODEL else 'Instruct'}\")\n",
        "\n",
        "# Load model using FastModel (required for MOE architectures)\n",
        "# Settings from Unsloth docs for Qwen3-2507\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name=MODEL_NAME,\n",
        "    max_seq_length=8192,          # Supports up to 256K context, use 8K for memory efficiency\n",
        "    load_in_4bit=True,            # 4-bit quantization to reduce memory\n",
        "    load_in_8bit=False,           # Alternative: slightly more accurate but 2x memory\n",
        "    full_finetuning=False,        # Use LoRA for efficient fine-tuning\n",
        "    device_map=\"cuda:0\",          # Explicit GPU mapping to prevent CPU offload\n",
        "    # token = \"hf_...\",           # Use if accessing gated models\n",
        ")\n",
        "\n",
        "# Enable faster inference mode\n",
        "FastModel.for_inference(model)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ¤– MODEL LOADED (Qwen3-2507 MOE)\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Model:            {MODEL_NAME}\")\n",
        "print(f\"  Architecture:     Mixture of Experts (MOE)\")\n",
        "print(f\"  Mode:             {'Thinking' if IS_THINKING_MODEL else 'Instruct'}\")\n",
        "print(f\"  Max Seq Length:   8,192\")\n",
        "print(f\"  Quantization:     4-bit\")\n",
        "print(f\"  Device:           {next(model.parameters()).device}\")\n",
        "print(f\"  Temperature:      {GENERATION_TEMPERATURE}\")\n",
        "print(f\"  Top-P:            {GENERATION_TOP_P}\")\n",
        "print(f\"  Top-K:            {GENERATION_TOP_K}\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# AGENT NODE - The \"Brain\" that decides the next action\n",
        "# ============================================================================\n",
        "# Uses Qwen3 NATIVE tool calling format for reliable function calling\n",
        "# Reference: https://github.com/QwenLM/Qwen3/blob/main/docs/source/framework/function_call.md\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "# Define tools in Qwen3 native format (OpenAI-compatible JSON Schema)\n",
        "QWEN3_TOOLS = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_account_summary\",\n",
        "            \"description\": \"Get account metadata and risk assessment for an account ID.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"account_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique account identifier (format: 'bankid-accountnumber')\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"account_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_recent_transactions\",\n",
        "            \"description\": \"Get the top-5 recent transactions by amount for an account.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"account_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The account to get transactions for\"\n",
        "                    },\n",
        "                    \"direction\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"outgoing\", \"incoming\"],\n",
        "                        \"description\": \"Transaction direction. Defaults to 'outgoing'\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"account_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"check_sanctions_list\",\n",
        "            \"description\": \"Check if an entity is on the OFAC sanctions list. ALWAYS call this before submitting SAR!\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"entity_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The account/entity ID to check against sanctions\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"entity_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"submit_sar\",\n",
        "            \"description\": \"Submit a Suspicious Activity Report. THIS IS A TERMINAL ACTION. Only call after confirming entity is on sanctions list!\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"entity_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The sanctioned entity to report\"\n",
        "                    },\n",
        "                    \"reason\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Detailed justification for the SAR submission\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"entity_id\", \"reason\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "class Qwen3AgentWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper to make Qwen3 model compatible with LangGraph using NATIVE tool calling.\n",
        "    \n",
        "    This implementation uses Qwen3's built-in function calling format:\n",
        "    - Tools are passed to apply_chat_template\n",
        "    - Model outputs tool calls in a structured format\n",
        "    - Works with both Instruct and Thinking models\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, tokenizer, tools: List, max_new_tokens: int = 256):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.langchain_tools = tools  # Keep for execution\n",
        "        self.tool_names = [t.name for t in tools]\n",
        "        self.max_new_tokens = max_new_tokens\n",
        "        self.qwen3_tools = QWEN3_TOOLS  # Native format for apply_chat_template\n",
        "    \n",
        "    def _build_investigation_context(self, state: dict) -> str:\n",
        "        \"\"\"\n",
        "        Build INFORMATIONAL context for trainable agent.\n",
        "        \n",
        "        TRAINABLE DESIGN: Shows raw state data for model to interpret.\n",
        "        Model must learn to recognize when SAR conditions are met.\n",
        "        \"\"\"\n",
        "        lines = []\n",
        "        \n",
        "        # Basic progress\n",
        "        lines.append(f\"Step: {state.get('step_count', 0)}/{MAX_STEPS}\")\n",
        "        lines.append(f\"Accounts analyzed: {len(state.get('accounts_analyzed', {}))}\")\n",
        "        \n",
        "        # Laundering trail info (critical for decision)\n",
        "        trail = state.get(\"accounts_on_laundering_trail\", [])\n",
        "        if len(trail) > 1:  # More than just seed\n",
        "            lines.append(f\"Accounts on laundering trail: {len(trail)}\")\n",
        "            lines.append(f\"Trail: {' â†’ '.join(trail[-5:])}\")\n",
        "        \n",
        "        # High-risk counterparties (candidates for sanctions check)\n",
        "        high_risk = state.get(\"high_risk_counterparties\", [])\n",
        "        entities_checked = state.get(\"entities_checked\", {})\n",
        "        unchecked_high_risk = [a for a in high_risk if a not in entities_checked]\n",
        "        if unchecked_high_risk:\n",
        "            lines.append(f\"High-risk unchecked: {', '.join(unchecked_high_risk[:3])}\")\n",
        "        \n",
        "        # Sanctions results (critical for SAR decision)\n",
        "        sanctioned = [e for e, s in entities_checked.items() if s]\n",
        "        if sanctioned:\n",
        "            # Show which sanctioned entities are on the laundering trail\n",
        "            on_trail = [e for e in sanctioned if e in trail]\n",
        "            not_on_trail = [e for e in sanctioned if e not in trail]\n",
        "            if on_trail:\n",
        "                lines.append(f\"SANCTIONED ON TRAIL: {', '.join(on_trail)}\")\n",
        "            if not_on_trail:\n",
        "                lines.append(f\"Sanctioned (not on trail): {', '.join(not_on_trail)}\")\n",
        "        \n",
        "        return \" | \".join(lines)\n",
        "    \n",
        "    def _build_messages(self, messages: List[BaseMessage], state: dict) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Build INFORMATIONAL messages for trainable agent.\n",
        "        \n",
        "        TRAINABLE DESIGN:\n",
        "        - System prompt explains GOAL and CRITERIA, not specific actions\n",
        "        - State information is provided, model must interpret\n",
        "        - Model learns to recognize when to submit SAR\n",
        "        - No \"Submit SAR NOW\" directives - model must decide\n",
        "        \"\"\"\n",
        "        formatted = []\n",
        "        start_account = state.get(\"start_account\", \"\")\n",
        "        \n",
        "        # Gather state information for model to interpret\n",
        "        trail = state.get(\"accounts_on_laundering_trail\", [])\n",
        "        high_risk = state.get(\"high_risk_counterparties\", [])\n",
        "        entities_checked = state.get(\"entities_checked\", {})\n",
        "        accounts_analyzed = state.get(\"accounts_analyzed\", {})\n",
        "        \n",
        "        # Key decision data\n",
        "        sanctioned = [e for e, s in entities_checked.items() if s]\n",
        "        sanctioned_on_trail = [e for e in sanctioned if e in trail]\n",
        "        unchecked_on_trail = [a for a in trail if a not in entities_checked and a != start_account]\n",
        "        \n",
        "        # Build context\n",
        "        context = self._build_investigation_context(state)\n",
        "        \n",
        "        # System message - explains GOAL, not specific actions\n",
        "        system_content = f\"\"\"You are an AML investigator finding money laundering.\n",
        "\n",
        "TARGET ACCOUNT: {start_account}\n",
        "\n",
        "GOAL: Submit a Suspicious Activity Report (SAR) for an entity that meets BOTH conditions:\n",
        "1. Entity is on the OFAC sanctions list (check_sanctions_list returns on_sanctions_list=true)\n",
        "2. Entity is reachable via laundering transactions from {start_account} (is_laundering=1 in transactions)\n",
        "\n",
        "HOW TO IDENTIFY LAUNDERING PATHS:\n",
        "- Use get_recent_transactions to find transactions with is_laundering=1\n",
        "- Accounts reached via is_laundering=1 are on the laundering trail\n",
        "- high_risk_indicator=true means the counterparty is connected to laundering network\n",
        "\n",
        "TOOLS:\n",
        "- get_account_summary(account_id): Get risk info, transitive_illicit flag\n",
        "- get_recent_transactions(account_id): Find connected accounts, see is_laundering flag\n",
        "- check_sanctions_list(entity_id): Check if on OFAC list\n",
        "- submit_sar(entity_id, reason): Submit SAR - ONLY for sanctioned entities on laundering trail\n",
        "\n",
        "CURRENT STATE:\n",
        "{context}\n",
        "\n",
        "AVAILABLE ACCOUNTS: {', '.join(list(accounts_analyzed.keys())[:5]) if accounts_analyzed else start_account}\n",
        "LAUNDERING TRAIL: {', '.join(trail[-5:]) if trail else start_account}\"\"\"\n",
        "        \n",
        "        # Add key decision info if available\n",
        "        if sanctioned_on_trail:\n",
        "            system_content += f\"\\n\\nâš ï¸ SANCTIONED ENTITIES ON LAUNDERING TRAIL: {', '.join(sanctioned_on_trail)}\"\n",
        "        elif unchecked_on_trail:\n",
        "            system_content += f\"\\n\\nAccounts on trail not yet checked for sanctions: {', '.join(unchecked_on_trail[:3])}\"\n",
        "        \n",
        "        formatted.append({\"role\": \"system\", \"content\": system_content})\n",
        "        \n",
        "        # User message\n",
        "        if not messages or len([m for m in messages if isinstance(m, ToolMessage)]) == 0:\n",
        "            # First message\n",
        "            formatted.append({\n",
        "                \"role\": \"user\", \n",
        "                \"content\": f\"Investigate account {start_account} for money laundering. Find sanctioned entities on the laundering trail.\"\n",
        "            })\n",
        "        else:\n",
        "            # Add recent tool results for context\n",
        "            tool_results = [(msg.name, msg.content) for msg in messages if isinstance(msg, ToolMessage)]\n",
        "            for name, content in tool_results[-3:]:\n",
        "                formatted.append({\"role\": \"function\", \"name\": name, \"content\": content})\n",
        "            \n",
        "            # Non-directive follow-up - model must decide\n",
        "            formatted.append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Analyze the results. What is your next action? Consider: Are there sanctioned entities on the laundering trail?\"\n",
        "            })\n",
        "        \n",
        "        return formatted\n",
        "    \n",
        "    def invoke(self, messages: List[BaseMessage], state: dict = None) -> AIMessage:\n",
        "        \"\"\"\n",
        "        Invoke Qwen3 model with NATIVE tool calling.\n",
        "        Uses apply_chat_template with tools parameter for proper function calling.\n",
        "        \"\"\"\n",
        "        if state is None:\n",
        "            state = {\"start_account\": \"\"}\n",
        "        \n",
        "        # Build messages\n",
        "        formatted_messages = self._build_messages(messages, state)\n",
        "        \n",
        "        # Apply chat template WITH TOOLS for native function calling\n",
        "        try:\n",
        "            text = self.tokenizer.apply_chat_template(\n",
        "                formatted_messages,\n",
        "                tools=self.qwen3_tools,  # Pass tools for native function calling!\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # Fallback: some tokenizers don't support tools parameter\n",
        "            print(f\"Warning: apply_chat_template with tools failed: {e}\")\n",
        "            text = self.tokenizer.apply_chat_template(\n",
        "                formatted_messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True,\n",
        "            )\n",
        "        \n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            text, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=4096\n",
        "        ).to(self.model.device)\n",
        "        \n",
        "        # Generate with correct parameters for Instruct model\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=self.max_new_tokens,\n",
        "                temperature=GENERATION_TEMPERATURE,\n",
        "                do_sample=True,\n",
        "                top_p=GENERATION_TOP_P,\n",
        "                top_k=GENERATION_TOP_K,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.05,  # Reduce repetition\n",
        "            )\n",
        "        \n",
        "        # Decode response\n",
        "        response = self.tokenizer.decode(\n",
        "            outputs[0][inputs.input_ids.shape[1]:], \n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        \n",
        "        # Extract tool calls from response\n",
        "        tool_calls = self._extract_tool_calls(response)\n",
        "        \n",
        "        if tool_calls:\n",
        "            return AIMessage(content=response, tool_calls=tool_calls)\n",
        "        else:\n",
        "            return AIMessage(content=response)\n",
        "    \n",
        "    def _extract_tool_calls(self, response: str) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Extract tool calls from Qwen3 response.\n",
        "        Qwen3 outputs tool calls in various formats - we try all of them.\n",
        "        \"\"\"\n",
        "        tool_calls = []\n",
        "        \n",
        "        # Clean up response\n",
        "        response = response.strip()\n",
        "        \n",
        "        # Pattern 1: Qwen3 native <tool_call> tags\n",
        "        tool_call_pattern = r'<tool_call>\\s*(\\{.*?\\})\\s*</tool_call>'\n",
        "        matches = re.findall(tool_call_pattern, response, re.DOTALL)\n",
        "        for match in matches:\n",
        "            try:\n",
        "                call_data = json.loads(match)\n",
        "                name = call_data.get(\"name\", \"\")\n",
        "                args = call_data.get(\"arguments\", {})\n",
        "                if isinstance(args, str):\n",
        "                    args = json.loads(args)\n",
        "                if name.lower() in [t.lower() for t in self.tool_names]:\n",
        "                    tool_calls.append({\n",
        "                        \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                        \"name\": name.lower(),\n",
        "                        \"args\": args\n",
        "                    })\n",
        "            except (json.JSONDecodeError, TypeError):\n",
        "                pass\n",
        "        \n",
        "        if tool_calls:\n",
        "            return tool_calls\n",
        "        \n",
        "        # Pattern 2: Raw JSON object with name and arguments\n",
        "        json_pattern = r'\\{[^{}]*\"name\"\\s*:\\s*\"(\\w+)\"[^{}]*\"arguments\"\\s*:\\s*(\\{[^{}]*\\})[^{}]*\\}'\n",
        "        matches = re.findall(json_pattern, response, re.DOTALL)\n",
        "        for name, args_str in matches:\n",
        "            try:\n",
        "                args = json.loads(args_str)\n",
        "                if name.lower() in [t.lower() for t in self.tool_names]:\n",
        "                    tool_calls.append({\n",
        "                        \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                        \"name\": name.lower(),\n",
        "                        \"args\": args\n",
        "                    })\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "        \n",
        "        if tool_calls:\n",
        "            return tool_calls\n",
        "        \n",
        "        # Pattern 3: function_call format {\"name\": ..., \"arguments\": ...}\n",
        "        # Try to find any JSON-like structure\n",
        "        try:\n",
        "            # Look for JSON object anywhere in response\n",
        "            json_start = response.find('{')\n",
        "            if json_start >= 0:\n",
        "                json_end = response.rfind('}') + 1\n",
        "                if json_end > json_start:\n",
        "                    json_str = response[json_start:json_end]\n",
        "                    data = json.loads(json_str)\n",
        "                    if isinstance(data, dict) and 'name' in data:\n",
        "                        name = data['name']\n",
        "                        args = data.get('arguments', data.get('args', {}))\n",
        "                        if isinstance(args, str):\n",
        "                            args = json.loads(args)\n",
        "                        if name.lower() in [t.lower() for t in self.tool_names]:\n",
        "                            tool_calls.append({\n",
        "                                \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                                \"name\": name.lower(),\n",
        "                                \"args\": args\n",
        "                            })\n",
        "        except (json.JSONDecodeError, TypeError):\n",
        "            pass\n",
        "        \n",
        "        if tool_calls:\n",
        "            return tool_calls\n",
        "        \n",
        "        # Pattern 4: Direct function call syntax (tool_name(args))\n",
        "        for tool_name in self.tool_names:\n",
        "            pattern = rf'\\b{tool_name}\\s*\\(\\s*([^)]*)\\s*\\)'\n",
        "            matches = re.findall(pattern, response, re.IGNORECASE)\n",
        "            if matches:\n",
        "                args = self._parse_args(matches[0])\n",
        "                if args:  # Only if we got valid args\n",
        "                    tool_calls.append({\n",
        "                        \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                        \"name\": tool_name.lower(),\n",
        "                        \"args\": args\n",
        "                    })\n",
        "                    return tool_calls\n",
        "        \n",
        "        # Pattern 5: Fallback - look for tool name + account ID in response\n",
        "        # This catches cases where model mentions tool but doesn't format correctly\n",
        "        start_account = None\n",
        "        acc_pattern = r'\\b(\\d{1,3}-\\d+)\\b'\n",
        "        acc_matches = re.findall(acc_pattern, response)\n",
        "        if acc_matches:\n",
        "            start_account = acc_matches[0]\n",
        "        \n",
        "        if start_account:\n",
        "            # Determine which tool based on keywords\n",
        "            response_lower = response.lower()\n",
        "            if 'submit' in response_lower and 'sar' in response_lower:\n",
        "                tool_calls.append({\n",
        "                    \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                    \"name\": \"submit_sar\",\n",
        "                    \"args\": {\"entity_id\": start_account, \"reason\": \"Suspicious activity detected\"}\n",
        "                })\n",
        "            elif 'sanction' in response_lower or 'check' in response_lower:\n",
        "                tool_calls.append({\n",
        "                    \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                    \"name\": \"check_sanctions_list\",\n",
        "                    \"args\": {\"entity_id\": start_account}\n",
        "                })\n",
        "            elif 'transaction' in response_lower:\n",
        "                tool_calls.append({\n",
        "                    \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                    \"name\": \"get_recent_transactions\",\n",
        "                    \"args\": {\"account_id\": start_account}\n",
        "                })\n",
        "            elif 'account' in response_lower or 'summary' in response_lower or 'investigate' in response_lower:\n",
        "                tool_calls.append({\n",
        "                    \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
        "                    \"name\": \"get_account_summary\",\n",
        "                    \"args\": {\"account_id\": start_account}\n",
        "                })\n",
        "        \n",
        "        return tool_calls\n",
        "    \n",
        "    def _parse_args(self, args_str: str) -> dict:\n",
        "        \"\"\"Parse function arguments from string.\"\"\"\n",
        "        args = {}\n",
        "        if not args_str:\n",
        "            return args\n",
        "        \n",
        "        # Try JSON first\n",
        "        try:\n",
        "            return json.loads('{' + args_str + '}')\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Handle key=\"value\" or key='value' patterns\n",
        "        pattern = r'(\\w+)\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']'\n",
        "        for match in re.finditer(pattern, args_str):\n",
        "            args[match.group(1)] = match.group(2)\n",
        "        \n",
        "        return args\n",
        "    \n",
        "\n",
        "\n",
        "# Create the agent wrapper with Qwen3 native tool calling\n",
        "agent_model = Qwen3AgentWrapper(model, tokenizer, aml_tools, max_new_tokens=256)\n",
        "\n",
        "print(\"âœ“ Qwen3 Agent Wrapper created (Native Tool Calling)\")\n",
        "print(f\"  - Model: {MODEL_NAME}\")\n",
        "print(f\"  - Tools: {agent_model.tool_names}\")\n",
        "print(f\"  - Max new tokens: {agent_model.max_new_tokens}\")\n",
        "print(f\"  - Temperature: {GENERATION_TEMPERATURE}\")\n",
        "print(f\"  - Top-P: {GENERATION_TOP_P}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LANGGRAPH COMPONENTS - Agent Node, Tool Node, Conditional Edge\n",
        "# ============================================================================\n",
        "\n",
        "def agent_node(state: InvestigationState) -> dict:\n",
        "    \"\"\"\n",
        "    The Agent Node - the \"brain\" that decides the next action.\n",
        "    \n",
        "    This node:\n",
        "    1. Looks at current state (NOT full message history)\n",
        "    2. Passes structured investigation context to the model\n",
        "    3. Invokes Qwen3 to decide next action\n",
        "    4. Returns updated state with new AI message\n",
        "    \n",
        "    OPTIMIZATIONS:\n",
        "    - Passes full state for building concise context\n",
        "    - State includes: accounts_analyzed, entities_checked, investigation_path\n",
        "    - Model receives structured summary instead of raw message history\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    start_account = state[\"start_account\"]\n",
        "    \n",
        "    # If no messages yet, add initial user message\n",
        "    if not messages:\n",
        "        initial_message = HumanMessage(\n",
        "            content=f\"Begin investigation of account: {start_account}\"\n",
        "        )\n",
        "        messages = [initial_message]\n",
        "    \n",
        "    # Invoke the agent model with FULL STATE (not just start_account)\n",
        "    # This allows the model to see structured investigation context\n",
        "    response = agent_model.invoke(messages, state)\n",
        "    \n",
        "    # Update step count\n",
        "    new_step_count = state.get(\"step_count\", 0) + 1\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [response],\n",
        "        \"step_count\": new_step_count,\n",
        "    }\n",
        "\n",
        "\n",
        "def tool_node(state: InvestigationState) -> dict:\n",
        "    \"\"\"\n",
        "    The Tool Node - executes tool calls from the agent.\n",
        "    \n",
        "    TRAINABLE DESIGN:\n",
        "    - Tracks accounts_on_laundering_trail (via is_laundering=1 transactions)\n",
        "    - Tracks high_risk_counterparties (via high_risk_indicator=True)\n",
        "    - These fields help model learn which accounts are SAR candidates\n",
        "    \n",
        "    ERROR HANDLING:\n",
        "    - Catches exceptions during tool execution\n",
        "    - Validates tool arguments before calling\n",
        "    - Returns informative error messages\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    start_account = state.get(\"start_account\", \"\")\n",
        "    \n",
        "    outputs = []\n",
        "    updated_accounts = dict(state.get(\"accounts_analyzed\", {}))\n",
        "    updated_entities = dict(state.get(\"entities_checked\", {}))\n",
        "    updated_path = list(state.get(\"investigation_path\", []))\n",
        "    # TRAINABLE: Track laundering trail as list (for JSON serialization)\n",
        "    updated_laundering_trail = list(state.get(\"accounts_on_laundering_trail\", [start_account]))\n",
        "    updated_high_risk = list(state.get(\"high_risk_counterparties\", []))\n",
        "    total_amount = state.get(\"total_amount_traced\", 0.0)\n",
        "    \n",
        "    terminated = False\n",
        "    success = False\n",
        "    final_result = None\n",
        "    \n",
        "    # Handle case where there are no tool calls\n",
        "    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:\n",
        "        return {\n",
        "            \"messages\": [ToolMessage(\n",
        "                content=json.dumps({\"error\": \"No tool calls found in message\"}),\n",
        "                name=\"system\",\n",
        "                tool_call_id=\"no_calls\",\n",
        "            )],\n",
        "            \"accounts_analyzed\": updated_accounts,\n",
        "            \"entities_checked\": updated_entities,\n",
        "            \"investigation_path\": updated_path,\n",
        "            \"accounts_on_laundering_trail\": updated_laundering_trail,\n",
        "            \"high_risk_counterparties\": updated_high_risk,\n",
        "            \"total_amount_traced\": total_amount,\n",
        "            \"terminated\": False,\n",
        "            \"success\": False,\n",
        "            \"final_result\": None,\n",
        "        }\n",
        "    \n",
        "    for tool_call in last_message.tool_calls:\n",
        "        tool_name = tool_call.get(\"name\", \"unknown\")\n",
        "        tool_args = tool_call.get(\"args\", {})\n",
        "        tool_id = tool_call.get(\"id\", f\"call_{uuid.uuid4().hex[:8]}\")\n",
        "        \n",
        "        try:\n",
        "            # Normalize tool name (handle case sensitivity)\n",
        "            tool_name_lower = tool_name.lower()\n",
        "            matched_tool = None\n",
        "            for name, tool in tools_by_name.items():\n",
        "                if name.lower() == tool_name_lower:\n",
        "                    matched_tool = tool\n",
        "                    tool_name = name  # Use canonical name\n",
        "                    break\n",
        "            \n",
        "            if matched_tool is None:\n",
        "                tool_result = json.dumps({\n",
        "                    \"error\": f\"Unknown tool: {tool_name}\",\n",
        "                    \"available_tools\": list(tools_by_name.keys())\n",
        "                })\n",
        "            else:\n",
        "                # Validate required arguments\n",
        "                missing_args = []\n",
        "                if tool_name == \"get_account_summary\" and not tool_args.get(\"account_id\"):\n",
        "                    missing_args.append(\"account_id\")\n",
        "                elif tool_name == \"get_recent_transactions\" and not tool_args.get(\"account_id\"):\n",
        "                    missing_args.append(\"account_id\")\n",
        "                elif tool_name == \"check_sanctions_list\" and not tool_args.get(\"entity_id\"):\n",
        "                    missing_args.append(\"entity_id\")\n",
        "                elif tool_name == \"submit_sar\":\n",
        "                    if not tool_args.get(\"entity_id\"):\n",
        "                        missing_args.append(\"entity_id\")\n",
        "                    if not tool_args.get(\"reason\"):\n",
        "                        # Provide default reason if missing\n",
        "                        tool_args[\"reason\"] = \"Suspicious activity detected during investigation\"\n",
        "                \n",
        "                if missing_args:\n",
        "                    tool_result = json.dumps({\n",
        "                        \"error\": f\"Missing required arguments: {missing_args}\",\n",
        "                        \"provided_args\": tool_args,\n",
        "                        \"hint\": f\"Please provide: {', '.join(missing_args)}\"\n",
        "                    })\n",
        "                else:\n",
        "                    # Execute the tool\n",
        "                    tool_result = matched_tool.invoke(tool_args)\n",
        "                    \n",
        "                    # Parse result for state updates\n",
        "                    try:\n",
        "                        result_dict = json.loads(tool_result)\n",
        "                        \n",
        "                        # Update state based on tool type\n",
        "                        if tool_name == \"get_account_summary\":\n",
        "                            acc_id = tool_args.get(\"account_id\", \"\")\n",
        "                            if \"error\" not in result_dict:\n",
        "                                updated_accounts[acc_id] = result_dict\n",
        "                                if acc_id and acc_id not in updated_path:\n",
        "                                    updated_path.append(acc_id)\n",
        "                        \n",
        "                        elif tool_name == \"get_recent_transactions\":\n",
        "                            source_account = tool_args.get(\"account_id\", \"\")\n",
        "                            if isinstance(result_dict, list):\n",
        "                                for txn in result_dict:\n",
        "                                    total_amount += txn.get(\"amount\", 0)\n",
        "                                    counterparty = txn.get(\"counterparty\", \"\")\n",
        "                                    \n",
        "                                    if counterparty:\n",
        "                                        # Track exploration path\n",
        "                                        if counterparty not in updated_path:\n",
        "                                            updated_path.append(counterparty)\n",
        "                                        \n",
        "                                        # TRAINABLE: Track laundering trail\n",
        "                                        # If source is on trail AND this is a laundering txn,\n",
        "                                        # then counterparty is also on the trail\n",
        "                                        if txn.get(\"is_laundering\") == 1:\n",
        "                                            if source_account in updated_laundering_trail or source_account == start_account:\n",
        "                                                if counterparty not in updated_laundering_trail:\n",
        "                                                    updated_laundering_trail.append(counterparty)\n",
        "                                        \n",
        "                                        # TRAINABLE: Track high-risk counterparties\n",
        "                                        if txn.get(\"high_risk_indicator\"):\n",
        "                                            if counterparty not in updated_high_risk:\n",
        "                                                updated_high_risk.append(counterparty)\n",
        "                        \n",
        "                        elif tool_name == \"check_sanctions_list\":\n",
        "                            entity_id = tool_args.get(\"entity_id\", \"\")\n",
        "                            is_sanctioned = result_dict.get(\"on_sanctions_list\", False)\n",
        "                            if entity_id:\n",
        "                                updated_entities[entity_id] = is_sanctioned\n",
        "                        \n",
        "                        elif tool_name == \"submit_sar\":\n",
        "                            terminated = True\n",
        "                            success = result_dict.get(\"correct_identification\", False)\n",
        "                            final_result = result_dict\n",
        "                    \n",
        "                    except json.JSONDecodeError:\n",
        "                        # Tool returned non-JSON, keep as-is\n",
        "                        pass\n",
        "        \n",
        "        except Exception as e:\n",
        "            # Catch any execution errors\n",
        "            tool_result = json.dumps({\n",
        "                \"error\": f\"Tool execution failed: {str(e)}\",\n",
        "                \"tool\": tool_name,\n",
        "                \"args\": tool_args\n",
        "            })\n",
        "        \n",
        "        outputs.append(\n",
        "            ToolMessage(\n",
        "                content=tool_result,\n",
        "                name=tool_name,\n",
        "                tool_call_id=tool_id,\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    return {\n",
        "        \"messages\": outputs,\n",
        "        \"accounts_analyzed\": updated_accounts,\n",
        "        \"entities_checked\": updated_entities,\n",
        "        \"investigation_path\": updated_path,\n",
        "        \"accounts_on_laundering_trail\": updated_laundering_trail,\n",
        "        \"high_risk_counterparties\": updated_high_risk,\n",
        "        \"total_amount_traced\": total_amount,\n",
        "        \"terminated\": terminated,\n",
        "        \"success\": success,\n",
        "        \"final_result\": final_result,\n",
        "    }\n",
        "\n",
        "\n",
        "def should_continue(state: InvestigationState) -> Literal[\"tools\", \"end\"]:\n",
        "    \"\"\"\n",
        "    The Conditional Edge - the router that decides next step.\n",
        "    \n",
        "    This function:\n",
        "    1. Checks if investigation should terminate\n",
        "    2. Checks if there are tool calls to execute\n",
        "    3. Routes to either 'tools' node or 'end'\n",
        "    \"\"\"\n",
        "    # Check termination conditions\n",
        "    if state.get(\"terminated\", False):\n",
        "        return \"end\"\n",
        "    \n",
        "    if state.get(\"step_count\", 0) >= MAX_STEPS:\n",
        "        return \"end\"\n",
        "    \n",
        "    # Check for tool calls in last message\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if messages:\n",
        "        last_message = messages[-1]\n",
        "        if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
        "            return \"tools\"\n",
        "    \n",
        "    return \"end\"\n",
        "\n",
        "\n",
        "print(\"âœ“ LangGraph components defined:\")\n",
        "print(\"  - agent_node: The brain that decides actions\")\n",
        "print(\"  - tool_node: Executes investigation tools\")\n",
        "print(\"  - should_continue: Routes between tools and end\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BUILD LANGGRAPH - Compile the Investigation Agent Graph\n",
        "# ============================================================================\n",
        "\n",
        "import mlflow\n",
        "\n",
        "# Enable MLflow autologging for LangGraph (via LangChain integration)\n",
        "mlflow.langchain.autolog()\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(\"AML_Investigation_Agent_LangGraph\")\n",
        "print(\"âœ“ MLflow experiment: AML_Investigation_Agent_LangGraph\")\n",
        "print(\"âœ“ MLflow autologging enabled for LangGraph\")\n",
        "\n",
        "# Create MemorySaver for persistent checkpointing\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Build the StateGraph\n",
        "builder = StateGraph(InvestigationState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"agent\", agent_node)\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set entry point\n",
        "builder.add_edge(START, \"agent\")\n",
        "\n",
        "# Add conditional edge from agent\n",
        "builder.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"end\": END,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add edge from tools back to agent (the loop)\n",
        "builder.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile the graph with MemorySaver\n",
        "investigation_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"ğŸ”„ LANGGRAPH INVESTIGATION AGENT COMPILED\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(\"  Nodes:\")\n",
        "print(\"    - agent: Qwen3 decision making\")\n",
        "print(\"    - tools: Tool execution\")\n",
        "print(\"  Edges:\")\n",
        "print(\"    - START â†’ agent\")\n",
        "print(\"    - agent â†’ (conditional) â†’ tools | END\")\n",
        "print(\"    - tools â†’ agent (loop)\")\n",
        "print(\"  Checkpointer: MemorySaver (in-memory)\")\n",
        "print(\"  MLflow: Autologging enabled\")\n",
        "print(f\"{'=' * 60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# INVESTIGATION EXECUTION - Run Episodes with LangGraph\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class InvestigationEpisode:\n",
        "    \"\"\"Records an investigation episode for evaluation and training.\"\"\"\n",
        "    start_account: str\n",
        "    steps: List[dict] = field(default_factory=list)\n",
        "    terminated: bool = False\n",
        "    success: bool = False\n",
        "    final_result: dict = field(default_factory=dict)\n",
        "    total_reward: float = 0.0\n",
        "    \n",
        "    def add_step(self, tool_name: str, args: dict, result: Any, reward: float = 0.0):\n",
        "        self.steps.append({\n",
        "            \"step\": len(self.steps) + 1, \n",
        "            \"tool_name\": tool_name, \n",
        "            \"arguments\": args, \n",
        "            \"result\": result, \n",
        "            \"reward\": reward\n",
        "        })\n",
        "        self.total_reward += reward\n",
        "\n",
        "\n",
        "def calculate_reward(tool_name: str, tool_args: dict, result: Any, state: dict) -> float:\n",
        "    \"\"\"\n",
        "    TRAINABLE reward function for GRPO.\n",
        "    \n",
        "    Rewards are designed to shape learning:\n",
        "    - Following laundering path: HIGH reward (core skill to learn)\n",
        "    - Strategic sanctions checks: MEDIUM reward\n",
        "    - Correct SAR: MAJOR reward (goal)\n",
        "    - Wrong SAR: MAJOR penalty (avoid false positives)\n",
        "    - Exploration: Small positive (but less than laundering path)\n",
        "    \"\"\"\n",
        "    reward = -0.05  # Small step penalty (allow exploration)\n",
        "    \n",
        "    # Get state for context-aware rewards\n",
        "    laundering_trail = state.get(\"accounts_on_laundering_trail\", [])\n",
        "    high_risk = state.get(\"high_risk_counterparties\", [])\n",
        "    \n",
        "    if tool_name == \"get_account_summary\":\n",
        "        if isinstance(result, dict):\n",
        "            if result.get(\"transitive_illicit\"):\n",
        "                reward += 0.3  # Found account on laundering network\n",
        "            if result.get(\"is_sanctioned\"):\n",
        "                reward += 0.4  # Found potentially sanctioned (but need trail)\n",
        "    \n",
        "    elif tool_name == \"get_recent_transactions\":\n",
        "        if isinstance(result, list):\n",
        "            laundering_count = 0\n",
        "            high_risk_count = 0\n",
        "            for txn in result:\n",
        "                if txn.get(\"is_laundering\") == 1:\n",
        "                    laundering_count += 1\n",
        "                if txn.get(\"high_risk_indicator\"):\n",
        "                    high_risk_count += 1\n",
        "            \n",
        "            # KEY REWARD: Finding laundering transactions extends the trail\n",
        "            reward += 0.4 * laundering_count  # Strong signal for path discovery\n",
        "            reward += 0.1 * high_risk_count   # Smaller bonus for high-risk\n",
        "    \n",
        "    elif tool_name == \"check_sanctions_list\":\n",
        "        entity_id = tool_args.get(\"entity_id\", \"\")\n",
        "        if isinstance(result, dict) and result.get(\"on_sanctions_list\"):\n",
        "            # Check if entity is on the laundering trail (strategic check)\n",
        "            if entity_id in laundering_trail:\n",
        "                reward += 1.5  # MAJOR: Sanctioned AND on trail = SAR candidate!\n",
        "            else:\n",
        "                reward += 0.3  # Found sanctioned but not yet on trail\n",
        "        elif entity_id in laundering_trail:\n",
        "            reward += 0.1  # Good strategic check even if not sanctioned\n",
        "    \n",
        "    elif tool_name == \"submit_sar\":\n",
        "        if isinstance(result, dict):\n",
        "            if result.get(\"correct_identification\"):\n",
        "                reward += 5.0  # MAJOR SUCCESS - correct SAR\n",
        "            else:\n",
        "                reward -= 3.0  # MAJOR PENALTY - wrong SAR (learn to avoid)\n",
        "    \n",
        "    return reward\n",
        "\n",
        "\n",
        "def run_investigation(\n",
        "    start_account: str,\n",
        "    graph = None,\n",
        "    max_steps: int = MAX_STEPS,\n",
        "    verbose: bool = False,\n",
        "    thread_id: str = None,\n",
        ") -> InvestigationEpisode:\n",
        "    \"\"\"\n",
        "    Run a complete investigation episode using the LangGraph agent.\n",
        "    \n",
        "    Args:\n",
        "        start_account: The seed account to investigate\n",
        "        graph: The compiled LangGraph (defaults to investigation_graph)\n",
        "        max_steps: Maximum investigation steps\n",
        "        verbose: Show detailed step-by-step output (full context, thinking, decisions)\n",
        "        thread_id: Thread ID for MemorySaver (auto-generated if None)\n",
        "    \n",
        "    Returns:\n",
        "        InvestigationEpisode with full investigation record\n",
        "    \"\"\"\n",
        "    if graph is None:\n",
        "        graph = investigation_graph\n",
        "    \n",
        "    if thread_id is None:\n",
        "        thread_id = f\"investigation-{uuid.uuid4().hex[:8]}\"\n",
        "    \n",
        "    # Reset environment for this investigation\n",
        "    env.reset_investigation(start_account)\n",
        "    \n",
        "    # Create initial state\n",
        "    initial_state = create_initial_state(start_account)\n",
        "    \n",
        "    # Add initial user message\n",
        "    initial_state[\"messages\"] = [\n",
        "        HumanMessage(content=f\"Begin investigation of account: {start_account}\")\n",
        "    ]\n",
        "    \n",
        "    # Configure with thread ID for MemorySaver and recursion limit\n",
        "    # Each agentâ†’tools cycle = 2 node invocations, so set limit to 3x MAX_STEPS\n",
        "    config = {\n",
        "        \"configurable\": {\"thread_id\": thread_id},\n",
        "        \"recursion_limit\": MAX_STEPS * 3,\n",
        "    }\n",
        "    \n",
        "    # Create episode recorder\n",
        "    episode = InvestigationEpisode(start_account=start_account)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{'â•' * 80}\")\n",
        "        print(f\"ğŸ” INVESTIGATION START\")\n",
        "        print(f\"{'â•' * 80}\")\n",
        "        print(f\"  Target Account: {start_account}\")\n",
        "        print(f\"  Thread ID:      {thread_id}\")\n",
        "        print(f\"  Max Steps:      {max_steps}\")\n",
        "        print(f\"  Model:          {MODEL_NAME}\")\n",
        "        print(f\"  Temperature:    {GENERATION_TEMPERATURE}\")\n",
        "        print(f\"{'â•' * 80}\")\n",
        "    \n",
        "    try:\n",
        "        # Run the graph\n",
        "        for step_output in graph.stream(initial_state, config, stream_mode=\"values\"):\n",
        "            step_count = step_output.get(\"step_count\", 0)\n",
        "            messages = step_output.get(\"messages\", [])\n",
        "            \n",
        "            if verbose:\n",
        "                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "                # DETAILED STEP LOGGING - Full context, thinking, and decisions\n",
        "                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "                \n",
        "                print(f\"\\n{'â–“' * 80}\")\n",
        "                print(f\"  STEP {step_count}\")\n",
        "                print(f\"{'â–“' * 80}\")\n",
        "                \n",
        "                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                # 1. MEMORY CONTEXT (MemorySaver State)\n",
        "                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                print(f\"\\nâ”Œ{'â”€' * 78}â”\")\n",
        "                print(f\"â”‚ ğŸ“š MEMORY CONTEXT (MemorySaver State)                                        â”‚\")\n",
        "                print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                \n",
        "                # Show all messages in context\n",
        "                msg_count = len(messages)\n",
        "                print(f\"â”‚ Total Messages in Context: {msg_count}\")\n",
        "                print(f\"â”‚\")\n",
        "                \n",
        "                for idx, msg in enumerate(messages):\n",
        "                    msg_type = type(msg).__name__\n",
        "                    if isinstance(msg, HumanMessage):\n",
        "                        print(f\"â”‚ [{idx}] ğŸ‘¤ HumanMessage:\")\n",
        "                        for line in msg.content.split('\\n'):\n",
        "                            print(f\"â”‚     {line}\")\n",
        "                    elif isinstance(msg, SystemMessage):\n",
        "                        print(f\"â”‚ [{idx}] âš™ï¸ SystemMessage:\")\n",
        "                        # Show first 200 chars of system message\n",
        "                        content_preview = msg.content[:200] + \"...\" if len(msg.content) > 200 else msg.content\n",
        "                        for line in content_preview.split('\\n'):\n",
        "                            print(f\"â”‚     {line}\")\n",
        "                    elif isinstance(msg, AIMessage):\n",
        "                        print(f\"â”‚ [{idx}] ğŸ¤– AIMessage:\")\n",
        "                        # Show full AI response\n",
        "                        for line in msg.content.split('\\n'):\n",
        "                            print(f\"â”‚     {line}\")\n",
        "                        if msg.tool_calls:\n",
        "                            print(f\"â”‚     [Tool Calls: {len(msg.tool_calls)}]\")\n",
        "                    elif isinstance(msg, ToolMessage):\n",
        "                        print(f\"â”‚ [{idx}] ğŸ”§ ToolMessage ({msg.name}):\")\n",
        "                        # Show full tool response\n",
        "                        for line in str(msg.content).split('\\n'):\n",
        "                            print(f\"â”‚     {line}\")\n",
        "                    print(f\"â”‚\")\n",
        "                \n",
        "                print(f\"â””{'â”€' * 78}â”˜\")\n",
        "                \n",
        "                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                # 2. LATEST MESSAGE ANALYSIS\n",
        "                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                if messages:\n",
        "                    last_msg = messages[-1]\n",
        "                    \n",
        "                    if isinstance(last_msg, AIMessage):\n",
        "                        print(f\"\\nâ”Œ{'â”€' * 78}â”\")\n",
        "                        print(f\"â”‚ ğŸ§  MODEL THINKING & DECISION                                                 â”‚\")\n",
        "                        print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                        \n",
        "                        # Extract thinking content (between <think> and </think>)\n",
        "                        content = last_msg.content\n",
        "                        thinking_match = re.search(r'<think>(.*?)</think>', content, re.DOTALL)\n",
        "                        \n",
        "                        if thinking_match:\n",
        "                            thinking_content = thinking_match.group(1).strip()\n",
        "                            print(f\"â”‚ ğŸ’­ THINKING PROCESS:\")\n",
        "                            for line in thinking_content.split('\\n'):\n",
        "                                print(f\"â”‚   {line}\")\n",
        "                            print(f\"â”‚\")\n",
        "                            \n",
        "                            # Content after thinking\n",
        "                            after_think = content.split('</think>')[-1].strip() if '</think>' in content else \"\"\n",
        "                            if after_think:\n",
        "                                print(f\"â”‚ ğŸ“ DECISION OUTPUT:\")\n",
        "                                for line in after_think.split('\\n'):\n",
        "                                    print(f\"â”‚   {line}\")\n",
        "                        else:\n",
        "                            # No thinking tags, show full content\n",
        "                            print(f\"â”‚ ğŸ“ FULL RESPONSE (no <think> tags):\")\n",
        "                            for line in content.split('\\n'):\n",
        "                                print(f\"â”‚   {line}\")\n",
        "                        \n",
        "                        print(f\"â”‚\")\n",
        "                        \n",
        "                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                        # 3. ROUTING DECISION\n",
        "                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "                        print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                        print(f\"â”‚ ğŸš¦ ROUTING DECISION                                                          â”‚\")\n",
        "                        print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                        \n",
        "                        if last_msg.tool_calls:\n",
        "                            print(f\"â”‚ Decision: CONTINUE (tool calls detected)\")\n",
        "                            for tc_idx, tc in enumerate(last_msg.tool_calls):\n",
        "                                print(f\"â”‚\")\n",
        "                                print(f\"â”‚ ğŸ”§ TOOL CALL #{tc_idx + 1}:\")\n",
        "                                print(f\"â”‚   Tool ID:   {tc.get('id', 'N/A')}\")\n",
        "                                print(f\"â”‚   Tool Name: {tc['name']}\")\n",
        "                                print(f\"â”‚   Arguments:\")\n",
        "                                args_json = json.dumps(tc['args'], indent=6, default=str)\n",
        "                                for line in args_json.split('\\n'):\n",
        "                                    print(f\"â”‚     {line}\")\n",
        "                                \n",
        "                                # Check if this is the report tool\n",
        "                                if tc['name'] == 'submit_sar':\n",
        "                                    print(f\"â”‚   âš ï¸ REPORT TOOL DETECTED - Investigation will terminate after this\")\n",
        "                        else:\n",
        "                            print(f\"â”‚ Decision: END (no tool calls)\")\n",
        "                            print(f\"â”‚ Agent has finished reasoning without requesting more tools.\")\n",
        "                        \n",
        "                        print(f\"â””{'â”€' * 78}â”˜\")\n",
        "                    \n",
        "                    elif isinstance(last_msg, ToolMessage):\n",
        "                        print(f\"\\nâ”Œ{'â”€' * 78}â”\")\n",
        "                        print(f\"â”‚ ğŸ“Š TOOL EXECUTION RESULT                                                     â”‚\")\n",
        "                        print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                        print(f\"â”‚ Tool Name: {last_msg.name}\")\n",
        "                        print(f\"â”‚ Tool ID:   {getattr(last_msg, 'tool_call_id', 'N/A')}\")\n",
        "                        print(f\"â”‚\")\n",
        "                        print(f\"â”‚ ğŸ“„ FULL TOOL RESPONSE:\")\n",
        "                        \n",
        "                        # Parse and pretty-print the result\n",
        "                        try:\n",
        "                            result = json.loads(last_msg.content) if last_msg.content else {}\n",
        "                            result_json = json.dumps(result, indent=4, default=str)\n",
        "                            for line in result_json.split('\\n'):\n",
        "                                print(f\"â”‚   {line}\")\n",
        "                        except:\n",
        "                            for line in str(last_msg.content).split('\\n'):\n",
        "                                print(f\"â”‚   {line}\")\n",
        "                        \n",
        "                        # Calculate and show reward\n",
        "                        try:\n",
        "                            result = json.loads(last_msg.content) if last_msg.content else {}\n",
        "                            # Get tool_args from previous AI message tool calls\n",
        "                            tool_args = {}\n",
        "                            for prev_msg in step_output.get(\"messages\", []):\n",
        "                                if hasattr(prev_msg, 'tool_calls') and prev_msg.tool_calls:\n",
        "                                    for tc in prev_msg.tool_calls:\n",
        "                                        if tc.get(\"name\") == last_msg.name:\n",
        "                                            tool_args = tc.get(\"args\", {})\n",
        "                                            break\n",
        "                            reward = calculate_reward(last_msg.name, tool_args, result, step_output)\n",
        "                            episode.add_step(last_msg.name, tool_args, result, reward)\n",
        "                            \n",
        "                            print(f\"â”‚\")\n",
        "                            print(f\"â”œ{'â”€' * 78}â”¤\")\n",
        "                            reward_icon = \"ğŸŸ¢\" if reward > 0 else (\"ğŸ”´\" if reward < 0 else \"âšª\")\n",
        "                            print(f\"â”‚ ğŸ’° REWARD CALCULATION: {reward_icon} {reward:+.2f}\")\n",
        "                            print(f\"â”‚   Running Total: {episode.total_reward:+.2f}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"â”‚ âš ï¸ Error calculating reward: {e}\")\n",
        "                        \n",
        "                        print(f\"â””{'â”€' * 78}â”˜\")\n",
        "            \n",
        "            else:\n",
        "                # Non-verbose mode: still record steps\n",
        "                if messages:\n",
        "                    last_msg = messages[-1]\n",
        "                    if isinstance(last_msg, ToolMessage):\n",
        "                        try:\n",
        "                            result = json.loads(last_msg.content) if last_msg.content else {}\n",
        "                            # Get tool_args from previous AI message tool calls\n",
        "                            tool_args = {}\n",
        "                            for prev_msg in step_output.get(\"messages\", []):\n",
        "                                if hasattr(prev_msg, 'tool_calls') and prev_msg.tool_calls:\n",
        "                                    for tc in prev_msg.tool_calls:\n",
        "                                        if tc.get(\"name\") == last_msg.name:\n",
        "                                            tool_args = tc.get(\"args\", {})\n",
        "                                            break\n",
        "                            reward = calculate_reward(last_msg.name, tool_args, result, step_output)\n",
        "                            episode.add_step(last_msg.name, tool_args, result, reward)\n",
        "                        except:\n",
        "                            pass\n",
        "            \n",
        "            # Check for termination\n",
        "            if step_output.get(\"terminated\", False):\n",
        "                episode.terminated = True\n",
        "                episode.success = step_output.get(\"success\", False)\n",
        "                episode.final_result = step_output.get(\"final_result\", {})\n",
        "                break\n",
        "            \n",
        "            if step_count >= max_steps:\n",
        "                episode.terminated = True\n",
        "                break\n",
        "    \n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"\\n{'!' * 80}\")\n",
        "            print(f\"âŒ ERROR DURING INVESTIGATION\")\n",
        "            print(f\"{'!' * 80}\")\n",
        "            print(f\"  Exception Type: {type(e).__name__}\")\n",
        "            print(f\"  Exception Message: {e}\")\n",
        "            import traceback\n",
        "            print(f\"  Traceback:\")\n",
        "            for line in traceback.format_exc().split('\\n'):\n",
        "                print(f\"    {line}\")\n",
        "            print(f\"{'!' * 80}\")\n",
        "        episode.terminated = True\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{'â•' * 80}\")\n",
        "        print(f\"ğŸ“‹ INVESTIGATION COMPLETE\")\n",
        "        print(f\"{'â•' * 80}\")\n",
        "        print(f\"  Result:       {'âœ… SUCCESS' if episode.success else 'âŒ FAILED'}\")\n",
        "        print(f\"  Total Steps:  {len(episode.steps)}\")\n",
        "        print(f\"  Total Reward: {episode.total_reward:+.2f}\")\n",
        "        if episode.final_result:\n",
        "            print(f\"  SAR Filed:    {'Yes' if episode.final_result.get('filed') else 'No'}\")\n",
        "            print(f\"  SAR Reason:   {episode.final_result.get('evaluation_reason', 'N/A')}\")\n",
        "        print(f\"{'â•' * 80}\")\n",
        "        \n",
        "        # Summary of all steps\n",
        "        print(f\"\\nğŸ“Š STEP SUMMARY:\")\n",
        "        for i, step in enumerate(episode.steps):\n",
        "            reward_icon = \"ğŸŸ¢\" if step['reward'] > 0 else (\"ğŸ”´\" if step['reward'] < 0 else \"âšª\")\n",
        "            print(f\"  {i+1}. {step['tool_name']}: {reward_icon} {step['reward']:+.2f}\")\n",
        "    \n",
        "    return episode\n",
        "\n",
        "\n",
        "print(\"âœ“ Investigation execution function defined\")\n",
        "print(\"  - run_investigation: Execute full investigation episode with detailed logging\")\n",
        "print(\"  - calculate_reward: GRPO reward calculation\")\n",
        "print(\"  - Verbose mode shows: Memory context, Model thinking, Routing decisions, Tool results\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. LLM-as-Judge Evaluation with Gemini\n",
        "\n",
        "Evaluate agent performance using Gemini as an LLM judge with integrated MLflow tracing.\n",
        "\n",
        "**Rubric:**\n",
        "1. **Strategy Quality** (0-10): Did the agent prioritize high-value/high-risk transfers?\n",
        "2. **Decision Persistence** (0-10): Did it pivot correctly after hitting dead ends?\n",
        "3. **Outcome** (0-10): Did the agent correctly identify a sanctioned entity?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LLM-AS-JUDGE EVALUATION - Gemini-based Scoring\n",
        "# ============================================================================\n",
        "\n",
        "from google import genai\n",
        "\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "if GEMINI_API_KEY:\n",
        "    gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    print(\"âœ“ Gemini API configured (google.genai)\")\n",
        "else:\n",
        "    gemini_client = None\n",
        "    print(\"âš ï¸ GEMINI_API_KEY not set - LLM-as-Judge will be disabled\")\n",
        "\n",
        "\n",
        "JUDGE_PROMPT = \"\"\"You are an expert evaluator of AML investigations.\n",
        "\n",
        "## Investigation Trace\n",
        "{trace}\n",
        "\n",
        "## Evaluation Rubric\n",
        "1. **Strategy Quality** (0-10): Did the agent prioritize high-value and high-risk transfers?\n",
        "2. **Decision Persistence** (0-10): Did the agent correctly pivot after hitting dead ends?\n",
        "3. **Outcome Quality** (0-10): Did the agent correctly identify a sanctioned entity?\n",
        "\n",
        "## Response Format\n",
        "Provide your evaluation as JSON:\n",
        "{{\"strategy_score\": <0-10>, \"persistence_score\": <0-10>, \"outcome_score\": <0-10>, \"overall_score\": <0-10>, \"reasoning\": \"<brief explanation>\"}}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@mlflow.trace(span_type=\"LLM_JUDGE\")\n",
        "def evaluate_episode_with_llm(episode: InvestigationEpisode) -> dict:\n",
        "    \"\"\"Evaluate an investigation episode using Gemini as LLM judge.\"\"\"\n",
        "    default_scores = {\n",
        "        \"strategy_score\": 0, \n",
        "        \"persistence_score\": 0, \n",
        "        \"outcome_score\": 10 if episode.success else 0,\n",
        "        \"overall_score\": 5 if episode.success else 0, \n",
        "        \"reasoning\": \"Default score\"\n",
        "    }\n",
        "    \n",
        "    if not gemini_client:\n",
        "        default_scores[\"reasoning\"] = \"LLM evaluation disabled (no API key)\"\n",
        "        return default_scores\n",
        "    \n",
        "    # Build investigation trace\n",
        "    trace_lines = [f\"Start Account: {episode.start_account}\", \"\"]\n",
        "    for step in episode.steps:\n",
        "        tool_name = step.get('tool_name', 'unknown')\n",
        "        trace_lines.append(f\"Step {step['step']}: {tool_name}\")\n",
        "        trace_lines.append(f\"  Args: {json.dumps(step.get('arguments', {}), default=str)[:80]}\")\n",
        "        \n",
        "        result = step.get('result', {})\n",
        "        if tool_name == \"get_account_summary\" and isinstance(result, dict):\n",
        "            trace_lines.append(f\"  Result: Type={result.get('account_type', 'Unknown')}, Risk={result.get('risk_score', 0):.2f}, Illicit={result.get('transitive_illicit', False)}\")\n",
        "        elif tool_name == \"get_recent_transactions\" and isinstance(result, list):\n",
        "            trace_lines.append(f\"  Result: {len(result)} transactions (high_risk: {sum(1 for t in result if t.get('high_risk_indicator'))})\")\n",
        "        elif tool_name == \"check_sanctions_list\" and isinstance(result, dict):\n",
        "            trace_lines.append(f\"  Result: Sanctioned={result.get('on_sanctions_list', False)}\")\n",
        "        elif tool_name == \"submit_sar\" and isinstance(result, dict):\n",
        "            trace_lines.append(f\"  Result: Correct={result.get('correct_identification', False)}, Reason={result.get('evaluation_reason', 'N/A')[:50]}\")\n",
        "        else:\n",
        "            trace_lines.append(f\"  Result: {json.dumps(result, default=str)[:100]}\")\n",
        "        trace_lines.append(f\"  Reward: {step.get('reward', 0):+.2f}\")\n",
        "    \n",
        "    trace_lines.append(f\"\\nFinal: {'SUCCESS' if episode.success else 'FAILED'} | Steps: {len(episode.steps)} | Total Reward: {episode.total_reward:+.2f}\")\n",
        "    \n",
        "    trace_text = \"\\n\".join(trace_lines)\n",
        "    \n",
        "    try:\n",
        "        response = gemini_client.models.generate_content(\n",
        "            model=GEMINI_MODEL, \n",
        "            contents=JUDGE_PROMPT.format(trace=trace_text)\n",
        "        )\n",
        "        \n",
        "        # Extract JSON from response\n",
        "        json_match = re.search(r'\\{[^{}]*\\}', response.text, re.DOTALL)\n",
        "        if json_match:\n",
        "            scores = json.loads(json_match.group())\n",
        "            for key in [\"strategy_score\", \"persistence_score\", \"outcome_score\", \"overall_score\"]:\n",
        "                if key not in scores:\n",
        "                    scores[key] = 0\n",
        "            if \"reasoning\" not in scores:\n",
        "                scores[\"reasoning\"] = \"No reasoning provided\"\n",
        "            return scores\n",
        "        else:\n",
        "            default_scores[\"reasoning\"] = f\"Failed to parse JSON from: {response.text[:100]}\"\n",
        "            return default_scores\n",
        "            \n",
        "    except Exception as e:\n",
        "        default_scores[\"reasoning\"] = f\"API error: {str(e)[:50]}\"\n",
        "        return default_scores\n",
        "\n",
        "\n",
        "print(\"âœ“ LLM-as-Judge evaluation configured\")\n",
        "print(f\"  - Model: {GEMINI_MODEL}\")\n",
        "print(f\"  - Status: {'Enabled' if gemini_client else 'Disabled'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EVALUATION FUNCTION - Run Multiple Episodes\n",
        "# ============================================================================\n",
        "\n",
        "def run_evaluation(\n",
        "    graph,\n",
        "    stage_name: str, \n",
        "    n_episodes: int = EVAL_EPISODES, \n",
        "    use_llm_judge: bool = True, \n",
        "    verbose: bool = True,\n",
        "    show_episode_details: bool = True,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Run evaluation episodes and collect metrics.\n",
        "    \n",
        "    Args:\n",
        "        graph: The compiled LangGraph to evaluate\n",
        "        stage_name: Name of this evaluation stage (e.g., \"Baseline\", \"Post-SFT\")\n",
        "        n_episodes: Number of episodes to run\n",
        "        use_llm_judge: Whether to use Gemini for evaluation\n",
        "        verbose: Show progress and summaries\n",
        "        show_episode_details: Show step-by-step for each episode\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with evaluation results\n",
        "    \"\"\"\n",
        "    # Use pattern seed accounts for guaranteed laundering paths\n",
        "    eval_seeds = [\n",
        "        p.seed_account for p in random.sample(\n",
        "            laundering_patterns, \n",
        "            min(n_episodes, len(laundering_patterns))\n",
        "        ) if p.seed_account\n",
        "    ]\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    print(f\"\\n{'â•' * 70}\")\n",
        "    print(f\"ğŸ§ª EVALUATION: {stage_name.upper()}\")\n",
        "    print(f\"{'â•' * 70}\")\n",
        "    print(f\"  Episodes: {n_episodes}\")\n",
        "    print(f\"  Max Steps: {MAX_STEPS}\")\n",
        "    print(f\"  LLM Judge: {'Enabled' if use_llm_judge and gemini_client else 'Disabled'}\")\n",
        "    print(f\"{'â•' * 70}\")\n",
        "    \n",
        "    with mlflow.start_run(run_name=f\"eval_{stage_name}\"):\n",
        "        for i, seed in enumerate(eval_seeds[:n_episodes]):\n",
        "            print(f\"\\n{'â–“' * 70}\")\n",
        "            print(f\"  EPISODE {i+1}/{n_episodes}\")\n",
        "            print(f\"  Seed: {seed}\")\n",
        "            print(f\"{'â–“' * 70}\")\n",
        "            \n",
        "            # Run investigation\n",
        "            episode = run_investigation(\n",
        "                seed, \n",
        "                graph=graph,\n",
        "                verbose=show_episode_details,\n",
        "            )\n",
        "            \n",
        "            # LLM Judge evaluation\n",
        "            if use_llm_judge and gemini_client:\n",
        "                print(f\"\\n  ğŸ¤– LLM-AS-JUDGE EVALUATION...\")\n",
        "                llm_scores = evaluate_episode_with_llm(episode)\n",
        "                print(f\"     Strategy:    {llm_scores.get('strategy_score', 0)}/10\")\n",
        "                print(f\"     Persistence: {llm_scores.get('persistence_score', 0)}/10\")\n",
        "                print(f\"     Outcome:     {llm_scores.get('outcome_score', 0)}/10\")\n",
        "                print(f\"     Overall:     {llm_scores.get('overall_score', 0)}/10\")\n",
        "                if llm_scores.get('reasoning'):\n",
        "                    print(f\"     Reasoning:   {llm_scores.get('reasoning', '')[:60]}...\")\n",
        "            else:\n",
        "                llm_scores = {\n",
        "                    \"strategy_score\": 0, \n",
        "                    \"persistence_score\": 0, \n",
        "                    \"outcome_score\": 10 if episode.success else 0, \n",
        "                    \"overall_score\": 5 if episode.success else 0,\n",
        "                    \"reasoning\": \"LLM judge disabled\"\n",
        "                }\n",
        "            \n",
        "            result = {\n",
        "                \"seed_account\": seed, \n",
        "                \"success\": episode.success, \n",
        "                \"steps\": len(episode.steps),\n",
        "                \"total_reward\": episode.total_reward, \n",
        "                **llm_scores\n",
        "            }\n",
        "            results.append(result)\n",
        "            \n",
        "            # Episode summary\n",
        "            print(f\"\\n  â”Œâ”€ EPISODE {i+1} RESULT {'â”€' * 44}â”\")\n",
        "            print(f\"  â”‚ Outcome:      {'âœ… SUCCESS' if episode.success else 'âŒ FAILED':<20} â”‚\")\n",
        "            print(f\"  â”‚ Steps:        {len(episode.steps):<20} â”‚\")\n",
        "            print(f\"  â”‚ Total Reward: {episode.total_reward:+.2f}{' ' * 17} â”‚\")\n",
        "            print(f\"  â”‚ LLM Score:    {llm_scores.get('overall_score', 0)}/10{' ' * 16} â”‚\")\n",
        "            print(f\"  â””{'â”€' * 53}â”˜\")\n",
        "        \n",
        "        df = pd.DataFrame(results)\n",
        "        \n",
        "        # Log to MLflow\n",
        "        mlflow.log_metrics({\n",
        "            f\"{stage_name}_success_rate\": df['success'].mean(),\n",
        "            f\"{stage_name}_avg_steps\": df['steps'].mean(),\n",
        "            f\"{stage_name}_avg_reward\": df['total_reward'].mean(),\n",
        "            f\"{stage_name}_avg_score\": df['overall_score'].mean(),\n",
        "        })\n",
        "    \n",
        "    # Final Summary\n",
        "    print(f\"\\n{'â•' * 70}\")\n",
        "    print(f\"ğŸ“Š {stage_name.upper()} - FINAL SUMMARY\")\n",
        "    print(f\"{'â•' * 70}\")\n",
        "    print(f\"  Episodes Run:     {len(results)}\")\n",
        "    print(f\"  Success Rate:     {df['success'].mean()*100:.1f}% ({df['success'].sum()}/{len(results)})\")\n",
        "    print(f\"  Avg Steps:        {df['steps'].mean():.1f}\")\n",
        "    print(f\"  Avg Reward:       {df['total_reward'].mean():+.2f}\")\n",
        "    print(f\"  Avg LLM Score:    {df['overall_score'].mean():.1f}/10\")\n",
        "    print(f\"{'â”€' * 70}\")\n",
        "    print(f\"  Score Breakdown:\")\n",
        "    print(f\"    Strategy:       {df['strategy_score'].mean():.1f}/10\")\n",
        "    print(f\"    Persistence:    {df['persistence_score'].mean():.1f}/10\")\n",
        "    print(f\"    Outcome:        {df['outcome_score'].mean():.1f}/10\")\n",
        "    print(f\"{'â•' * 70}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "print(\"âœ“ Evaluation framework configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. STAGE 1: Baseline Evaluation (Pre-Training)\n",
        "\n",
        "Run evaluation on the **base Qwen3 model** before any fine-tuning to establish baseline performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STAGE 1: BASELINE EVALUATION - Pre-Training Performance\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ” STAGE 1: BASELINE EVALUATION\")\n",
        "print(\"   Testing base Qwen3 model (no fine-tuning)\")\n",
        "\n",
        "# Initialize results dictionary for all stages\n",
        "all_results = {}\n",
        "\n",
        "# Ensure model is in inference mode\n",
        "FastModel.for_inference(model)\n",
        "\n",
        "# Run baseline evaluation\n",
        "baseline_results = run_evaluation(\n",
        "    graph=investigation_graph,\n",
        "    stage_name=\"Baseline\",\n",
        "    n_episodes=EVAL_EPISODES,\n",
        "    use_llm_judge=bool(gemini_client),\n",
        "    verbose=True,\n",
        "    show_episode_details=True,\n",
        ")\n",
        "\n",
        "# Store results for comparison\n",
        "all_results[\"Baseline\"] = baseline_results\n",
        "\n",
        "print(\"\\nğŸ“Š Baseline Results Summary:\")\n",
        "print(baseline_results[['success', 'steps', 'total_reward', 'overall_score']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. SFT Training Data Generation\n",
        "\n",
        "Generate Supervised Fine-Tuning samples from laundering patterns with structured tool-calling format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SFT TRAINING DATA GENERATION - Multi-turn Conversations\n",
        "# ============================================================================\n",
        "\n",
        "def generate_sft_sample(pattern: LaunderingPattern) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Generate a multi-turn SFT training sample with REASONING demonstrations.\n",
        "    \n",
        "    TRAINABLE DESIGN:\n",
        "    - Shows explicit reasoning about laundering path tracking\n",
        "    - Demonstrates recognition of SAR conditions (sanctioned + on trail)\n",
        "    - Teaches model to make decisions, not just follow instructions\n",
        "    \"\"\"\n",
        "    messages = []\n",
        "    seed_account = pattern.seed_account\n",
        "    terminal_account = pattern.terminal_account\n",
        "    \n",
        "    if not seed_account or not terminal_account:\n",
        "        return []\n",
        "    \n",
        "    # Get intermediate accounts from pattern\n",
        "    intermediate_accounts = list(pattern.accounts_involved - {seed_account, terminal_account})[:2]\n",
        "    \n",
        "    # System message\n",
        "    messages.append({\n",
        "        \"role\": \"system\", \n",
        "        \"content\": INVESTIGATION_SYSTEM_PROMPT + f\"\\n\\nINVESTIGATION TARGET: {seed_account}\"\n",
        "    })\n",
        "    \n",
        "    # User starts investigation\n",
        "    messages.append({\n",
        "        \"role\": \"user\", \n",
        "        \"content\": f\"Investigate account {seed_account} for money laundering. Find sanctioned entities on the laundering trail.\"\n",
        "    })\n",
        "    \n",
        "    # Step 1: Get account summary\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\", \n",
        "        \"content\": f\"\"\"I need to check the seed account's risk profile first.\n",
        "\n",
        "<tool_call>\n",
        "{{\"name\": \"get_account_summary\", \"arguments\": {{\"account_id\": \"{seed_account}\"}}}}\n",
        "</tool_call>\"\"\"\n",
        "    })\n",
        "    \n",
        "    messages.append({\n",
        "        \"role\": \"user\", \n",
        "        \"content\": f'TOOL RESULT (get_account_summary): {json.dumps({\"account_id\": seed_account, \"account_type\": \"Corporate\", \"risk_score\": 0.75, \"transitive_illicit\": True, \"is_sanctioned\": False})}'\n",
        "    })\n",
        "    \n",
        "    # Step 2: Get transactions - FOCUS ON is_laundering=1\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\", \n",
        "        \"content\": f\"\"\"The account has transitive_illicit=True, meaning it's connected to laundering activity.\n",
        "Now I need to find the specific laundering transactions (is_laundering=1) to build the laundering trail.\n",
        "\n",
        "<tool_call>\n",
        "{{\"name\": \"get_recent_transactions\", \"arguments\": {{\"account_id\": \"{seed_account}\", \"direction\": \"outgoing\"}}}}\n",
        "</tool_call>\"\"\"\n",
        "    })\n",
        "    \n",
        "    # Show transactions with is_laundering flag\n",
        "    txn_results = [\n",
        "        {\"counterparty\": terminal_account, \"amount\": pattern.transactions[0]['amount'] if pattern.transactions else 5000, \"is_laundering\": 1, \"high_risk_indicator\": True},\n",
        "        {\"counterparty\": intermediate_accounts[0] if intermediate_accounts else \"999-ACC001\", \"amount\": 3000, \"is_laundering\": 1, \"high_risk_indicator\": True},\n",
        "        {\"counterparty\": \"999-LEGIT01\", \"amount\": 2000, \"is_laundering\": 0, \"high_risk_indicator\": False}\n",
        "    ]\n",
        "    messages.append({\n",
        "        \"role\": \"user\", \n",
        "        \"content\": f'TOOL RESULT (get_recent_transactions): {json.dumps(txn_results)}'\n",
        "    })\n",
        "    \n",
        "    # Step 3: REASONING about laundering trail before sanctions check\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\", \n",
        "        \"content\": f\"\"\"Analyzing the transactions:\n",
        "- {terminal_account}: is_laundering=1, high_risk_indicator=True â†’ ON LAUNDERING TRAIL\n",
        "- {intermediate_accounts[0] if intermediate_accounts else \"999-ACC001\"}: is_laundering=1 â†’ ON LAUNDERING TRAIL  \n",
        "- 999-LEGIT01: is_laundering=0 â†’ NOT on laundering trail\n",
        "\n",
        "For a valid SAR, I need to find an entity that is BOTH:\n",
        "1. On the sanctions list\n",
        "2. On the laundering trail (reached via is_laundering=1)\n",
        "\n",
        "Let me check sanctions for {terminal_account} since it's on the laundering trail.\n",
        "\n",
        "<tool_call>\n",
        "{{\"name\": \"check_sanctions_list\", \"arguments\": {{\"entity_id\": \"{terminal_account}\"}}}}\n",
        "</tool_call>\"\"\"\n",
        "    })\n",
        "    \n",
        "    messages.append({\n",
        "        \"role\": \"user\", \n",
        "        \"content\": f'TOOL RESULT (check_sanctions_list): {json.dumps({\"entity_id\": terminal_account, \"on_sanctions_list\": True, \"list_type\": \"OFAC SDN\"})}'\n",
        "    })\n",
        "    \n",
        "    # Step 4: Submit SAR - EXPLICIT REASONING about both conditions\n",
        "    reason = f\"Entity {terminal_account} is sanctioned (OFAC) and on laundering trail from {seed_account}\"\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\", \n",
        "        \"content\": f\"\"\"Checking SAR conditions for {terminal_account}:\n",
        "1. âœ“ On sanctions list: YES (OFAC SDN confirmed)\n",
        "2. âœ“ On laundering trail: YES (reached via is_laundering=1 from {seed_account})\n",
        "\n",
        "BOTH conditions are met. Submitting SAR now.\n",
        "\n",
        "<tool_call>\n",
        "{{\"name\": \"submit_sar\", \"arguments\": {{\"entity_id\": \"{terminal_account}\", \"reason\": \"{reason}\"}}}}\n",
        "</tool_call>\"\"\"\n",
        "    })\n",
        "    \n",
        "    return messages\n",
        "\n",
        "\n",
        "def generate_sft_dataset(patterns: List[LaunderingPattern], max_samples: int = 100) -> List[dict]:\n",
        "    dataset = []\n",
        "    for i, pattern in enumerate(random.sample(patterns, min(max_samples, len(patterns)))):\n",
        "        messages = generate_sft_sample(pattern)\n",
        "        if messages:\n",
        "            dataset.append({\"id\": f\"sft_{i}\", \"pattern_type\": pattern.pattern_type, \"messages\": messages})\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def format_for_unsloth_sft(dataset: List[dict]) -> List[dict]:\n",
        "    \"\"\"Format dataset for Unsloth SFT trainer.\"\"\"\n",
        "    formatted = []\n",
        "    for sample in dataset:\n",
        "        # Apply chat template to messages\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            sample['messages'],\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False,\n",
        "        )\n",
        "        formatted.append({\"text\": text})\n",
        "    return formatted\n",
        "\n",
        "\n",
        "# Generate SFT dataset\n",
        "print(\"ğŸ“Š Generating SFT training data...\")\n",
        "sft_dataset = generate_sft_dataset(laundering_patterns, max_samples=100)\n",
        "sft_formatted = format_for_unsloth_sft(sft_dataset)\n",
        "\n",
        "print(f\"âœ“ Generated {len(sft_formatted)} SFT training samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. SFT Training with Unsloth\n",
        "\n",
        "Fine-tune with LoRA adapters (r=32, alpha=64) targeting attention and MLP layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SFT TRAINING WITH UNSLOTH - LoRA Fine-tuning\n",
        "# ============================================================================\n",
        "\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "import shutil\n",
        "\n",
        "# ============================================================================\n",
        "# CLEANUP - Remove existing PEFT adapters and training artifacts\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ§¹ Cleaning up previous training artifacts...\")\n",
        "\n",
        "import gc\n",
        "\n",
        "# Check if model already has PEFT adapters - if so, user needs to restart kernel\n",
        "if hasattr(model, 'peft_config') or hasattr(model, 'active_adapter'):\n",
        "    raise RuntimeError(\n",
        "        \"âŒ Model already has PEFT adapters from a previous training run.\\n\"\n",
        "        \"   Please RESTART THE KERNEL and re-run all cells to train from scratch.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"   âœ“ Model is clean (no existing adapters)\")\n",
        "\n",
        "# Remove previous training output directories\n",
        "cleanup_dirs = [\n",
        "    MODELS_DIR / \"sft_output\",\n",
        "    MODELS_DIR / \"sft_adapter\",\n",
        "    MODELS_DIR / \"grpo_output\", \n",
        "    MODELS_DIR / \"grpo_adapter\",\n",
        "    MODELS_DIR / \"aml_agent_final\",\n",
        "]\n",
        "\n",
        "for dir_path in cleanup_dirs:\n",
        "    if dir_path.exists():\n",
        "        try:\n",
        "            shutil.rmtree(dir_path)\n",
        "            print(f\"   âœ“ Removed: {dir_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âš  Could not remove {dir_path.name}: {e}\")\n",
        "\n",
        "print(\"âœ“ Cleanup complete\\n\")\n",
        "\n",
        "print(\"ğŸ“¥ Configuring LoRA adapters for SFT...\")\n",
        "\n",
        "# Get PEFT model with LoRA\n",
        "model_for_training = FastModel.get_peft_model(\n",
        "    model, \n",
        "    r=LORA_R, \n",
        "    target_modules=LORA_TARGET_MODULES, \n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=0.05, \n",
        "    bias=\"none\", \n",
        "    use_gradient_checkpointing=\"unsloth\", \n",
        "    random_state=RANDOM_SEED,\n",
        ")\n",
        "\n",
        "# Create dataset\n",
        "sft_hf_dataset = Dataset.from_list([{\"text\": s[\"text\"]} for s in sft_formatted])\n",
        "\n",
        "# Training arguments\n",
        "sft_output_dir = MODELS_DIR / \"sft_output\"\n",
        "sft_args = TrainingArguments(\n",
        "    output_dir=str(sft_output_dir), \n",
        "    per_device_train_batch_size=2, \n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=SFT_EPOCHS, \n",
        "    learning_rate=SFT_LEARNING_RATE, \n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10, \n",
        "    save_strategy=\"epoch\", \n",
        "    fp16=not torch.cuda.is_bf16_supported(),\n",
        "    bf16=torch.cuda.is_bf16_supported(), \n",
        "    optim=\"adamw_8bit\", \n",
        "    seed=RANDOM_SEED, \n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "sft_trainer = SFTTrainer(\n",
        "    model=model_for_training, \n",
        "    tokenizer=tokenizer, \n",
        "    train_dataset=sft_hf_dataset,\n",
        "    args=sft_args, \n",
        "    max_seq_length=4096,\n",
        ")\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ“ STARTING SFT TRAINING\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Epochs: {SFT_EPOCHS} | LR: {SFT_LEARNING_RATE} | LoRA r={LORA_R}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "# Train\n",
        "sft_trainer.train()\n",
        "\n",
        "# Save adapter\n",
        "sft_adapter_path = MODELS_DIR / \"sft_adapter\"\n",
        "model_for_training.save_pretrained(str(sft_adapter_path))\n",
        "tokenizer.save_pretrained(str(sft_adapter_path))\n",
        "\n",
        "print(f\"\\nâœ“ SFT training complete! Adapter saved to: {sft_adapter_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. STAGE 2: Post-SFT Evaluation\n",
        "\n",
        "Evaluate the **SFT-tuned model** to measure improvement from supervised fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STAGE 2: POST-SFT EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ” STAGE 2: POST-SFT EVALUATION\")\n",
        "print(\"   Testing model after Supervised Fine-Tuning\")\n",
        "\n",
        "# Switch to inference mode\n",
        "FastModel.for_inference(model_for_training)\n",
        "\n",
        "# Update agent wrapper with trained model\n",
        "agent_model_sft = Qwen3AgentWrapper(model_for_training, tokenizer, aml_tools)\n",
        "\n",
        "# Update agent node to use SFT model\n",
        "def agent_node_sft(state: InvestigationState) -> dict:\n",
        "    \"\"\"Agent node using SFT-trained model with full state context.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    start_account = state[\"start_account\"]\n",
        "    \n",
        "    if not messages:\n",
        "        initial_message = HumanMessage(content=f\"Begin investigation of account: {start_account}\")\n",
        "        messages = [initial_message]\n",
        "    \n",
        "    # Pass full state for structured context building\n",
        "    response = agent_model_sft.invoke(messages, state)\n",
        "    new_step_count = state.get(\"step_count\", 0) + 1\n",
        "    \n",
        "    return {\"messages\": [response], \"step_count\": new_step_count}\n",
        "\n",
        "# Rebuild graph with SFT model\n",
        "builder_sft = StateGraph(InvestigationState)\n",
        "builder_sft.add_node(\"agent\", agent_node_sft)\n",
        "builder_sft.add_node(\"tools\", tool_node)\n",
        "builder_sft.add_edge(START, \"agent\")\n",
        "builder_sft.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
        "builder_sft.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "memory_sft = MemorySaver()\n",
        "investigation_graph_sft = builder_sft.compile(checkpointer=memory_sft)\n",
        "\n",
        "# Run post-SFT evaluation\n",
        "post_sft_results = run_evaluation(\n",
        "    graph=investigation_graph_sft,\n",
        "    stage_name=\"Post-SFT\",\n",
        "    n_episodes=EVAL_EPISODES,\n",
        "    use_llm_judge=bool(gemini_client),\n",
        "    verbose=True,\n",
        "    show_episode_details=True,\n",
        ")\n",
        "\n",
        "# Store results for comparison\n",
        "all_results[\"Post-SFT\"] = post_sft_results\n",
        "\n",
        "# Show improvement over baseline\n",
        "baseline_sr = all_results[\"Baseline\"]['success'].mean()\n",
        "post_sft_sr = post_sft_results['success'].mean()\n",
        "print(f\"\\nğŸ“ˆ SFT Improvement: {baseline_sr*100:.1f}% â†’ {post_sft_sr*100:.1f}% ({(post_sft_sr-baseline_sr)*100:+.1f}%)\")\n",
        "\n",
        "print(\"\\nğŸ“Š Post-SFT Results Summary:\")\n",
        "print(post_sft_results[['success', 'steps', 'total_reward', 'overall_score']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 10. GRPO Training - Reinforcement Learning\n",
        "\n",
        "Train with **Group Relative Policy Optimization (GRPO)** using TRL:\n",
        "- **R_Discovery (+0.5)**: Discovering transitive_illicit nodes\n",
        "- **R_Logic (+0.3)**: Correct tool sequencing\n",
        "- **R_Outcome (+2.0)**: Correct SAR submission\n",
        "- **R_Efficiency (-0.1)**: Step penalty to prevent loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GRPO TRAINING - Group Relative Policy Optimization\n",
        "# ============================================================================\n",
        "\n",
        "from trl import GRPOTrainer, GRPOConfig\n",
        "\n",
        "def generate_grpo_prompts(patterns: List[LaunderingPattern], n_prompts: int = 50) -> List[str]:\n",
        "    \"\"\"Generate prompts for GRPO training from laundering patterns.\"\"\"\n",
        "    prompts = []\n",
        "    selected = random.sample(patterns, min(n_prompts, len(patterns)))\n",
        "    \n",
        "    for pattern in selected:\n",
        "        seed = pattern.seed_account\n",
        "        if seed:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": INVESTIGATION_SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": f\"Begin investigation of account: {seed}\"}\n",
        "            ]\n",
        "            prompt = tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True,\n",
        "            )\n",
        "            prompts.append(prompt)\n",
        "    \n",
        "    return prompts\n",
        "\n",
        "\n",
        "def grpo_reward_function(completions: List[str], prompts: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    GRPO reward function that evaluates model completions.\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    \n",
        "    for completion, prompt in zip(completions, prompts):\n",
        "        # Extract seed account from prompt\n",
        "        match = re.search(r'account:\\s*([^\\n]+)', prompt)\n",
        "        if not match:\n",
        "            rewards.append(-1.0)\n",
        "            continue\n",
        "        \n",
        "        seed_account = match.group(1).strip()\n",
        "        total_reward = 0.0\n",
        "        \n",
        "        # Reset environment\n",
        "        env.reset_investigation(seed_account)\n",
        "        \n",
        "        # Try to extract and execute tool call from completion\n",
        "        tool_calls = agent_model_sft._extract_tool_calls(completion)\n",
        "        \n",
        "        if tool_calls:\n",
        "            tool_call = tool_calls[0]\n",
        "            tool_name = tool_call.get(\"name\", \"\")\n",
        "            tool_args = tool_call.get(\"args\", {})\n",
        "            \n",
        "            if tool_name in tools_by_name:\n",
        "                result = tools_by_name[tool_name].invoke(tool_args)\n",
        "                result_dict = json.loads(result)\n",
        "                total_reward = calculate_reward(tool_name, tool_args, result_dict, {})\n",
        "            else:\n",
        "                total_reward = -0.3  # Invalid tool name\n",
        "        else:\n",
        "            total_reward = -0.5  # No valid tool call\n",
        "        \n",
        "        rewards.append(total_reward)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "\n",
        "# Generate GRPO training prompts\n",
        "print(\"ğŸ“Š Generating GRPO training prompts...\")\n",
        "grpo_prompts = generate_grpo_prompts(laundering_patterns, n_prompts=50)\n",
        "grpo_dataset = Dataset.from_dict({\"prompt\": grpo_prompts})\n",
        "print(f\"âœ“ Generated {len(grpo_prompts)} GRPO training prompts\")\n",
        "\n",
        "# GRPO Training Configuration\n",
        "grpo_output_dir = MODELS_DIR / \"grpo_output\"\n",
        "grpo_config = GRPOConfig(\n",
        "    output_dir=str(grpo_output_dir),\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=GRPO_EPOCHS,\n",
        "    learning_rate=GRPO_LEARNING_RATE,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"ğŸ¯ STARTING GRPO TRAINING\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Epochs:        {GRPO_EPOCHS}\")\n",
        "print(f\"  Learning Rate: {GRPO_LEARNING_RATE}\")\n",
        "print(f\"  Prompts:       {len(grpo_prompts)}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "# Create GRPO Trainer\n",
        "grpo_trainer = GRPOTrainer(\n",
        "    model=model_for_training,\n",
        "    config=grpo_config,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=grpo_dataset,\n",
        "    reward_funcs=grpo_reward_function,\n",
        ")\n",
        "\n",
        "# Train with GRPO\n",
        "grpo_trainer.train()\n",
        "\n",
        "# Save GRPO adapter\n",
        "grpo_adapter_path = MODELS_DIR / \"grpo_adapter\"\n",
        "model_for_training.save_pretrained(str(grpo_adapter_path))\n",
        "tokenizer.save_pretrained(str(grpo_adapter_path))\n",
        "\n",
        "print(f\"\\nâœ“ GRPO training complete!\")\n",
        "print(f\"âœ“ Adapter saved to: {grpo_adapter_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. STAGE 3: Post-GRPO Evaluation\n",
        "\n",
        "Evaluate the **GRPO-trained model** to measure improvement from reinforcement learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STAGE 3: POST-GRPO EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ” STAGE 3: POST-GRPO EVALUATION\")\n",
        "print(\"   Testing model after GRPO Reinforcement Learning\")\n",
        "\n",
        "# Switch to inference mode\n",
        "FastModel.for_inference(model_for_training)\n",
        "\n",
        "# Update agent wrapper with GRPO-trained model\n",
        "agent_model_grpo = Qwen3AgentWrapper(model_for_training, tokenizer, aml_tools)\n",
        "\n",
        "# Update agent node to use GRPO model\n",
        "def agent_node_grpo(state: InvestigationState) -> dict:\n",
        "    \"\"\"Agent node using GRPO-trained model with full state context.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    start_account = state[\"start_account\"]\n",
        "    \n",
        "    if not messages:\n",
        "        initial_message = HumanMessage(content=f\"Begin investigation of account: {start_account}\")\n",
        "        messages = [initial_message]\n",
        "    \n",
        "    # Pass full state for structured context building\n",
        "    response = agent_model_grpo.invoke(messages, state)\n",
        "    new_step_count = state.get(\"step_count\", 0) + 1\n",
        "    \n",
        "    return {\"messages\": [response], \"step_count\": new_step_count}\n",
        "\n",
        "# Rebuild graph with GRPO model\n",
        "builder_grpo = StateGraph(InvestigationState)\n",
        "builder_grpo.add_node(\"agent\", agent_node_grpo)\n",
        "builder_grpo.add_node(\"tools\", tool_node)\n",
        "builder_grpo.add_edge(START, \"agent\")\n",
        "builder_grpo.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
        "builder_grpo.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "memory_grpo = MemorySaver()\n",
        "investigation_graph_grpo = builder_grpo.compile(checkpointer=memory_grpo)\n",
        "\n",
        "# Run post-GRPO evaluation\n",
        "post_grpo_results = run_evaluation(\n",
        "    graph=investigation_graph_grpo,\n",
        "    stage_name=\"Post-GRPO\",\n",
        "    n_episodes=EVAL_EPISODES,\n",
        "    use_llm_judge=bool(gemini_client),\n",
        "    verbose=True,\n",
        "    show_episode_details=True,\n",
        ")\n",
        "\n",
        "# Store results for comparison\n",
        "all_results[\"Post-GRPO\"] = post_grpo_results\n",
        "\n",
        "print(\"\\nğŸ“Š Post-GRPO Results Summary:\")\n",
        "print(post_grpo_results[['success', 'steps', 'total_reward', 'overall_score']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 12. Final Comparison: Baseline vs SFT vs GRPO\n",
        "\n",
        "Compare metrics across all three training stages:\n",
        "- **Success Rate**: Percentage of correct SAR submissions\n",
        "- **Average Steps**: Efficiency of investigation\n",
        "- **Average Reward**: GRPO reward function score\n",
        "- **LLM-as-Judge Scores**: Strategy, Persistence, Outcome, Overall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL COMPARISON - Baseline vs SFT vs GRPO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ“Š FINAL COMPARISON: BASELINE vs SFT vs GRPO\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Build comparison DataFrame\n",
        "comparison_data = []\n",
        "for stage_name, results_df in all_results.items():\n",
        "    comparison_data.append({\n",
        "        \"Stage\": stage_name,\n",
        "        \"Success Rate (%)\": results_df['success'].mean() * 100,\n",
        "        \"Avg Steps\": results_df['steps'].mean(),\n",
        "        \"Avg Reward\": results_df['total_reward'].mean(),\n",
        "        \"Avg Strategy Score\": results_df['strategy_score'].mean() if 'strategy_score' in results_df else 0,\n",
        "        \"Avg Persistence Score\": results_df['persistence_score'].mean() if 'persistence_score' in results_df else 0,\n",
        "        \"Avg Outcome Score\": results_df['outcome_score'].mean() if 'outcome_score' in results_df else 0,\n",
        "        \"Avg Overall Score\": results_df['overall_score'].mean() if 'overall_score' in results_df else 0,\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.set_index(\"Stage\")\n",
        "\n",
        "# Display comparison table\n",
        "print(\"\\nğŸ“ˆ METRICS COMPARISON:\")\n",
        "print(\"-\" * 80)\n",
        "print(comparison_df.round(2).to_string())\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Calculate improvements\n",
        "if len(comparison_data) >= 2:\n",
        "    baseline = comparison_data[0]\n",
        "    \n",
        "    print(\"\\nğŸ“Š IMPROVEMENTS OVER BASELINE:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    for i, stage in enumerate(comparison_data[1:], 1):\n",
        "        stage_name = stage[\"Stage\"]\n",
        "        success_improvement = stage[\"Success Rate (%)\"] - baseline[\"Success Rate (%)\"]\n",
        "        reward_improvement = stage[\"Avg Reward\"] - baseline[\"Avg Reward\"]\n",
        "        score_improvement = stage[\"Avg Overall Score\"] - baseline[\"Avg Overall Score\"]\n",
        "        \n",
        "        print(f\"\\n  {stage_name}:\")\n",
        "        print(f\"    Success Rate: {success_improvement:+.1f}%\")\n",
        "        print(f\"    Avg Reward:   {reward_improvement:+.2f}\")\n",
        "        print(f\"    Overall Score: {score_improvement:+.1f}/10\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "# Log to MLflow\n",
        "with mlflow.start_run(run_name=\"final_comparison\"):\n",
        "    for stage_name, results_df in all_results.items():\n",
        "        mlflow.log_metrics({\n",
        "            f\"{stage_name}_success_rate\": results_df['success'].mean(),\n",
        "            f\"{stage_name}_avg_steps\": results_df['steps'].mean(),\n",
        "            f\"{stage_name}_avg_reward\": results_df['total_reward'].mean(),\n",
        "            f\"{stage_name}_avg_overall_score\": results_df.get('overall_score', pd.Series([0])).mean(),\n",
        "        })\n",
        "\n",
        "print(\"âœ“ Comparison logged to MLflow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION - Performance Comparison Charts\n",
        "# ============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create comparison visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('AML Investigation Agent (LangGraph): Training Stage Comparison', fontsize=14, fontweight='bold')\n",
        "\n",
        "stages = list(all_results.keys())\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71'][:len(stages)]\n",
        "\n",
        "# 1. Success Rate\n",
        "ax1 = axes[0, 0]\n",
        "success_rates = [all_results[s]['success'].mean() * 100 for s in stages]\n",
        "bars1 = ax1.bar(stages, success_rates, color=colors, edgecolor='black', linewidth=1.2)\n",
        "ax1.set_ylabel('Success Rate (%)', fontweight='bold')\n",
        "ax1.set_title('SAR Submission Accuracy', fontweight='bold')\n",
        "ax1.set_ylim(0, 100)\n",
        "for bar, val in zip(bars1, success_rates):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, f'{val:.1f}%', \n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. Average Reward\n",
        "ax2 = axes[0, 1]\n",
        "avg_rewards = [all_results[s]['total_reward'].mean() for s in stages]\n",
        "bars2 = ax2.bar(stages, avg_rewards, color=colors, edgecolor='black', linewidth=1.2)\n",
        "ax2.set_ylabel('Average Reward', fontweight='bold')\n",
        "ax2.set_title('GRPO Reward Score', fontweight='bold')\n",
        "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "for bar, val in zip(bars2, avg_rewards):\n",
        "    ypos = bar.get_height() + 0.1 if val >= 0 else bar.get_height() - 0.3\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, ypos, f'{val:.2f}', \n",
        "             ha='center', va='bottom' if val >= 0 else 'top', fontweight='bold')\n",
        "\n",
        "# 3. Average Steps\n",
        "ax3 = axes[1, 0]\n",
        "avg_steps = [all_results[s]['steps'].mean() for s in stages]\n",
        "bars3 = ax3.bar(stages, avg_steps, color=colors, edgecolor='black', linewidth=1.2)\n",
        "ax3.set_ylabel('Average Steps', fontweight='bold')\n",
        "ax3.set_title('Investigation Efficiency', fontweight='bold')\n",
        "for bar, val in zip(bars3, avg_steps):\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, f'{val:.1f}', \n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. LLM-as-Judge Overall Score\n",
        "ax4 = axes[1, 1]\n",
        "if 'overall_score' in all_results[stages[0]].columns:\n",
        "    overall_scores = [all_results[s]['overall_score'].mean() for s in stages]\n",
        "    bars4 = ax4.bar(stages, overall_scores, color=colors, edgecolor='black', linewidth=1.2)\n",
        "    ax4.set_ylabel('Overall Score (0-10)', fontweight='bold')\n",
        "    ax4.set_title('LLM-as-Judge Score', fontweight='bold')\n",
        "    ax4.set_ylim(0, 10)\n",
        "    for bar, val in zip(bars4, overall_scores):\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, f'{val:.1f}', \n",
        "                 ha='center', va='bottom', fontweight='bold')\n",
        "else:\n",
        "    ax4.text(0.5, 0.5, 'LLM-as-Judge\\nNot Available', ha='center', va='center', fontsize=12)\n",
        "    ax4.set_title('LLM-as-Judge Score', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "comparison_chart_path = OUTPUT_DIR / \"langgraph_training_comparison.png\"\n",
        "plt.savefig(str(comparison_chart_path), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ“ Comparison chart saved to {comparison_chart_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 13. Save Final Model\n",
        "\n",
        "Save the trained model adapters for deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE FINAL MODEL\n",
        "# ============================================================================\n",
        "\n",
        "# Save final adapter to models directory\n",
        "final_model_path = MODELS_DIR / \"aml_agent_langgraph_final\"\n",
        "model_for_training.save_pretrained(str(final_model_path))\n",
        "tokenizer.save_pretrained(str(final_model_path))\n",
        "\n",
        "# Save comparison results\n",
        "comparison_csv_path = OUTPUT_DIR / \"langgraph_training_comparison.csv\"\n",
        "comparison_df.to_csv(str(comparison_csv_path))\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"âœ… TRAINING COMPLETE\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Final Model:      {final_model_path}\")\n",
        "print(f\"  SFT Adapter:      {sft_adapter_path}\")\n",
        "print(f\"  GRPO Adapter:     {grpo_adapter_path}\")\n",
        "print(f\"  Comparison Chart: {OUTPUT_DIR / 'langgraph_training_comparison.png'}\")\n",
        "print(f\"  Comparison CSV:   {comparison_csv_path}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "print(f\"\\nğŸ‰ AML Investigation Agent (LangGraph) Training Complete!\")\n",
        "print(f\"\\nğŸ“Š Final Performance Summary:\")\n",
        "print(comparison_df.round(2).to_string())\n",
        "\n",
        "print(f\"\\nğŸ”— LangGraph Architecture Summary:\")\n",
        "print(f\"  - State: InvestigationState with messages + investigation context\")\n",
        "print(f\"  - Agent Node: Qwen3 decision making with tool calling\")\n",
        "print(f\"  - Tool Node: Executes 4 AML investigation tools\")\n",
        "print(f\"  - Conditional Edge: Routes between tools and end\")\n",
        "print(f\"  - Checkpointer: MemorySaver for persistent state\")\n",
        "print(f\"  - Observability: MLflow autologging for full traces\")\n",
        "\n",
        "print(f\"\\nNext Steps:\")\n",
        "print(f\"  1. Load adapter with Unsloth for inference\")\n",
        "print(f\"  2. Deploy agent with LangGraph orchestration\")\n",
        "print(f\"  3. Monitor with MLflow tracing UI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
