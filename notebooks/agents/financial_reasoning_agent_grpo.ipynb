{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Reasoning Agent with GRPO Fine-Tuning\n",
    "\n",
    "This notebook implements a **Financial Analyst Agent** capable of complex reasoning and accurate calculation. We leverage a **\"Thinking\" Model** (DeepSeek-R1-Distill-Qwen-7B) fine-tuned with **Unsloth & GRPO**, orchestrate it via **LangGraph**, and empower it with a **Python REPL Tool** for precise arithmetic.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Financial Reasoning Agent                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚  Think   â”‚ -> â”‚ Generate â”‚ -> â”‚ Execute  â”‚ -> â”‚ Finalize  â”‚  â”‚\n",
    "â”‚  â”‚  Node    â”‚    â”‚  Code    â”‚    â”‚  Python  â”‚    â”‚  Answer   â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚        â”‚               â”‚               â”‚               â”‚        â”‚\n",
    "â”‚        v               v               v               v        â”‚\n",
    "â”‚   <think>...</think>  ```python   REPL Output    <answer>       â”‚\n",
    "â”‚   Reasoning trace    calculation   Precise math   Final result  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **\"Thinking\" Architecture**: The model generates explicit reasoning traces (`<think>...</think>`) before answering\n",
    "- **Tool-Augmented Reasoning**: Python REPL executes math derived during thinking phase for 100% arithmetic accuracy\n",
    "- **Before/After Comparison**: We evaluate agent performance with Base Model vs. Fine-Tuned Model\n",
    "- **Full Observability**: All traces and experiments logged to **MLflow** with LLM-as-Judge evaluation\n",
    "\n",
    "## Tech Stack\n",
    "\n",
    "| Component | Library | Purpose |\n",
    "|-----------|---------|--------|\n",
    "| Model Tuning | `unsloth`, `trl` (GRPO), `peft` | Efficient fine-tuning with reinforcement learning |\n",
    "| Orchestration | `langchain`, `langgraph` | Agent workflow and state management |\n",
    "| Tools | `langchain_experimental` | Python REPL for precise calculations |\n",
    "| Data Processing | `polars`, `datasets` | Fast DataFrame operations |\n",
    "| Evaluation | `mlflow`, `google-genai` | Experiment tracking & LLM-as-Judge |\n",
    "| Hardware | DGX Spark / GB10 GPU / CUDA | GPU acceleration |\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Phase 1: Environment & Data Preparation](#phase-1-environment--data-preparation)\n",
    "2. [Phase 2: Agent Definition](#phase-2-agent-definition)  \n",
    "3. [Phase 3: Base Model Evaluation](#phase-3-base-model-evaluation)\n",
    "4. [Phase 4: GRPO Fine-Tuning](#phase-4-grpo-fine-tuning)\n",
    "5. [Phase 5: Tuned Model Evaluation & Comparison](#phase-5-tuned-model-evaluation--comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Environment & Data Preparation\n",
    "\n",
    "## Functional Design\n",
    "\n",
    "This phase establishes the foundation for the entire project:\n",
    "- Load environment variables (API keys, tokens)\n",
    "- Initialize MLflow experiment tracking with proper configuration\n",
    "- Load and preprocess the ConvFinQA dataset for financial reasoning tasks\n",
    "- Define the prompt structure that teaches the model our \"thinking\" paradigm\n",
    "\n",
    "## Technical Design\n",
    "\n",
    "**Why ConvFinQA?**\n",
    "- Contains complex financial questions requiring **multi-step mathematical reasoning**\n",
    "- Provides rich context from financial documents (10-K reports, earnings calls)\n",
    "- Ground truth answers enable supervised and RL-based training\n",
    "\n",
    "**Data Enhancement Strategy:**\n",
    "We format data to reward the model for:\n",
    "1. Generating clear reasoning in `<think>` tags\n",
    "2. Producing executable Python code for calculations\n",
    "3. Outputting final answers in `<answer>` tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setup & Dependencies\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "1. **GPU**: NVIDIA GPU with CUDA support (tested on DGX Spark / GB10)\n",
    "2. **Environment variables**: `.env` file with `HF_TOKEN` and `GEMINI_API_KEY`\n",
    "3. **MLflow Server**: Start before running: `mlflow ui --port 5000`\n",
    "4. **Devcontainer**: Use the provided devcontainer which includes `litellm` (required by MLflow's `make_judge` for Gemini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded .env from: /workspace/.env\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION\n",
      "============================================================\n",
      "  Model: unsloth/DeepSeek-R1-Distill-Qwen-7B\n",
      "  Max Seq Length: 8192\n",
      "  4-bit Quantization: True\n",
      "  GPU Memory Utilization: 0.85\n",
      "  Training Steps: 1000\n",
      "  Evaluation Samples: 20\n",
      "  Random Seed: 42\n",
      "  HF Token: âœ“ Set\n",
      "  Gemini API Key: âœ“ Set\n",
      "  Gemini Model: gemini-2.5-pro\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS & CONFIGURATION\n",
    "# ============================================================================\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, List, Optional, Callable\n",
    "from dataclasses import dataclass\n",
    "import operator\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# PROJECT PATHS (relative to project root)\n",
    "# ============================================================================\n",
    "PROJECT_ROOT = Path().absolute().parent.parent\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\" / \"agents\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MLRUNS_DIR = NOTEBOOKS_DIR / \"mlruns\"\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ENVIRONMENT VARIABLES\n",
    "# ============================================================================\n",
    "env_path = PROJECT_ROOT / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ“ Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    load_dotenv()\n",
    "    print(\"âœ“ Loaded .env from current directory\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Central configuration for the Financial Reasoning Agent project.\"\"\"\n",
    "    \n",
    "    # API Keys\n",
    "    HF_TOKEN: str = os.getenv(\"HF_TOKEN\", \"\")\n",
    "    GEMINI_API_KEY: str = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "    GEMINI_MODEL: str = \"gemini-2.5-pro\"  # Model for LLM-as-Judge evaluation\n",
    "    \n",
    "    # Model Configuration\n",
    "    MODEL_NAME: str = \"unsloth/DeepSeek-R1-Distill-Qwen-7B\"  # DeepSeek R1 distilled - excellent reasoning\n",
    "    MAX_SEQ_LENGTH: int = 8192\n",
    "    LOAD_IN_4BIT: bool = True\n",
    "    GPU_MEMORY_UTILIZATION: float = 0.85\n",
    "    \n",
    "    # Training Configuration  \n",
    "    LEARNING_RATE: float = 5e-6\n",
    "    BATCH_SIZE: int = 1\n",
    "    GRADIENT_ACCUMULATION_STEPS: int = 4\n",
    "    MAX_TRAINING_STEPS: int = 1000  # Increased from 300 for better convergence\n",
    "    LOGGING_STEPS: int = 10\n",
    "    \n",
    "    # Evaluation Configuration\n",
    "    EVALUATION_SAMPLES: int = 20  # Increased for more robust evaluation\n",
    "    MAX_NEW_TOKENS: int = 2048  # Increased to allow longer reasoning traces\n",
    "    RANDOM_SEED: int = 42  # Seed for reproducible random sampling\n",
    "    \n",
    "    # MLflow Configuration\n",
    "    MLFLOW_EXPERIMENT_NAME: str = \"Financial-Reasoning-Agent\"\n",
    "    MLFLOW_TRACKING_URI: str = f\"file://{MLRUNS_DIR}\"\n",
    "    \n",
    "    # Output Paths\n",
    "    OUTPUT_DIR: str = str(MODELS_DIR / \"checkpoints\" / \"deepseek-r1-fin-agent\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Validate configuration\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Model: {config.MODEL_NAME}\")\n",
    "print(f\"  Max Seq Length: {config.MAX_SEQ_LENGTH}\")\n",
    "print(f\"  4-bit Quantization: {config.LOAD_IN_4BIT}\")\n",
    "print(f\"  GPU Memory Utilization: {config.GPU_MEMORY_UTILIZATION}\")\n",
    "print(f\"  Training Steps: {config.MAX_TRAINING_STEPS}\")\n",
    "print(f\"  Evaluation Samples: {config.EVALUATION_SAMPLES}\")\n",
    "print(f\"  Random Seed: {config.RANDOM_SEED}\")\n",
    "print(f\"  HF Token: {'âœ“ Set' if config.HF_TOKEN else 'âœ— Not set'}\")\n",
    "print(f\"  Gemini API Key: {'âœ“ Set' if config.GEMINI_API_KEY else 'âœ— Not set'}\")\n",
    "print(f\"  Gemini Model: {config.GEMINI_MODEL}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 MLflow Initialization\n",
    "\n",
    "**Technical Notes:**\n",
    "- We configure MLflow to store all experiment data locally in the `mlruns/` directory\n",
    "- `mlflow.langchain.autolog()` captures LangGraph agent traces automatically\n",
    "- Each run will log: parameters, metrics, artifacts, and full agent trajectories\n",
    "- The LLM-as-Judge evaluations will appear in the MLflow UI under the \"Evaluation\" tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  LangChain autologging not available: No module named 'langchain'\n",
      "  MLflow will still track runs and metrics, but without automatic LLM tracing.\n",
      "\n",
      "âœ“ MLflow initialized\n",
      "  Tracking URI: file:///workspace/notebooks/agents/mlruns\n",
      "  Experiment: Financial-Reasoning-Agent\n",
      "  Experiment ID: 425390645702784385\n",
      "  View traces at: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MLFLOW INITIALIZATION\n",
    "# ============================================================================\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create mlruns directory if it doesn't exist\n",
    "MLRUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set tracking URI and experiment\n",
    "mlflow.set_tracking_uri(config.MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(config.MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# Enable autologging for LangChain/LangGraph\n",
    "# This captures agent traces, LLM calls, and tool invocations\n",
    "# Note: mlflow.langchain.autolog() takes no parameters in current versions\n",
    "try:\n",
    "    mlflow.langchain.autolog()\n",
    "    print(\"âœ“ LangChain autologging enabled\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  LangChain autologging not available: {e}\")\n",
    "    print(\"  MLflow will still track runs and metrics, but without automatic LLM tracing.\")\n",
    "\n",
    "# Get experiment info\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(config.MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "print(\"\\nâœ“ MLflow initialized\")\n",
    "print(f\"  Tracking URI: {config.MLFLOW_TRACKING_URI}\")\n",
    "print(f\"  Experiment: {config.MLFLOW_EXPERIMENT_NAME}\")\n",
    "print(f\"  Experiment ID: {experiment.experiment_id if experiment else 'New'}\")\n",
    "print(f\"  View traces at: http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load & Explore ConvFinQA Dataset\n",
    "\n",
    "**Dataset: [ConvFinQA](https://huggingface.co/datasets/MehdiHosseiniMoghadam/ConvFinQA)**\n",
    "\n",
    "ConvFinQA (Conversational Finance Question Answering) contains:\n",
    "- Financial context from real SEC filings and earnings reports\n",
    "- Multi-turn conversational questions requiring numerical reasoning\n",
    "- **Ground truth answers WITH explicit calculation steps** (key improvement!)\n",
    "\n",
    "**Why this dataset version (MehdiHosseiniMoghadam)?**\n",
    "- Contains **`steps` column** with explicit reasoning traces for each answer\n",
    "- Each step has: operation, arguments, and intermediate results\n",
    "- Enables **Process Reward Model (PRM)** training with step-level feedback\n",
    "- Provides **`pre_text`, `post_text`, and `table`** for structured context\n",
    "\n",
    "**Data Enhancement Strategy:**\n",
    "We use the `steps` column to generate synthetic `<think>` traces, giving the model explicit reasoning examples to learn from during GRPO training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConvFinQA dataset from HuggingFace (MehdiHosseiniMoghadam version)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Dataset loaded successfully\n",
      "  Total samples: 3,037\n",
      "  Columns: ['pre_text', 'post_text', 'filename', 'table_ori', 'table', 'question', 'answer', 'steps', 'id']\n",
      "  Memory usage: 13.49 MB\n",
      "\n",
      "ðŸ“Š Key columns for reasoning:\n",
      "  - pre_text: Context before table\n",
      "  - post_text: Context after table\n",
      "  - table: Structured financial data\n",
      "  - question: The financial question\n",
      "  - answer: Ground truth answer\n",
      "  - steps: REASONING STEPS (crucial for PRM training!)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD CONVFINQA DATASET (MehdiHosseiniMoghadam version with steps)\n",
    "# ============================================================================\n",
    "print(\"Loading ConvFinQA dataset from HuggingFace (MehdiHosseiniMoghadam version)...\")\n",
    "\n",
    "# Load the dataset - this version has the crucial 'steps' column for reasoning traces\n",
    "dataset = load_dataset(\"MehdiHosseiniMoghadam/ConvFinQA\", split=\"train\")\n",
    "\n",
    "# Convert to Polars for fast data manipulation\n",
    "df = pl.from_pandas(dataset.to_pandas())\n",
    "\n",
    "print(f\"\\nâœ“ Dataset loaded successfully\")\n",
    "print(f\"  Total samples: {len(df):,}\")\n",
    "print(f\"  Columns: {df.columns}\")\n",
    "print(f\"  Memory usage: {df.estimated_size() / 1e6:.2f} MB\")\n",
    "\n",
    "# Highlight the key columns for GRPO training\n",
    "print(f\"\\nðŸ“Š Key columns for reasoning:\")\n",
    "print(f\"  - pre_text: Context before table\")\n",
    "print(f\"  - post_text: Context after table\")\n",
    "print(f\"  - table: Structured financial data\")\n",
    "print(f\"  - question: The financial question\")\n",
    "print(f\"  - answer: Ground truth answer\")\n",
    "print(f\"  - steps: REASONING STEPS (crucial for PRM training!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE DATA EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "--- Sample 1 ---\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Pre-text (first 300 chars):\n",
      "26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 . all revenue components within the segment experienced growth during fiscal 2008 . license revenue generated the largest dollar growth in revenue as ep...\n",
      "\n",
      "ðŸ“Š Table (first 3 rows):\n",
      "  ['2008', 'year ended june 30 2009 2008', 'year ended june 30 2009 2008', 'year ended june 30 2009']\n",
      "  ['net income', '$ 103102', '$ 104222', '$ 104681']\n",
      "  ['non-cash expenses', '74397', '70420', '56348']\n",
      "  ... (4 more rows)\n",
      "\n",
      "â“ Question: what was the percentage change in the net cash from operating activities from 2008 to 2009\n",
      "\n",
      "âœ… Answer: 14.1%\n",
      "\n",
      "ðŸ§  Reasoning Steps (2 steps):\n",
      "  Step 1: minus2-1(206588, 181001) = 25587\n",
      "  Step 2: divide2-2(#0, 181001) = 14.1%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "--- Sample 2 ---\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Pre-text (first 300 chars):\n",
      "substantially all of the goodwill and other intangible assets recorded related to the acquisition of allied are not deductible for tax purposes . pro forma information the consolidated financial statements presented for republic include the operating results of allied from the date of the acquisitio...\n",
      "\n",
      "ðŸ“Š Table (first 3 rows):\n",
      "  ['', 'year ended december 31 2008 ( unaudited )', 'year ended december 31 2007 ( unaudited )']\n",
      "  ['revenue', '$ 9362.2', '$ 9244.9']\n",
      "  ['income from continuing operations available to common stockholders', '285.7', '423.2']\n",
      "  ... (2 more rows)\n",
      "\n",
      "â“ Question: what was the percent of the growth in the revenues from 2007 to 2008\n",
      "\n",
      "âœ… Answer: 1.3%\n",
      "\n",
      "ðŸ§  Reasoning Steps (2 steps):\n",
      "  Step 1: minus2-1(9362.2, 9244.9) = 117.3\n",
      "  Step 2: divide2-2(#0, 9244.9) = 1.3%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "--- Sample 3 ---\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Pre-text (first 300 chars):\n",
      "in a new business model such as the retail segment is inherently risky , particularly in light of the significant investment involved , the current economic climate , and the fixed nature of a substantial portion of the retail segment's operating expenses . results for this segment are dependent upo...\n",
      "\n",
      "ðŸ“Š Table (first 3 rows):\n",
      "  ['', '2002', '2001', '2000']\n",
      "  ['net sales', '$ 5742', '$ 5363', '$ 7983']\n",
      "  ['cost of sales', '4139', '4128', '5817']\n",
      "  ... (2 more rows)\n",
      "\n",
      "â“ Question: what was the percentage change in net sales from 2000 to 2001?\n",
      "\n",
      "âœ… Answer: -32%\n",
      "\n",
      "ðŸ§  Reasoning Steps (2 steps):\n",
      "  Step 1: minus1-1(5363, 7983) = -2620\n",
      "  Step 2: divide1-2(#0, 7983) = -32%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPLORE SAMPLE DATA\n",
    "# ============================================================================\n",
    "# Display a sample to understand the data structure\n",
    "sample = df.head(3).to_pandas()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAMPLE DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"--- Sample {idx + 1} ---\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Show pre_text (context before table)\n",
    "    # Note: HuggingFace datasets may store lists as numpy arrays\n",
    "    pre_text = row.get('pre_text', [])\n",
    "    if pre_text is not None and len(pre_text) > 0:\n",
    "        pre_text_list = list(pre_text) if hasattr(pre_text, '__iter__') and not isinstance(pre_text, str) else [str(pre_text)]\n",
    "        pre_text_str = ' '.join(str(item) for item in pre_text_list)\n",
    "        print(f\"\\nðŸ“„ Pre-text (first 300 chars):\\n{pre_text_str[:300]}...\")\n",
    "    \n",
    "    # Show table structure\n",
    "    table = row.get('table', [])\n",
    "    if table is not None and len(table) > 0:\n",
    "        table_list = list(table) if hasattr(table, '__iter__') and not isinstance(table, str) else []\n",
    "        print(f\"\\nðŸ“Š Table (first 3 rows):\")\n",
    "        for i, trow in enumerate(table_list[:3]):\n",
    "            print(f\"  {list(trow) if hasattr(trow, '__iter__') else trow}\")\n",
    "        if len(table_list) > 3:\n",
    "            print(f\"  ... ({len(table_list) - 3} more rows)\")\n",
    "    \n",
    "    # Show question and answer\n",
    "    print(f\"\\nâ“ Question: {row.get('question', 'N/A')}\")\n",
    "    print(f\"\\nâœ… Answer: {row.get('answer', 'N/A')}\")\n",
    "    \n",
    "    # Show reasoning steps (THE KEY FEATURE!)\n",
    "    steps = row.get('steps', [])\n",
    "    if steps is not None and len(steps) > 0:\n",
    "        steps_list = list(steps) if hasattr(steps, '__iter__') and not isinstance(steps, (str, dict)) else []\n",
    "        print(f\"\\nðŸ§  Reasoning Steps ({len(steps_list)} steps):\")\n",
    "        for i, step in enumerate(steps_list[:5]):  # Show first 5 steps\n",
    "            if isinstance(step, dict):\n",
    "                print(f\"  Step {i+1}: {step.get('op', '?')}({step.get('arg1', '?')}, {step.get('arg2', '?')}) = {step.get('res', '?')}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: {step}\")\n",
    "        if len(steps_list) > 5:\n",
    "            print(f\"  ... ({len(steps_list) - 5} more steps)\")\n",
    "    else:\n",
    "        print(f\"\\nðŸ§  Reasoning Steps: (none)\")\n",
    "    \n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Format Data for GRPO Training\n",
    "\n",
    "**GRPO (Group Relative Policy Optimization)** requires data in a specific format:\n",
    "- `prompt`: The input to the model (system + user message)\n",
    "- `answer`: The ground truth for reward calculation\n",
    "\n",
    "**Our Prompt Engineering Strategy:**\n",
    "\n",
    "We instruct the model to follow a 3-step process:\n",
    "1. **Think**: Output reasoning in `<think>` tags\n",
    "2. **Calculate**: Generate Python code if math is needed  \n",
    "3. **Answer**: Output final answer in `<answer>` tags\n",
    "\n",
    "This structure enables:\n",
    "- Clear separation of reasoning from final answer\n",
    "- Tool integration (Python REPL) for arithmetic\n",
    "- Reward signals at each stage during GRPO training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data formatting functions defined\n",
      "âœ“ Answer normalization utilities defined\n",
      "âœ“ Steps-to-thinking conversion defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEFINE SYSTEM PROMPT & DATA FORMATTING\n",
    "# ============================================================================\n",
    "\n",
    "# The system prompt that defines our \"Thinking\" architecture\n",
    "# Optimized for DeepSeek-R1-Distill which naturally produces reasoning traces\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert financial analyst with deep expertise in numerical reasoning.\n",
    "\n",
    "Your task is to answer financial questions accurately. Follow this process:\n",
    "\n",
    "1. **THINK**: First, reason through the problem step-by-step in <think> tags.\n",
    "   - Identify the relevant numbers from the context and tables\n",
    "   - State clearly what calculation is needed and why\n",
    "   - Show each step of your reasoning with intermediate results\n",
    "   - Example: \"From the table, revenue in 2022 was $1.5M and in 2023 was $1.8M\"\n",
    "\n",
    "2. **CALCULATE**: If calculation is needed, generate Python code in a code block.\n",
    "   - Use only basic Python (no imports needed beyond math)\n",
    "   - Store the final result in a variable called `result`\n",
    "   - The code will be executed to get the precise answer\n",
    "\n",
    "3. **ANSWER**: Output your final answer in <answer> tags.\n",
    "   - Be concise and precise\n",
    "   - Include units if applicable (%, $, millions, etc.)\n",
    "   - For percentages, output as decimal (e.g., 0.25) or percentage (e.g., 25%)\n",
    "\n",
    "Example:\n",
    "<think>\n",
    "The question asks for the percentage change in revenue from 2022 to 2023.\n",
    "From the context: 2022 revenue = $1,500,000, 2023 revenue = $1,800,000\n",
    "Formula: ((new - old) / old) * 100\n",
    "Step 1: Difference = 1,800,000 - 1,500,000 = 300,000\n",
    "Step 2: Percentage = (300,000 / 1,500,000) * 100 = 20%\n",
    "</think>\n",
    "\n",
    "```python\n",
    "old_value = 1500000\n",
    "new_value = 1800000\n",
    "result = ((new_value - old_value) / old_value) * 100\n",
    "print(f\"{result}%\")\n",
    "```\n",
    "\n",
    "<answer>20%</answer>\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANSWER NORMALIZATION UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def normalize_answer(answer: str) -> tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Normalize an answer string to a numeric value and detect its format.\n",
    "    \n",
    "    Returns:\n",
    "        tuple of (numeric_value, format_type) where format_type is 'percent', 'decimal', or 'number'\n",
    "    \"\"\"\n",
    "    if not answer:\n",
    "        return None, 'unknown'\n",
    "    \n",
    "    answer_str = str(answer).strip().lower()\n",
    "    \n",
    "    # Remove common formatting\n",
    "    answer_str = answer_str.replace(',', '').replace('$', '').replace(' ', '')\n",
    "    \n",
    "    # Detect percentage\n",
    "    is_percent = '%' in answer_str\n",
    "    answer_str = answer_str.replace('%', '')\n",
    "    \n",
    "    try:\n",
    "        value = float(answer_str)\n",
    "        if is_percent:\n",
    "            return value / 100, 'percent'  # Convert to decimal for comparison\n",
    "        elif abs(value) < 1 and '.' in str(answer):\n",
    "            return value, 'decimal'  # Already a decimal like 0.25\n",
    "        else:\n",
    "            return value, 'number'\n",
    "    except ValueError:\n",
    "        return None, 'unknown'\n",
    "\n",
    "def answers_match(pred: str, gold: str, tolerance: float = 0.02) -> bool:\n",
    "    \"\"\"\n",
    "    Check if two answers match, handling different formats.\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted answer\n",
    "        gold: Ground truth answer\n",
    "        tolerance: Relative tolerance for numeric comparison (default 2%)\n",
    "    \n",
    "    Returns:\n",
    "        True if answers match within tolerance\n",
    "    \"\"\"\n",
    "    pred_val, pred_fmt = normalize_answer(pred)\n",
    "    gold_val, gold_fmt = normalize_answer(gold)\n",
    "    \n",
    "    if pred_val is None or gold_val is None:\n",
    "        # Fall back to string comparison\n",
    "        return str(pred).strip().lower() == str(gold).strip().lower()\n",
    "    \n",
    "    # Handle percent vs decimal mismatch (e.g., \"3%\" vs \"0.02676\")\n",
    "    # If gold is small decimal and pred is large, pred might be percentage\n",
    "    if gold_fmt == 'decimal' and pred_fmt == 'percent':\n",
    "        # gold is already decimal, pred was converted from percent\n",
    "        pass  # Both are now in same scale\n",
    "    elif gold_fmt == 'decimal' and pred_fmt == 'number' and abs(pred_val) > 1:\n",
    "        # pred might be percentage without % sign\n",
    "        pred_val = pred_val / 100\n",
    "    \n",
    "    # Compare with tolerance\n",
    "    if gold_val == 0:\n",
    "        return abs(pred_val) < tolerance\n",
    "    \n",
    "    relative_error = abs(pred_val - gold_val) / abs(gold_val)\n",
    "    return relative_error < tolerance\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEPS TO THINKING TRACE CONVERSION\n",
    "# ============================================================================\n",
    "\n",
    "# Operation name mapping for readable traces\n",
    "OP_NAMES = {\n",
    "    'add': 'Addition',\n",
    "    'subtract': 'Subtraction', \n",
    "    'minus': 'Subtraction',\n",
    "    'multiply': 'Multiplication',\n",
    "    'divide': 'Division',\n",
    "    'exp': 'Exponentiation',\n",
    "    'greater': 'Comparison (greater)',\n",
    "    'table_sum': 'Table Sum',\n",
    "    'table_average': 'Table Average',\n",
    "    'table_max': 'Table Max',\n",
    "    'table_min': 'Table Min',\n",
    "}\n",
    "\n",
    "def steps_to_thinking(steps, question: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Convert ConvFinQA calculation steps to a <think> reasoning trace.\n",
    "    \n",
    "    Args:\n",
    "        steps: List of step dicts with 'op', 'arg1', 'arg2', 'res' keys (may be numpy array)\n",
    "        question: The question being answered (for context)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted thinking trace string\n",
    "    \"\"\"\n",
    "    # Convert numpy array to list if needed\n",
    "    if steps is None or (hasattr(steps, '__len__') and len(steps) == 0):\n",
    "        return \"\"\n",
    "    \n",
    "    if hasattr(steps, 'tolist'):\n",
    "        steps = steps.tolist()\n",
    "    elif hasattr(steps, '__iter__') and not isinstance(steps, (str, dict)):\n",
    "        steps = list(steps)\n",
    "    \n",
    "    if not steps:\n",
    "        return \"\"\n",
    "    \n",
    "    thinking_lines = []\n",
    "    \n",
    "    if question:\n",
    "        thinking_lines.append(f\"To answer this question, I need to perform the following calculations:\")\n",
    "    \n",
    "    for i, step in enumerate(steps):\n",
    "        if not isinstance(step, dict):\n",
    "            continue\n",
    "            \n",
    "        op = step.get('op', 'unknown')\n",
    "        arg1 = step.get('arg1', '?')\n",
    "        arg2 = step.get('arg2', '?')\n",
    "        res = step.get('res', '?')\n",
    "        \n",
    "        # Extract operation type from op string (e.g., \"divide1-1\" -> \"divide\")\n",
    "        op_base = ''.join(c for c in str(op) if c.isalpha()).lower()\n",
    "        op_name = OP_NAMES.get(op_base, op_base.capitalize())\n",
    "        \n",
    "        # Handle references to previous results (e.g., \"#0\" refers to step 0 result)\n",
    "        if str(arg1).startswith('#'):\n",
    "            try:\n",
    "                ref_idx = int(str(arg1)[1:])\n",
    "                arg1 = f\"(result from step {ref_idx + 1})\"\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if str(arg2).startswith('#'):\n",
    "            try:\n",
    "                ref_idx = int(str(arg2)[1:])\n",
    "                arg2 = f\"(result from step {ref_idx + 1})\"\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        thinking_lines.append(f\"Step {i + 1}: {op_name}: {arg1} and {arg2} = {res}\")\n",
    "    \n",
    "    if thinking_lines and len(steps) > 0:\n",
    "        last_step = steps[-1]\n",
    "        if isinstance(last_step, dict):\n",
    "            thinking_lines.append(f\"Therefore, the final answer is {last_step.get('res', '?')}\")\n",
    "    \n",
    "    return '\\n'.join(thinking_lines)\n",
    "\n",
    "\n",
    "def format_table_as_text(table) -> str:\n",
    "    \"\"\"\n",
    "    Convert a table (list of lists or numpy array) to a readable text format.\n",
    "    \"\"\"\n",
    "    if table is None or len(table) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to list if numpy array\n",
    "    if hasattr(table, 'tolist'):\n",
    "        table = table.tolist()\n",
    "    else:\n",
    "        table = list(table)\n",
    "    \n",
    "    # Simple text representation\n",
    "    lines = []\n",
    "    for i, row in enumerate(table):\n",
    "        # Convert row to list if needed\n",
    "        if hasattr(row, 'tolist'):\n",
    "            row = row.tolist()\n",
    "        elif hasattr(row, '__iter__') and not isinstance(row, str):\n",
    "            row = list(row)\n",
    "        else:\n",
    "            row = [row]\n",
    "        \n",
    "        if i == 0:\n",
    "            # Header row\n",
    "            lines.append(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")\n",
    "            lines.append(\"|\" + \"|\".join([\"---\"] * len(row)) + \"|\")\n",
    "        else:\n",
    "            lines.append(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def format_for_grpo(row) -> dict:\n",
    "    \"\"\"\n",
    "    Format a single row from MehdiHosseiniMoghadam/ConvFinQA for GRPO training.\n",
    "    \n",
    "    This version uses:\n",
    "    - pre_text, post_text, table for context\n",
    "    - steps to generate thinking traces\n",
    "    - Proper answer normalization\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'prompt', 'answer', 'steps', 'context', 'question', 'thinking_trace'\n",
    "    \"\"\"\n",
    "    # Extract fields from new dataset format\n",
    "    # Note: HuggingFace datasets may store lists as numpy arrays\n",
    "    pre_text = row.get(\"pre_text\", [])\n",
    "    post_text = row.get(\"post_text\", [])\n",
    "    table = row.get(\"table\", [])\n",
    "    question = row.get(\"question\", \"\")\n",
    "    answer = row.get(\"answer\", \"\")\n",
    "    steps = row.get(\"steps\", [])\n",
    "    \n",
    "    # Convert numpy arrays to lists if needed\n",
    "    def to_list(val):\n",
    "        if val is None:\n",
    "            return []\n",
    "        if hasattr(val, 'tolist'):  # numpy array\n",
    "            return val.tolist()\n",
    "        if hasattr(val, '__iter__') and not isinstance(val, (str, dict)):\n",
    "            return list(val)\n",
    "        return val\n",
    "    \n",
    "    pre_text = to_list(pre_text)\n",
    "    post_text = to_list(post_text)\n",
    "    table = to_list(table)\n",
    "    steps = to_list(steps)\n",
    "    \n",
    "    # Build context from pre_text, table, and post_text\n",
    "    context_parts = []\n",
    "    \n",
    "    if pre_text and len(pre_text) > 0:\n",
    "        pre_text_str = ' '.join(str(item) for item in pre_text)\n",
    "        context_parts.append(pre_text_str)\n",
    "    \n",
    "    if table and len(table) > 0:\n",
    "        table_text = format_table_as_text(table)\n",
    "        context_parts.append(f\"\\n**Financial Data Table:**\\n{table_text}\")\n",
    "    \n",
    "    if post_text and len(post_text) > 0:\n",
    "        post_text_str = ' '.join(str(item) for item in post_text)\n",
    "        context_parts.append(post_text_str)\n",
    "    \n",
    "    context = '\\n\\n'.join(context_parts)\n",
    "    \n",
    "    # Generate thinking trace from steps (for PRM training signal)\n",
    "    thinking_trace = steps_to_thinking(steps, question)\n",
    "    \n",
    "    # Construct the user prompt\n",
    "    user_content = f\"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        \"answer\": str(answer),\n",
    "        \"steps\": steps,  # Keep steps for PRM reward calculation\n",
    "        \"context\": context,\n",
    "        \"question\": question,\n",
    "        \"thinking_trace\": thinking_trace,  # Gold standard thinking for reference\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Data formatting functions defined\")\n",
    "print(\"âœ“ Answer normalization utilities defined\")\n",
    "print(\"âœ“ Steps-to-thinking conversion defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset for GRPO training...\n",
      "\n",
      "âœ“ Dataset processed\n",
      "  Total processed samples: 3,037\n",
      "  Columns: ['prompt', 'answer', 'steps', 'context', 'question', 'thinking_trace']\n",
      "\n",
      "âœ“ Train/Eval split complete (random seed: 42)\n",
      "  Evaluation samples: 20 (randomly selected, excluded from training)\n",
      "  Training samples: 3,017\n",
      "  Evaluation indices: [2619, 456, 102, 1126, 1003]...\n",
      "\n",
      "================================================================================\n",
      "FORMATTED SAMPLE (from training set)\n",
      "================================================================================\n",
      "System Prompt (first 200 chars): You are an expert financial analyst with deep expertise in numerical reasoning.\n",
      "\n",
      "Your task is to answer financial questions accurately. Follow this process:\n",
      "\n",
      "1. **THINK**: First, reason through the pr...\n",
      "\n",
      "User Prompt (first 400 chars): Context:\n",
      "26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 . all revenue components within the segment experienced growth during fiscal 2008 . license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced s...\n",
      "\n",
      "Ground Truth Answer: 14.1%\n",
      "\n",
      "ðŸ§  Reasoning Steps from dataset:\n",
      "  Step 1: minus2-1(206588, 181001) = 25587\n",
      "  Step 2: divide2-2(#0, 181001) = 14.1%\n",
      "\n",
      "ðŸ’­ Generated Thinking Trace:\n",
      "To answer this question, I need to perform the following calculations:\n",
      "Step 1: Subtraction: 206588 and 181001 = 25587\n",
      "Step 2: Division: (result from step 1) and 181001 = 14.1%\n",
      "Therefore, the final answer is 14.1%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PROCESS DATASET\n",
    "# ============================================================================\n",
    "import random\n",
    "\n",
    "print(\"Processing dataset for GRPO training...\")\n",
    "\n",
    "# Convert to pandas for easier row-wise operations\n",
    "df_pandas = df.to_pandas()\n",
    "\n",
    "# Apply formatting to each row\n",
    "processed_data = []\n",
    "for idx, row in df_pandas.iterrows():\n",
    "    try:\n",
    "        formatted = format_for_grpo(row)\n",
    "        processed_data.append(formatted)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Skipped row {idx} due to error: {e}\")\n",
    "\n",
    "# Create processed DataFrame\n",
    "processed_df = pd.DataFrame(processed_data)\n",
    "\n",
    "print(f\"\\nâœ“ Dataset processed\")\n",
    "print(f\"  Total processed samples: {len(processed_df):,}\")\n",
    "print(f\"  Columns: {list(processed_df.columns)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SPLIT INTO TRAINING AND EVALUATION SETS\n",
    "# ============================================================================\n",
    "# Randomly sample evaluation questions - these will NOT be used for training\n",
    "random.seed(config.RANDOM_SEED)\n",
    "all_indices = list(range(len(processed_df)))\n",
    "eval_indices = random.sample(all_indices, min(config.EVALUATION_SAMPLES, len(processed_df)))\n",
    "train_indices = [i for i in all_indices if i not in eval_indices]\n",
    "\n",
    "# Create evaluation dataset (randomly sampled, excluded from training)\n",
    "evaluation_df = processed_df.iloc[eval_indices].copy().reset_index(drop=True)\n",
    "\n",
    "# Create training dataset (excludes evaluation samples)\n",
    "training_df = processed_df.iloc[train_indices].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ“ Train/Eval split complete (random seed: {config.RANDOM_SEED})\")\n",
    "print(f\"  Evaluation samples: {len(evaluation_df):,} (randomly selected, excluded from training)\")\n",
    "print(f\"  Training samples: {len(training_df):,}\")\n",
    "print(f\"  Evaluation indices: {eval_indices[:5]}{'...' if len(eval_indices) > 5 else ''}\")\n",
    "\n",
    "# Show a formatted sample with the new fields\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FORMATTED SAMPLE (from training set)\")\n",
    "print(\"=\"*80)\n",
    "sample = training_df.iloc[0]\n",
    "print(f\"System Prompt (first 200 chars): {sample['prompt'][0]['content'][:200]}...\")\n",
    "print(f\"\\nUser Prompt (first 400 chars): {sample['prompt'][1]['content'][:400]}...\")\n",
    "print(f\"\\nGround Truth Answer: {sample['answer']}\")\n",
    "\n",
    "# Show reasoning steps and generated thinking trace\n",
    "print(f\"\\nðŸ§  Reasoning Steps from dataset:\")\n",
    "steps = sample.get('steps', [])\n",
    "# Handle numpy arrays and check length properly\n",
    "if steps is not None and hasattr(steps, '__len__') and len(steps) > 0:\n",
    "    steps_list = list(steps) if not isinstance(steps, list) else steps\n",
    "    for i, step in enumerate(steps_list[:5]):  # Show first 5 steps\n",
    "        if isinstance(step, dict):\n",
    "            print(f\"  Step {i+1}: {step.get('op', '?')}({step.get('arg1', '?')}, {step.get('arg2', '?')}) = {step.get('res', '?')}\")\n",
    "    if len(steps_list) > 5:\n",
    "        print(f\"  ... ({len(steps_list) - 5} more steps)\")\n",
    "else:\n",
    "    print(\"  (no steps)\")\n",
    "\n",
    "print(f\"\\nðŸ’­ Generated Thinking Trace:\")\n",
    "thinking = sample.get('thinking_trace', '')\n",
    "if thinking and len(str(thinking)) > 0:\n",
    "    print(str(thinking)[:500] + ('...' if len(str(thinking)) > 500 else ''))\n",
    "else:\n",
    "    print(\"  (no thinking trace generated)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Agent Definition\n",
    "\n",
    "## Functional Design\n",
    "\n",
    "The Financial Analyst Agent follows a **linear workflow** with three stages:\n",
    "\n",
    "1. **Think Node**: Generates reasoning traces and potential Python code\n",
    "2. **Calculate Node**: Extracts and executes Python code if present\n",
    "3. **Finalize Node**: Parses the final answer from model output or tool result\n",
    "\n",
    "## Technical Design\n",
    "\n",
    "**Why LangGraph?**\n",
    "- Provides **stateful** agent execution with clear state transitions\n",
    "- Enables **automatic tracing** via MLflow integration\n",
    "- Supports **tool integration** seamlessly\n",
    "\n",
    "**Python REPL Tool:**\n",
    "- Executes arbitrary Python code for precise calculations\n",
    "- Sandboxed execution with error handling\n",
    "- Captures stdout for use as the calculation result\n",
    "\n",
    "**State Schema:**\n",
    "```\n",
    "AgentState {\n",
    "    query: str           # The financial question\n",
    "    context: str         # Financial document context  \n",
    "    model_output: str    # Raw LLM response\n",
    "    tool_output: str     # Python REPL execution result\n",
    "    final_answer: str    # Parsed final answer\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Python Calculator Tool\n",
    "\n",
    "The Python REPL tool enables the agent to execute calculations precisely. This is critical for financial analysis where small rounding errors can lead to incorrect conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Python Calculator Tool:\n",
      "----------------------------------------\n",
      "Code:\n",
      "\n",
      "revenue_2023 = 1500000\n",
      "revenue_2022 = 1200000\n",
      "growth_rate = ((revenue_2023 - revenue_2022) / revenue_2022) * 100\n",
      "print(f\"Revenue growth: {growth_rate:.2f}%\")\n",
      "\n",
      "\n",
      "Output:\n",
      "Revenue growth: 25.00%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PYTHON CALCULATOR TOOL\n",
    "# ============================================================================\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "# Initialize the Python REPL\n",
    "repl = PythonREPL()\n",
    "\n",
    "def python_calculator(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes Python code to perform financial calculations.\n",
    "    \n",
    "    Args:\n",
    "        code: Python code string to execute\n",
    "        \n",
    "    Returns:\n",
    "        str: The output of the code execution (stdout) or error message\n",
    "        \n",
    "    Security Note:\n",
    "        This executes arbitrary Python code. In production, use a sandboxed\n",
    "        environment or restrict to specific operations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Capture stdout\n",
    "        result = repl.run(code)\n",
    "        return result.strip() if result else \"Code executed successfully (no output)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {str(e)}\"\n",
    "\n",
    "# Test the calculator\n",
    "test_code = \"\"\"\n",
    "revenue_2023 = 1500000\n",
    "revenue_2022 = 1200000\n",
    "growth_rate = ((revenue_2023 - revenue_2022) / revenue_2022) * 100\n",
    "print(f\"Revenue growth: {growth_rate:.2f}%\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing Python Calculator Tool:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Code:\")\n",
    "print(test_code)\n",
    "print(\"\\nOutput:\")\n",
    "print(python_calculator(test_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define Agent State & Graph\n",
    "\n",
    "The LangGraph state machine orchestrates the agent's workflow. Each node receives the current state and returns updates to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ AgentState TypedDict defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT STATE DEFINITION\n",
    "# ============================================================================\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    State schema for the Financial Reasoning Agent.\n",
    "    \n",
    "    This state is passed between nodes and updated at each step.\n",
    "    MLflow traces capture the state at each transition.\n",
    "    \"\"\"\n",
    "    query: str              # The financial question being asked\n",
    "    context: str            # Financial document context\n",
    "    model_output: str       # Raw output from the LLM\n",
    "    tool_output: str        # Result from Python REPL execution\n",
    "    final_answer: str       # The parsed final answer\n",
    "    thinking: str           # Extracted reasoning trace\n",
    "    code_generated: str     # Extracted Python code (if any)\n",
    "\n",
    "print(\"âœ“ AgentState TypedDict defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent factory function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGENT FACTORY FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def build_financial_agent(llm_engine, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Builds a LangGraph agent for financial reasoning.\n",
    "    \n",
    "    This is a factory function that creates an agent wrapping any LLM engine\n",
    "    that implements a `generate(prompt: str) -> str` interface. This allows\n",
    "    us to use the same agent structure with both the base and fine-tuned models.\n",
    "    \n",
    "    Args:\n",
    "        llm_engine: An object with a `generate(prompt: str) -> str` method\n",
    "        verbose: Whether to print progress during execution\n",
    "        \n",
    "    Returns:\n",
    "        Compiled LangGraph workflow ready for invocation\n",
    "    \"\"\"\n",
    "    \n",
    "    def think_node(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Node 1: Generate reasoning and potential code.\n",
    "        \n",
    "        This node:\n",
    "        1. Constructs the prompt from context and query\n",
    "        2. Calls the LLM to generate thinking + code + answer\n",
    "        3. Extracts the thinking trace for logging\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"  â”œâ”€ ðŸ§  [Think] Generating reasoning...\")\n",
    "        \n",
    "        # Construct the full prompt\n",
    "        prompt = f\"{SYSTEM_PROMPT}\\n\\nContext: {state['context']}\\n\\nQuestion: {state['query']}\"\n",
    "        \n",
    "        # Generate response from the LLM\n",
    "        response = llm_engine.generate(prompt)\n",
    "        \n",
    "        # Extract thinking trace if present\n",
    "        think_match = re.search(r\"<think>(.*?)</think>\", response, re.DOTALL)\n",
    "        thinking = think_match.group(1).strip() if think_match else \"\"\n",
    "        \n",
    "        if verbose and thinking:\n",
    "            print(f\"  â”‚    â””â”€ Reasoning: {thinking[:100]}...\")\n",
    "        \n",
    "        return {\n",
    "            \"model_output\": response,\n",
    "            \"thinking\": thinking\n",
    "        }\n",
    "    \n",
    "    def calculate_node(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Node 2: Extract and execute Python code if present.\n",
    "        \n",
    "        This node:\n",
    "        1. Searches for Python code blocks in the model output\n",
    "        2. Executes the code using the Python REPL tool\n",
    "        3. Captures the output for use in the final answer\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\")\n",
    "        \n",
    "        model_output = state[\"model_output\"]\n",
    "        \n",
    "        # Extract Python code from markdown code blocks\n",
    "        code_match = re.search(r\"```python(.*?)```\", model_output, re.DOTALL)\n",
    "        \n",
    "        if code_match:\n",
    "            code = code_match.group(1).strip()\n",
    "            if verbose:\n",
    "                print(f\"  â”‚    â”œâ”€ Found code: {code[:80]}...\")\n",
    "            \n",
    "            # Execute the code\n",
    "            result = python_calculator(code)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  â”‚    â””â”€ Result: {result}\")\n",
    "            \n",
    "            return {\n",
    "                \"tool_output\": result,\n",
    "                \"code_generated\": code\n",
    "            }\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  â”‚    â””â”€ No code found, skipping calculation\")\n",
    "            return {\n",
    "                \"tool_output\": \"No code executed.\",\n",
    "                \"code_generated\": \"\"\n",
    "            }\n",
    "    \n",
    "    def finalize_node(state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        Node 3: Extract and finalize the answer.\n",
    "        \n",
    "        This node:\n",
    "        1. If tool was used successfully, uses tool output as answer\n",
    "        2. Otherwise, parses <answer> tags from model output\n",
    "        3. Falls back to the raw model output if no tags found\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"  â”œâ”€ âœ… [Finalize] Extracting final answer...\")\n",
    "        \n",
    "        tool_output = state[\"tool_output\"]\n",
    "        model_output = state[\"model_output\"]\n",
    "        \n",
    "        # Priority 1: Use tool output if code was executed successfully\n",
    "        if tool_output and tool_output != \"No code executed.\" and not tool_output.startswith(\"Error\"):\n",
    "            final_answer = tool_output\n",
    "            if verbose:\n",
    "                print(f\"  â”‚    â””â”€ Using tool output: {final_answer}\")\n",
    "            return {\"final_answer\": final_answer}\n",
    "        \n",
    "        # Priority 2: Parse <answer> tags\n",
    "        answer_match = re.search(r\"<answer>(.*?)</answer>\", model_output, re.DOTALL)\n",
    "        if answer_match:\n",
    "            final_answer = answer_match.group(1).strip()\n",
    "            if verbose:\n",
    "                print(f\"  â”‚    â””â”€ Parsed from tags: {final_answer}\")\n",
    "            return {\"final_answer\": final_answer}\n",
    "        \n",
    "        # Fallback: Try to extract any number from the response\n",
    "        numbers = re.findall(r\"-?\\d+\\.?\\d*%?\", model_output)\n",
    "        if numbers:\n",
    "            final_answer = numbers[-1]  # Take the last number as likely the answer\n",
    "            if verbose:\n",
    "                print(f\"  â”‚    â””â”€ Extracted number: {final_answer}\")\n",
    "            return {\"final_answer\": final_answer}\n",
    "        \n",
    "        # Last resort: return N/A\n",
    "        if verbose:\n",
    "            print(\"  â”‚    â””â”€ Could not extract answer, returning N/A\")\n",
    "        return {\"final_answer\": \"N/A\"}\n",
    "    \n",
    "    # =========================================================================\n",
    "    # BUILD THE GRAPH\n",
    "    # =========================================================================\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"think\", think_node)\n",
    "    workflow.add_node(\"calculate\", calculate_node)\n",
    "    workflow.add_node(\"finalize\", finalize_node)\n",
    "    \n",
    "    # Define edges (linear flow)\n",
    "    workflow.add_edge(START, \"think\")\n",
    "    workflow.add_edge(\"think\", \"calculate\")\n",
    "    workflow.add_edge(\"calculate\", \"finalize\")\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Compile and return\n",
    "    return workflow.compile()\n",
    "\n",
    "print(\"âœ“ Agent factory function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Base Model Evaluation\n",
    "\n",
    "## Functional Design\n",
    "\n",
    "Before fine-tuning, we establish a **baseline** by evaluating the agent with the base model:\n",
    "- Load the Qwen3-4B model using Unsloth for efficient inference\n",
    "- Wrap the model to match our agent's interface\n",
    "- Run evaluation on a sample of validation questions\n",
    "- Log all traces and results to MLflow\n",
    "\n",
    "## Technical Design\n",
    "\n",
    "**Unsloth Advantages:**\n",
    "- **2x faster inference** through optimized kernels\n",
    "- **4-bit quantization** reduces memory footprint by 4x\n",
    "- **vLLM integration** for high-throughput generation\n",
    "- **Direct GRPO support** for seamless training\n",
    "\n",
    "**MLflow Tracing:**\n",
    "- Each agent invocation creates a trace with all node executions\n",
    "- Traces include: input state, LLM calls, tool calls, output state\n",
    "- Viewable in MLflow UI under the experiment's \"Traces\" tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load Base Model with Unsloth + LoRA Adapters\n",
    "\n",
    "We use **DeepSeek-R1-Distill-Qwen-7B** - a model distilled from DeepSeek's reasoning-focused R1 model. This model excels at:\n",
    "- **Chain-of-thought reasoning**: Naturally produces step-by-step thinking\n",
    "- **Mathematical calculations**: Strong performance on numerical tasks\n",
    "- **Instruction following**: Well-aligned for structured output formats\n",
    "\n",
    "**Unsloth Optimizations:**\n",
    "- 4-bit quantization to reduce memory usage (~4GB VRAM)\n",
    "- Fast inference mode optimizations\n",
    "- Efficient LoRA training with gradient checkpointing\n",
    "\n",
    "**LoRA Adapters:** When using quantized models (4-bit), you cannot fine-tune the quantized weights directly. We add **LoRA (Low-Rank Adaptation)** adapters - small trainable matrices that learn task-specific adaptations on top of the frozen base model. Key parameters:\n",
    "- `r=16`: Rank of the LoRA matrices (higher = more capacity but slower)\n",
    "- `lora_alpha=16`: Scaling factor (Unsloth uses same as r)\n",
    "- `target_modules`: Attention (q/k/v/o_proj) and MLP (gate/up/down_proj) layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading base model with Unsloth...\n",
      "  Model: unsloth/DeepSeek-R1-Distill-Qwen-7B\n",
      "  Max Seq Length: 8192\n",
      "  4-bit Quantization: True\n",
      "==((====))==  Unsloth 2025.12.9: Fast Qwen2 patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GB10. Num GPUs = 1. Max memory: 119.635 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0a0+b558c986e8.nv25.11. CUDA: 12.1. CUDA Toolkit: 13.0. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d417413dac914ccf977158e77bcd0bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc0a53a88ba4815a4976ee46e7eb34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad07d3972ba94feba0e37db1e84a96fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4624577d014af0bdae4da420a665e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad692806d0e4083ad526e5e4661fe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d6b30f85e8479bac8f7782617c7165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d45e7f6ae6486e9ef99327e00e30ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b740ccf6f9e4dfd9d0a0a99ce7a7f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96623ba990a94eee9ae967eb075e5fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Model loaded successfully\n",
      "  Model type: Qwen2ForCausalLM\n",
      "  Tokenizer: LlamaTokenizerFast\n",
      "\n",
      "Configuring LoRA adapters for fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.12.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ LoRA adapters configured\n",
      "  LoRA rank (r): 16\n",
      "  LoRA alpha: 16\n",
      "  LoRA dropout: 0\n",
      "  Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj\n",
      "  Gradient checkpointing: unsloth (memory optimized)\n",
      "\n",
      "ðŸ“Š Parameter efficiency:\n",
      "  Trainable parameters: 40,370,176\n",
      "  Total parameters: 5,383,329,280\n",
      "  Trainable %: 0.75%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD BASE MODEL WITH UNSLOTH + CONFIGURE LORA ADAPTERS\n",
    "# ============================================================================\n",
    "# Following the Unsloth GRPO example:\n",
    "# https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "print(\"Loading base model with Unsloth...\")\n",
    "print(f\"  Model: {config.MODEL_NAME}\")\n",
    "print(f\"  Max Seq Length: {config.MAX_SEQ_LENGTH}\")\n",
    "print(f\"  4-bit Quantization: {config.LOAD_IN_4BIT}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    config.MODEL_NAME,\n",
    "    max_seq_length=config.MAX_SEQ_LENGTH,\n",
    "    load_in_4bit=config.LOAD_IN_4BIT,\n",
    "    fast_inference=False,\n",
    "    gpu_memory_utilization=config.GPU_MEMORY_UTILIZATION,\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Model loaded successfully\")\n",
    "print(f\"  Model type: {type(model).__name__}\")\n",
    "print(f\"  Tokenizer: {type(tokenizer).__name__}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURE LORA ADAPTERS FOR TRAINING\n",
    "# ============================================================================\n",
    "# Add LoRA adapters to the quantized model for efficient fine-tuning\n",
    "# This is REQUIRED when using 4-bit quantized models\n",
    "\n",
    "print(\"\\nConfiguring LoRA adapters for fine-tuning...\")\n",
    "\n",
    "# LoRA configuration (following Unsloth recommendations)\n",
    "LORA_R = 16              # LoRA rank\n",
    "LORA_ALPHA = 16          # LoRA scaling factor (Unsloth uses same as r)\n",
    "LORA_DROPOUT = 0         # Unsloth is optimized for no dropout\n",
    "\n",
    "# Get the model with LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention layers\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",      # MLP layers\n",
    "    ],\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Memory-efficient gradient checkpointing\n",
    "    random_state=config.RANDOM_SEED,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ LoRA adapters configured\")\n",
    "print(f\"  LoRA rank (r): {LORA_R}\")\n",
    "print(f\"  LoRA alpha: {LORA_ALPHA}\")\n",
    "print(f\"  LoRA dropout: {LORA_DROPOUT}\")\n",
    "print(f\"  Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj\")\n",
    "print(f\"  Gradient checkpointing: unsloth (memory optimized)\")\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_pct = 100 * trainable_params / total_params\n",
    "\n",
    "print(f\"\\nðŸ“Š Parameter efficiency:\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable %: {trainable_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model Wrapper for Agent Integration\n",
    "\n",
    "We create a simple wrapper class that provides a `generate()` interface compatible with our agent. This abstraction allows us to swap models (base vs. tuned) without changing the agent code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model wrapper created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL WRAPPER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class UnslothModelWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper class that provides a simple generate() interface for the agent.\n",
    "    \n",
    "    This allows the same agent structure to work with both:\n",
    "    - The base model (before fine-tuning)\n",
    "    - The fine-tuned model (after GRPO training)\n",
    "    \n",
    "    The wrapper handles tokenization, generation, and decoding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, max_new_tokens: int = 1024):\n",
    "        \"\"\"\n",
    "        Initialize the wrapper.\n",
    "        \n",
    "        Args:\n",
    "            model: The Unsloth/HuggingFace model\n",
    "            tokenizer: The associated tokenizer\n",
    "            max_new_tokens: Maximum tokens to generate\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a response for the given prompt.\n",
    "        \n",
    "        Args:\n",
    "            prompt: The input prompt string\n",
    "            \n",
    "        Returns:\n",
    "            str: The generated response (excluding the prompt)\n",
    "        \"\"\"\n",
    "        # Tokenize the input\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=config.MAX_SEQ_LENGTH - self.max_new_tokens\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Generate\n",
    "        with mlflow.start_span(name=\"llm_generate\") as span:\n",
    "            span.set_inputs({\"prompt_length\": len(prompt)})\n",
    "            \n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "            \n",
    "            # Decode the output\n",
    "            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Remove the prompt from the response\n",
    "            response = full_response[len(prompt):].strip()\n",
    "            \n",
    "            span.set_outputs({\"response_length\": len(response)})\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Create wrapper for the base model\n",
    "base_engine = UnslothModelWrapper(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=config.MAX_NEW_TOKENS\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model wrapper created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Run Baseline Evaluation\n",
    "\n",
    "We evaluate the base model on a sample of validation questions. Each agent invocation is traced by MLflow, allowing us to:\n",
    "- View the full execution path in the MLflow UI\n",
    "- Analyze where the agent succeeds or fails\n",
    "- Compare with the fine-tuned model later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Base agent built\n",
      "âœ“ Evaluation sample: 20 questions (randomly sampled, excluded from training)\n",
      "\n",
      "================================================================================\n",
      "BASELINE EVALUATION (Base Model)\n",
      "================================================================================\n",
      "Evaluating on 20 randomly selected questions\n",
      "Random seed: 42\n",
      "\n",
      "================================================================================\n",
      "QUESTION 1/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent change in net expense in interest and penalties between 2008 and 2009?\n",
      "\n",
      "âœ… Ground Truth: -36%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 2/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage reduction in the segment 2019s backlog from 2006 to 2007\n",
      "\n",
      "âœ… Ground Truth: -18.8%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 14:12:06 WARNING mlflow.tracing.export.mlflow_v3: Failed to send trace to MLflow backend: Yaml file '/workspace/notebooks/agents/mlruns/425390645702784385/traces/tr-b38a088ca65ed389b74d0fb132e70629/trace_info.yaml' exists as '/workspace/notebooks/agents/mlruns/425390645702784385/traces/tr-b38a088ca65ed389b74d0fb132e70629/trace_info.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_backlog = 3200000000\n",
      "new_backlog = 2600000000\n",
      "result = ((old_backlog - new_b...\n",
      "  â”‚    â””â”€ Result: 18.75%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 18.75%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_backlog = 3200000000\n",
      "new_backlog = 2600000000\n",
      "result = ((old_backlog - new_backlog) / old_backlog) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 18.75%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 3/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage difference in the number of shares to be issued if the stock price closes at $ 11 compared to if it closes at $ 20?\n",
      "\n",
      "âœ… Ground Truth: 278%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 4/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage decrease from 2007 for 2009 for the cmg balance?\n",
      "\n",
      "âœ… Ground Truth: 1.47%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 5/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in cash from operations between 2008 and 2009?\n",
      "\n",
      "âœ… Ground Truth: 35%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 6/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 142.5  # 2006 total interest costs\n",
      "new_value = 155.8  # 2007 total i...\n",
      "  â”‚    â””â”€ Result: 9.333333333333341%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 9.333333333333341%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 142.5  # 2006 total interest costs\n",
      "new_value = 155.8  # 2007 total interest costs\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 9.333333333333341%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 7/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in earnings per share from 2005 to 2006?\n",
      "\n",
      "âœ… Ground Truth: 22%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_eps = 3.49\n",
      "new_eps = 4.27\n",
      "result = ((new_eps - old_eps) / old_eps) * 100\n",
      "pri...\n",
      "  â”‚    â””â”€ Result: 22.349570200573048%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 22.349570200573048%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_eps = 3.49\n",
      "new_eps = 4.27\n",
      "result = ((new_eps - old_eps) / old_eps) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 22.349570200573048%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 8/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much did the quarterly dividend yield change from 2010 to 2012 for applied materials?\n",
      "\n",
      "âœ… Ground Truth: the dividend yield increased 0.04% from 2010 to 2012\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 9/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent of the increase in the operating income from 2010 to 2011\n",
      "\n",
      "âœ… Ground Truth: 10.1%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 10/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what percent of the net change in revenue between 2007 and 2008 was due to volume/weather?\n",
      "\n",
      "âœ… Ground Truth: 76.5%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 14:12:18 WARNING mlflow.tracing.export.mlflow_v3: Failed to send trace to MLflow backend: Yaml file '/workspace/notebooks/agents/mlruns/425390645702784385/traces/tr-2369b584ff5e9ff0ff50bde4382567b8/trace_info.yaml' exists as '/workspace/notebooks/agents/mlruns/425390645702784385/traces/tr-2369b584ff5e9ff0ff50bde4382567b8/trace_info.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 11/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in gross unpaid losses from 2008 to 2009?\n",
      "\n",
      "âœ… Ground Truth: 1.63%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 37112000\n",
      "new_value = 37176000\n",
      "result = ((new_value - old_value) / ol...\n",
      "  â”‚    â””â”€ Result: 0.1725%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 0.1725%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 37112000\n",
      "new_value = 37176000\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result:.4f}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 0.1725%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 12/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the net tax expense for the 3 years ended 2005 related to the change in financial derivatives ( in millions? )\n",
      "\n",
      "âœ… Ground Truth: -8.2\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 13/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in total operating expenses in 2012?\n",
      "\n",
      "âœ… Ground Truth: 1.4%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 14/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much has cash equivalents and marketable securities decreased from 2014 to 2016?\n",
      "\n",
      "âœ… Ground Truth: 33.9% decrease\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 15/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage increase in the property and equipment net from 2004 to 2005\n",
      "\n",
      "âœ… Ground Truth: 52.2%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: # Extract property and equipment net for 2004 and 2005\n",
      "prop_eq_2004 = 2273356\n",
      "pr...\n",
      "  â”‚    â””â”€ Result: 52.221033573272294%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 52.221033573272294%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "# Extract property and equipment net for 2004 and 2005\n",
      "prop_eq_2004 = 2273356\n",
      "prop_eq_2005 = 3460526\n",
      "\n",
      "# Calculate the percentage increase\n",
      "percentage_increase = ((prop_eq_2005 - prop_eq_2004) / prop_eq_2004) * 100\n",
      "print(f\"{percentage_increase}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 52.221033573272294%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 16/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Parsed from tags: 9.63\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 9.63\n",
      "\n",
      "================================================================================\n",
      "QUESTION 17/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the net income margin for 2018?\n",
      "\n",
      "âœ… Ground Truth: 3.3%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 18/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the total intrinsic value of options exercised during 2007 , 2006 and 2005 in millions?\n",
      "\n",
      "âœ… Ground Truth: 194\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Extracted number: 31\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 31\n",
      "\n",
      "================================================================================\n",
      "QUESTION 19/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Extracted number: 40%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 40%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 20/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage total return for delphi automotive plc for the three years ended december 31 2013?\\\\n\n",
      "\n",
      "âœ… Ground Truth: 185.81%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: initial_investment = 100.00\n",
      "final_value = 285.81\n",
      "result = ((final_value - initia...\n",
      "  â”‚    â””â”€ Result: 185.81%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 185.81%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "initial_investment = 100.00\n",
      "final_value = 285.81\n",
      "result = ((final_value - initial_investment) / initial_investment) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 185.81%\n",
      "\n",
      "================================================================================\n",
      "âœ“ Baseline evaluation complete\n",
      "================================================================================\n",
      "  Total time: 100.01s\n",
      "  Avg per question: 5.00s\n",
      "  Run ID: cfcfd5e0123f4945b496b9724a1ccb61\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BUILD BASE AGENT & RUN BASELINE EVALUATION\n",
    "# ============================================================================\n",
    "import time\n",
    "\n",
    "# Build the agent with the base model\n",
    "base_agent = build_financial_agent(base_engine, verbose=True)\n",
    "print(\"âœ“ Base agent built\")\n",
    "\n",
    "# Use the randomly sampled evaluation dataset (excluded from training)\n",
    "evaluation_sample = evaluation_df.copy()\n",
    "print(f\"âœ“ Evaluation sample: {len(evaluation_sample)} questions (randomly sampled, excluded from training)\")\n",
    "\n",
    "# Run baseline evaluation with MLflow tracking\n",
    "baseline_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE EVALUATION (Base Model)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Evaluating on {len(evaluation_sample)} randomly selected questions\")\n",
    "print(f\"Random seed: {config.RANDOM_SEED}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Base_Model_Eval\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": config.MODEL_NAME,\n",
    "        \"model_type\": \"base\",\n",
    "        \"evaluation_samples\": len(evaluation_sample),\n",
    "        \"max_new_tokens\": config.MAX_NEW_TOKENS,\n",
    "        \"random_seed\": config.RANDOM_SEED,\n",
    "    })\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, row in evaluation_sample.iterrows():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"QUESTION {idx + 1}/{len(evaluation_sample)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\\nðŸ“‹ Question:\\n{row['question']}\")\n",
    "        print(f\"\\nâœ… Ground Truth: {row['answer']}\")\n",
    "        \n",
    "        try:\n",
    "            # Invoke the agent (MLflow autologs the trace)\n",
    "            result = base_agent.invoke({\n",
    "                \"query\": row['question'],\n",
    "                \"context\": row['context'],\n",
    "                \"model_output\": \"\",\n",
    "                \"tool_output\": \"\",\n",
    "                \"final_answer\": \"\",\n",
    "                \"thinking\": \"\",\n",
    "                \"code_generated\": \"\",\n",
    "            })\n",
    "            \n",
    "            agent_answer = result.get('final_answer', 'N/A')\n",
    "            thinking = result.get('thinking', '')\n",
    "            code_generated = result.get('code_generated', '')\n",
    "            \n",
    "            # Print full output (no truncation)\n",
    "            print(f\"\\nðŸ§  Thinking:\\n{thinking if thinking else '(none)'}\")\n",
    "            print(f\"\\nðŸ’» Code Generated:\\n{code_generated if code_generated else '(none)'}\")\n",
    "            print(f\"\\nðŸ¤– Agent Answer: {agent_answer}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error: {e}\")\n",
    "            agent_answer = f\"Error: {str(e)}\"\n",
    "            thinking = \"\"\n",
    "            code_generated = \"\"\n",
    "            result = {\"final_answer\": agent_answer}\n",
    "        \n",
    "        # Store full results (no truncation)\n",
    "        baseline_results.append({\n",
    "            \"question\": row['question'],\n",
    "            \"context\": row['context'],\n",
    "            \"ground_truth\": row['answer'],\n",
    "            \"agent_answer\": agent_answer,\n",
    "            \"thinking\": thinking,\n",
    "            \"code_generated\": code_generated,\n",
    "        })\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Add results to evaluation sample\n",
    "    evaluation_sample['base_agent_answer'] = [r['agent_answer'] for r in baseline_results]\n",
    "    evaluation_sample['base_thinking'] = [r['thinking'] for r in baseline_results]\n",
    "    evaluation_sample['base_code'] = [r['code_generated'] for r in baseline_results]\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"total_time_seconds\", elapsed_time)\n",
    "    mlflow.log_metric(\"avg_time_per_question\", elapsed_time / len(evaluation_sample))\n",
    "    \n",
    "    # Log the results table as artifact\n",
    "    mlflow.log_table(\n",
    "        data=pd.DataFrame(baseline_results),\n",
    "        artifact_file=\"baseline_results.json\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ“ Baseline evaluation complete\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Total time: {elapsed_time:.2f}s\")\n",
    "    print(f\"  Avg per question: {elapsed_time / len(evaluation_sample):.2f}s\")\n",
    "    print(f\"  Run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Define LLM-as-Judge Metrics & Run Baseline Evaluation\n",
    "\n",
    "We use **MLflow's `make_judge` API** to create template-based LLM scorers. These metrics are defined **once** here and reused for both baseline and tuned model evaluation.\n",
    "\n",
    "The cell below:\n",
    "1. Defines the `evaluate_response()` function with three judge metrics\n",
    "2. Runs LLM-as-Judge evaluation on baseline outputs (enabling comparison with tuned model later)\n",
    "\n",
    "**Metrics Evaluated:**\n",
    "- **Answer Score**: How well does the answer match ground truth?\n",
    "- **Reasoning Score**: Quality of thinking process in `<think>` tags\n",
    "- **Code Score**: Correctness of any generated Python code\n",
    "\n",
    "**Reference:** [MLflow make_judge Documentation](https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/make-judge/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Gemini API key configured for MLflow make_judge\n",
      "âœ“ MLflow template-based LLM Scorers (make_judge) configured\n",
      "  Model: gemini/gemini-2.5-pro\n",
      "  Judges defined:\n",
      "    - answer_quality_judge\n",
      "    - reasoning_quality_judge\n",
      "    - code_correctness_judge (N/A when no tool calling)\n",
      "  Function: evaluate_response() - reusable for any evaluation\n",
      "================================================================================\n",
      "LLM-AS-JUDGE EVALUATION (Baseline Model)\n",
      "================================================================================\n",
      "Using MLflow make_judge with model: gemini/gemini-2.5-pro\n",
      "\n",
      "Evaluating 20 baseline responses with LLM-as-Judge...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[1/20] QUESTION:\n",
      "what was the percent change in net expense in interest and penalties between 2008 and 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -36%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, which is incorrect. The expected answer is a numerical value (-36%), indicating that the necessary data to perform the calculation was available. The agent failed to answer the question entirely.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent failed to provide any thinking process or an answer to the question. It simply returned 'N/A' without any explanation or attempt to solve the problem. This is a complete failure to address the user's query.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[2/20] QUESTION:\n",
      "what was the percentage reduction in the segment 2019s backlog from 2006 to 2007\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -18.8%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 18.75%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_backlog = 3200000000\n",
      "new_backlog = 2600000000\n",
      "result = ((old_backlog - new_backlog) / old_backlog) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    4/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is numerically very close to the expected answer (18.75% vs. 18.8%). The difference is likely due to rounding. However, the question asks for a 'percentage reduction,' and the expected answer correctly represents this with a negative sign. The agent's positive value is less precise in this context, making the answer good but not excellent.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided a final answer but completely failed to show its thinking process. The evaluation is focused on the quality of the reasoning, and since no reasoning was provided, it is impossible to assess the clarity, logic, or mathematical steps taken. This is a critical failure as the core component for evaluation is missing.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The Python code is syntactically correct and will run without errors. It correctly implements the standard formula for percentage reduction: ((initial value - final value) / initial value) * 100. The variable names `old_backlog` and `new_backlog` are clear and descriptive. The calculation is performed accurately, yielding the correct result of 18.75%.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[3/20] QUESTION:\n",
      "what is the percentage difference in the number of shares to be issued if the stock price closes at $ 11 compared to if it closes at $ 20?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 278%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, which means it completely failed to address the user's question. The question requires a numerical calculation, and the agent did not attempt to provide one. This is an incorrect and unhelpful response.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent failed to provide any thinking process or an answer. The thinking process is empty and the final answer is 'N/A', indicating a complete failure to address the user's question.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[4/20] QUESTION:\n",
      "what was the percentage decrease from 2007 for 2009 for the cmg balance?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.47%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent did not answer the question and instead returned 'N/A'. The expected answer was a specific numerical value (1.47%). The agent failed to perform the required calculation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent failed to answer the question, providing 'N/A' as the response. There is no thinking process provided, which means it's impossible to evaluate its reasoning, identification of numbers, or calculation steps. The agent completely failed to address the user's query.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[5/20] QUESTION:\n",
      "what was the percentage change in cash from operations between 2008 and 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 35%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent failed to answer the question, providing 'N/A' instead of the calculated percentage change. The expected answer was '35%'.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and returned 'N/A' as the answer. It completely failed to address the user's question. There is no reasoning to evaluate.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[6/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 9.333333333333341%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 142.5  # 2006 total interest costs\n",
      "new_value = 155.8  # 2007 total interest costs\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    2/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The provided context is incomplete as it lacks both the user's question and the expected answer. The agent's answer is simply a numerical value (9.333333333333341%) without any supporting explanation, calculation steps, or context. For any financial reasoning task, the methodology and justification are as important as the final answer. Without this information, the answer is unverifiable and lacks any educational or practical value. Therefore, it is considered a poor response.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user did not provide any context for the evaluation. The 'Question' and 'Agent's Thinking' fields are both empty. It is impossible to evaluate the agent's reasoning without knowing the question it was trying to answer and the steps it took to arrive at the solution. The submission is incomplete and cannot be assessed.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly implements the standard formula for calculating percentage change: ((new_value - old_value) / old_value) * 100. The variable names 'old_value' and 'new_value' are clear and appropriate for the context. The use of an f-string for printing the final output is a modern and readable approach. The calculation is accurate, and the agent's answer matches the code's output.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[7/20] QUESTION:\n",
      "what was the percentage change in earnings per share from 2005 to 2006?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 22%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 22.349570200573048%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_eps = 3.49\n",
      "new_eps = 4.27\n",
      "result = ((new_eps - old_eps) / old_eps) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is a more precise version of the expected answer. When the agent's answer (22.349...) is rounded to the nearest whole number, it matches the expected answer of 22%. This indicates a correct calculation with a higher degree of precision.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent's thinking process is completely missing. The evaluation requires assessing the clarity of thinking, identification of numbers/formulas, logical breakdown, and mathematical reasoning. Without the step-by-step thinking process, none of these criteria can be evaluated. The agent only provided a final numerical answer, which is insufficient and unverifiable without the underlying data and logic.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly implements the standard formula for percentage change: ((New Value - Old Value) / Old Value) * 100. The variable names `old_eps` and `new_eps` are clear and appropriate for the context of 'earnings per share'. The final output correctly calculates and displays the result.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[8/20] QUESTION:\n",
      "how much did the quarterly dividend yield change from 2010 to 2012 for applied materials?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: the dividend yield increased 0.04% from 2010 to 2012\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is N/A, which means that it did not answer the question. The dividend yield for Applied Materials increased by 0.04% from 2010 to 2012. The agent's answer is therefore incorrect.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and an 'N/A' answer. It completely failed to address the question. There is no reasoning to evaluate, no identification of numbers or formulas, and no logical breakdown. The response is entirely unhelpful.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[9/20] QUESTION:\n",
      "what was the percent of the increase in the operating income from 2010 to 2011\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 10.1%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, which is incorrect. The expected answer is a specific numerical value (10.1%), indicating a failure to process the query and retrieve or calculate the required information.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided 'N/A' as the answer and failed to show any thinking process. It did not identify any relevant numbers or formulas, nor did it attempt to break down the problem. The response completely fails to answer the user's question, indicating an inability to either find the necessary data or perform the calculation.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[10/20] QUESTION:\n",
      "what percent of the net change in revenue between 2007 and 2008 was due to volume/weather?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 76.5%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' and did not answer the question. The expected answer was a specific numerical value, 76.5%. The agent failed to perform the required calculation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process or answer ('N/A'). It completely failed to address the user's question. Therefore, there is no reasoning to evaluate.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[11/20] QUESTION:\n",
      "what is the percentage change in gross unpaid losses from 2008 to 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.63%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 0.1725%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 37112000\n",
      "new_value = 37176000\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result:.4f}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's calculated percentage change is incorrect. The agent provided an answer of 0.1725%, whereas the expected correct answer is 1.63%. The discrepancy is significant, indicating a fundamental error in the calculation or data retrieval.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user has not provided the agent's thinking process. The response only contains a final answer without any context, data, or calculation steps. It is impossible to evaluate the clarity, logic, or mathematical soundness of the reasoning because no reasoning is presented. To assess the quality of financial reasoning, the step-by-step process of arriving at the answer is essential, and it is completely missing here.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly applies the standard formula for calculating percentage change. The variable names ('old_value', 'new_value') are descriptive and appropriate. The calculation is accurate, and the final print statement correctly formats the result to four decimal places, matching the agent's answer.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[12/20] QUESTION:\n",
      "what was the net tax expense for the 3 years ended 2005 related to the change in financial derivatives ( in millions? )\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -8.2\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is 'N/A', which is completely incorrect. The expected answer is a numerical value of -8.2. The agent failed to answer the question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no reasoning or thought process. The answer \"N/A\" is not a valid response and indicates a complete failure to address the question. There is no evidence of any attempt to break down the problem, identify relevant data, or perform any calculations.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[13/20] QUESTION:\n",
      "what is the percentage change in total operating expenses in 2012?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.4%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's response was 'N/A' which is incorrect. The expected answer is a numerical value, '1.4%'. The agent failed to answer the question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided 'N/A' as the answer and did not include any thinking process. This indicates a complete failure to address the user's question. There is no reasoning to evaluate, no numbers were identified, and no calculation was attempted.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[14/20] QUESTION:\n",
      "how much has cash equivalents and marketable securities decreased from 2014 to 2016?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 33.9% decrease\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent failed to answer the question, providing 'N/A' as its response. The question asks for a specific calculation, and the agent did not attempt to provide one.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and an answer of 'N/A'. It completely failed to address the question, identify any relevant numbers, or perform any calculations. This represents a total failure to reason about the problem.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[15/20] QUESTION:\n",
      "what was the percentage increase in the property and equipment net from 2004 to 2005\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 52.2%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 52.221033573272294%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "# Extract property and equipment net for 2004 and 2005\n",
      "prop_eq_2004 = 2273356\n",
      "prop_eq_2005 = 3460526\n",
      "\n",
      "# Calculate the percentage increase\n",
      "percentage_increase = ((prop_eq_2005 - prop_eq_2004) / prop_eq_2004) * 100\n",
      "print(f\"{percentage_increase}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is numerically correct and matches the expected answer when rounded to one decimal place. The higher precision provided by the agent is not an error and demonstrates an accurate calculation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user did not provide the agent's thinking process. The evaluation requires assessing the clarity, logic, and mathematical soundness of the reasoning, which is impossible without the actual reasoning steps. Only the final answer is given, which is insufficient for the task.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly implements the formula for percentage increase: ((New Value - Old Value) / Old Value) * 100. The variable names are clear and appropriate for the values they represent. The final output correctly calculates the percentage increase based on the provided input values.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[16/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 9.63\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The evaluation context is incomplete. Both the 'Question' and 'Expected Answer' fields are missing. Without them, it is impossible to assess the correctness or relevance of the agent's answer '9.63'. The provided information is insufficient to perform an evaluation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The evaluation context is incomplete. The 'Question' and 'Agent's Thinking' fields are empty. Without the question and the agent's reasoning process, it is impossible to assess the clarity, logic, mathematical soundness, or overall quality of the financial reasoning. The agent provided a numerical answer but no supporting work, which completely fails the evaluation criteria.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[17/20] QUESTION:\n",
      "what is the net income margin for 2018?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 3.3%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is 'N/A', while the expected answer is '3.3%'. The agent failed to provide the correct numerical answer to the question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process whatsoever. The answer 'N/A' is not accompanied by any explanation, making it impossible to assess the agent's understanding of the question, the required formula, or its attempt to find the data. This is a complete failure of reasoning.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[18/20] QUESTION:\n",
      "what was the total intrinsic value of options exercised during 2007 , 2006 and 2005 in millions?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 194\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 31\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer of 31 million is incorrect. The expected answer is 194 million. The agent failed to extract the correct figure from the financial data.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided a single number as the answer without any supporting thought process, explanation, or calculation. It is impossible to evaluate the reasoning because none was provided. This fails all criteria for the evaluation: there is no clarity, no identification of numbers, no logical breakdown, and no mathematical reasoning shown.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[19/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 40%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The evaluation cannot be performed because the 'Question' and 'Expected Answer' were not provided in the evaluation context. Without knowing what was asked and what the correct answer should be, it is impossible to assess the correctness of the agent's answer ('40%').\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user did not provide the question or the agent's thinking process. Without the context of the problem and the agent's step-by-step reasoning, it is impossible to evaluate the correctness, clarity, or logical soundness of the answer '40%'. The provided information is insufficient for any form of assessment.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[20/20] QUESTION:\n",
      "what was the percentage total return for delphi automotive plc for the three years ended december 31 2013?\\\\n\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 185.81%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 185.81%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "initial_investment = 100.00\n",
      "final_value = 285.81\n",
      "result = ((final_value - initial_investment) / initial_investment) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is a perfect match to the expected answer, indicating it correctly retrieved the specific financial data point requested.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided a final numerical answer but completely omitted the thinking process required to arrive at that answer. It is impossible to evaluate the clarity, logic, or mathematical soundness of the reasoning because no reasoning was provided. Furthermore, the final answer of 185.81% appears to be incorrect. The question itself is flawed, as Delphi Automotive PLC was not public for the full three-year period ending Dec 31, 2013 (its IPO was in Nov 2011). Based on public data for the period the stock was traded (from its IPO date or from the start of 2012), the total return is significantly different from the agent's answer. The complete lack of a discernible reasoning process and an incorrect final answer makes the response invalid.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and runs without errors. It correctly implements the standard formula for percentage total return: ((Final Value - Initial Value) / Initial Value) * 100. The variable names `initial_investment`, `final_value`, and `result` are clear, descriptive, and appropriate for the calculation. The logic is sound and correctly computes the result based on the provided values.\n",
      "\n",
      "================================================================================\n",
      "âœ“ LLM-as-Judge Evaluation Complete (Baseline)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š BASELINE MODEL AGGREGATE METRICS:\n",
      "  Average Answer Score:    1.80/5\n",
      "  Average Reasoning Score: 1.00/5\n",
      "  Average Code Score:      5.00/5 (6 samples with code)\n",
      "\n",
      "  Run ID: 91eff102ba214134bb82f0c04c13cfab\n",
      "  View detailed results in MLflow UI at: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEFINE LLM-AS-JUDGE METRICS\n",
    "# ============================================================================\n",
    "# Using MLflow's make_judge API for template-based LLM Scorer\n",
    "# These are defined ONCE here and reused for baseline AND tuned model evaluation\n",
    "# Reference: https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/make-judge/\n",
    "# Note: litellm is required and provided by the devcontainer\n",
    "\n",
    "from mlflow.genai.judges import make_judge\n",
    "from mlflow.entities import Feedback, Expectation, AssessmentSource\n",
    "from typing import Literal\n",
    "import re\n",
    "\n",
    "# Configure environment for MLflow's make_judge API\n",
    "# Gemini requires the API key in the environment\n",
    "if config.GEMINI_API_KEY:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = config.GEMINI_API_KEY\n",
    "    print(\"âœ“ Gemini API key configured for MLflow make_judge\")\n",
    "else:\n",
    "    print(\"âš  Gemini API key not set - LLM-as-Judge evaluation will be skipped\")\n",
    "\n",
    "# Score mapping for categorical feedback to numeric scores\n",
    "SCORE_MAP = {\n",
    "    \"excellent\": 5,\n",
    "    \"good\": 4,\n",
    "    \"adequate\": 3,\n",
    "    \"poor\": 2,\n",
    "    \"wrong\": 1,\n",
    "}\n",
    "\n",
    "# Define the answer quality judge using MLflow's template-based approach\n",
    "# Note: Only use template variables that are passed to the judge\n",
    "answer_quality_judge = make_judge(\n",
    "    name=\"answer_quality\",\n",
    "    instructions=(\n",
    "        \"You are an expert judge evaluating financial reasoning quality.\\n\\n\"\n",
    "        \"{{ outputs }}\\n\\n\"\n",
    "        \"Rate the agent's answer based on how well it matches the expected answer.\\n\"\n",
    "        \"Consider correctness, completeness, and relevance.\\n\"\n",
    "        \"- 'excellent': Matches or exceeds expected answer with clear reasoning\\n\"\n",
    "        \"- 'good': Correct with minor issues\\n\"\n",
    "        \"- 'adequate': Mostly correct but missing key details\\n\"\n",
    "        \"- 'poor': Partially correct but with significant errors\\n\"\n",
    "        \"- 'wrong': Completely wrong or unrelated\\n\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"excellent\", \"good\", \"adequate\", \"poor\", \"wrong\"],\n",
    "    model=f\"gemini:/{config.GEMINI_MODEL}\",\n",
    ")\n",
    "\n",
    "# Define the reasoning quality judge\n",
    "reasoning_quality_judge = make_judge(\n",
    "    name=\"reasoning_quality\",\n",
    "    instructions=(\n",
    "        \"You are an expert judge evaluating the quality of financial reasoning.\\n\\n\"\n",
    "        \"{{ outputs }}\\n\\n\"\n",
    "        \"Evaluate the response for:\\n\"\n",
    "        \"1. Clarity of the thinking process\\n\"\n",
    "        \"2. Correct identification of relevant numbers and formulas\\n\"\n",
    "        \"3. Logical step-by-step breakdown of the problem\\n\"\n",
    "        \"4. Sound mathematical reasoning\\n\\n\"\n",
    "        \"Rate the reasoning quality:\\n\"\n",
    "        \"- 'excellent': Clear reasoning with comprehensive analysis\\n\"\n",
    "        \"- 'good': Good reasoning with clear logic\\n\"\n",
    "        \"- 'adequate': Adequate reasoning with minor issues\\n\"\n",
    "        \"- 'poor': Some reasoning but major gaps or errors\\n\"\n",
    "        \"- 'wrong': No reasoning or completely incorrect approach\\n\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"excellent\", \"good\", \"adequate\", \"poor\", \"wrong\"],\n",
    "    model=f\"gemini:/{config.GEMINI_MODEL}\",\n",
    ")\n",
    "\n",
    "# Define the code correctness judge\n",
    "code_correctness_judge = make_judge(\n",
    "    name=\"code_correctness\",\n",
    "    instructions=(\n",
    "        \"You are an expert judge evaluating Python code correctness.\\n\\n\"\n",
    "        \"{{ outputs }}\\n\\n\"\n",
    "        \"Evaluate the code for:\\n\"\n",
    "        \"1. Syntactic correctness (will it run?)\\n\"\n",
    "        \"2. Semantic correctness (does it compute the right thing?)\\n\"\n",
    "        \"3. Appropriate variable naming\\n\"\n",
    "        \"4. Correct use of financial formulas\\n\\n\"\n",
    "        \"Rate the code correctness:\\n\"\n",
    "        \"- 'excellent': Clean, correct, and efficient code\\n\"\n",
    "        \"- 'good': Correct code with good structure\\n\"\n",
    "        \"- 'adequate': Code runs but has minor issues\\n\"\n",
    "        \"- 'poor': Code has syntax errors or major logic errors\\n\"\n",
    "        \"- 'wrong': Completely broken or incorrect code\\n\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"excellent\", \"good\", \"adequate\", \"poor\", \"wrong\"],\n",
    "    model=f\"gemini:/{config.GEMINI_MODEL}\",\n",
    ")\n",
    "\n",
    "def has_code(text: str) -> bool:\n",
    "    \"\"\"Check if the text contains Python code (tool calling).\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    # Check for code blocks or Python REPL tool usage\n",
    "    return bool(re.search(r'```python|def |print\\(|result\\s*=|python_repl', text, re.IGNORECASE))\n",
    "\n",
    "def evaluate_response(agent_answer: str, ground_truth: str, question: str, \n",
    "                      thinking: str = \"\", code: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate agent answer using MLflow's template-based LLM judges.\n",
    "    \n",
    "    This function is reused for both baseline and tuned model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        agent_answer: The agent's generated answer\n",
    "        ground_truth: The correct answer\n",
    "        question: The original question\n",
    "        thinking: The agent's thinking/reasoning (optional)\n",
    "        code: The agent's generated code (optional)\n",
    "    \n",
    "    Returns:\n",
    "        dict with scores (1-5 or N/A) and explanations for each metric\n",
    "    \"\"\"\n",
    "    if not config.GEMINI_API_KEY:\n",
    "        # Fallback: simple string matching\n",
    "        gt_lower = ground_truth.lower().strip()\n",
    "        ans_lower = agent_answer.lower().strip()\n",
    "        if gt_lower in ans_lower or ans_lower in gt_lower:\n",
    "            return {\n",
    "                \"answer_score\": 4, \"answer_explanation\": \"Fallback: Answer contains ground truth\",\n",
    "                \"reasoning_score\": 3, \"reasoning_explanation\": \"Fallback: Unable to verify\",\n",
    "                \"code_score\": \"N/A\", \"code_explanation\": \"Fallback: Unable to verify\"\n",
    "            }\n",
    "        return {\n",
    "            \"answer_score\": 2, \"answer_explanation\": \"Fallback: Unable to verify without judge\",\n",
    "            \"reasoning_score\": 2, \"reasoning_explanation\": \"Fallback: Unable to verify\",\n",
    "            \"code_score\": \"N/A\", \"code_explanation\": \"Fallback: Unable to verify\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Build context string for answer evaluation\n",
    "        answer_context = (\n",
    "            f\"Question: {question}\\n\"\n",
    "            f\"Expected Answer: {ground_truth}\\n\"\n",
    "            f\"Agent's Answer: {agent_answer}\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate answer quality\n",
    "        answer_feedback = answer_quality_judge(\n",
    "            outputs={\"evaluation_context\": answer_context},\n",
    "        )\n",
    "        answer_score = SCORE_MAP.get(answer_feedback.value, 3)\n",
    "        \n",
    "        # Build context string for reasoning evaluation\n",
    "        reasoning_context = (\n",
    "            f\"Question: {question}\\n\"\n",
    "            f\"Agent's Thinking:\\n{thinking}\\n\"\n",
    "            f\"Agent's Answer: {agent_answer}\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate reasoning quality\n",
    "        reasoning_feedback = reasoning_quality_judge(\n",
    "            outputs={\"evaluation_context\": reasoning_context},\n",
    "        )\n",
    "        reasoning_score = SCORE_MAP.get(reasoning_feedback.value, 3)\n",
    "        \n",
    "        # Evaluate code correctness only if code was generated (tool calling)\n",
    "        if has_code(code) or has_code(agent_answer):\n",
    "            code_context = (\n",
    "                f\"Question: {question}\\n\"\n",
    "                f\"Generated Code:\\n```python\\n{code}\\n```\\n\"\n",
    "                f\"Agent's Answer: {agent_answer}\"\n",
    "            )\n",
    "            code_feedback = code_correctness_judge(\n",
    "                outputs={\"evaluation_context\": code_context},\n",
    "            )\n",
    "            code_score = SCORE_MAP.get(code_feedback.value, 3)\n",
    "            code_explanation = code_feedback.rationale or \"No rationale\"\n",
    "        else:\n",
    "            # No tool calling - code evaluation is N/A\n",
    "            code_score = \"N/A\"\n",
    "            code_explanation = \"No code/tool calling in this response\"\n",
    "        \n",
    "        return {\n",
    "            \"answer_score\": answer_score,\n",
    "            \"answer_explanation\": answer_feedback.rationale or \"No rationale\",\n",
    "            \"reasoning_score\": reasoning_score,\n",
    "            \"reasoning_explanation\": reasoning_feedback.rationale or \"No rationale\",\n",
    "            \"code_score\": code_score,\n",
    "            \"code_explanation\": code_explanation,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"answer_score\": 0, \"answer_explanation\": f\"Evaluation error: {str(e)}\",\n",
    "            \"reasoning_score\": 0, \"reasoning_explanation\": f\"Evaluation error: {str(e)}\",\n",
    "            \"code_score\": \"N/A\", \"code_explanation\": f\"Evaluation error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ“ MLflow template-based LLM Scorers (make_judge) configured\")\n",
    "print(f\"  Model: gemini/{config.GEMINI_MODEL}\")\n",
    "print(\"  Judges defined:\")\n",
    "print(\"    - answer_quality_judge\")\n",
    "print(\"    - reasoning_quality_judge\")\n",
    "print(\"    - code_correctness_judge (N/A when no tool calling)\")\n",
    "print(\"  Function: evaluate_response() - reusable for any evaluation\")\n",
    "\n",
    "if config.GEMINI_API_KEY:\n",
    "    print(\"=\"*80)\n",
    "    print(\"LLM-AS-JUDGE EVALUATION (Baseline Model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Using MLflow make_judge with model: gemini/{config.GEMINI_MODEL}\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Base_Model_LLM_Judge\") as run:\n",
    "        print(f\"\\nEvaluating {len(evaluation_sample)} baseline responses with LLM-as-Judge...\")\n",
    "        \n",
    "        # Store evaluation results\n",
    "        baseline_judge_results = []\n",
    "        \n",
    "        for idx, row in evaluation_sample.iterrows():\n",
    "            question = row['question']\n",
    "            ground_truth = row['answer']\n",
    "            agent_output = row.get('base_agent_answer', '')\n",
    "            thinking = row.get('base_thinking', '')\n",
    "            code = row.get('base_code', '')\n",
    "            \n",
    "            print(f\"\\n{'â”€'*80}\")\n",
    "            print(f\"[{idx+1}/{len(evaluation_sample)}] QUESTION:\")\n",
    "            print(f\"{question}\")\n",
    "            print(f\"\\nðŸ“Œ EXPECTED ANSWER: {ground_truth}\")\n",
    "            print(f\"\\nðŸ¤– AGENT ANSWER: {agent_output}\")\n",
    "            \n",
    "            if thinking:\n",
    "                print(f\"\\nðŸ’­ THINKING:\")\n",
    "                print(thinking)\n",
    "            \n",
    "            if code:\n",
    "                print(f\"\\nðŸ’» CODE:\")\n",
    "                print(code)\n",
    "            \n",
    "            # Run LLM-as-Judge evaluation (pass thinking and code separately)\n",
    "            evaluation = evaluate_response(\n",
    "                agent_answer=agent_output,\n",
    "                ground_truth=ground_truth,\n",
    "                question=question,\n",
    "                thinking=thinking,\n",
    "                code=code\n",
    "            )\n",
    "            \n",
    "            # Store full results (no truncation)\n",
    "            baseline_judge_results.append({\n",
    "                \"question\": question,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"agent_output\": agent_output,\n",
    "                \"thinking\": thinking,\n",
    "                \"code\": code,\n",
    "                \"answer_score\": evaluation[\"answer_score\"],\n",
    "                \"reasoning_score\": evaluation[\"reasoning_score\"],\n",
    "                \"code_score\": evaluation[\"code_score\"],\n",
    "                \"answer_explanation\": evaluation[\"answer_explanation\"],\n",
    "                \"reasoning_explanation\": evaluation[\"reasoning_explanation\"],\n",
    "                \"code_explanation\": evaluation[\"code_explanation\"],\n",
    "            })\n",
    "            \n",
    "            # Print full evaluation results (no truncation)\n",
    "            code_score_display = evaluation['code_score'] if evaluation['code_score'] != \"N/A\" else \"N/A\"\n",
    "            print(f\"\\n{'â”€'*40}\")\n",
    "            print(f\"ðŸ“Š LLM-AS-JUDGE SCORES:\")\n",
    "            print(f\"  Answer Score:    {evaluation['answer_score']}/5\")\n",
    "            print(f\"  Reasoning Score: {evaluation['reasoning_score']}/5\")\n",
    "            print(f\"  Code Score:      {code_score_display}{'/5' if code_score_display != 'N/A' else ''}\")\n",
    "            \n",
    "            print(f\"\\nðŸ“ ANSWER EVALUATION:\")\n",
    "            print(evaluation['answer_explanation'])\n",
    "            \n",
    "            print(f\"\\nðŸ“ REASONING EVALUATION:\")\n",
    "            print(evaluation['reasoning_explanation'])\n",
    "            \n",
    "            print(f\"\\nðŸ“ CODE EVALUATION:\")\n",
    "            print(evaluation['code_explanation'])\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        baseline_judge_df = pd.DataFrame(baseline_judge_results)\n",
    "        \n",
    "        # Calculate aggregate metrics (handle N/A for code scores)\n",
    "        base_avg_answer = baseline_judge_df[\"answer_score\"].mean()\n",
    "        base_avg_reasoning = baseline_judge_df[\"reasoning_score\"].mean()\n",
    "        \n",
    "        # Filter out N/A values for code score average\n",
    "        code_scores_numeric = [s for s in baseline_judge_df[\"code_score\"] if s != \"N/A\"]\n",
    "        base_avg_code = sum(code_scores_numeric) / len(code_scores_numeric) if code_scores_numeric else None\n",
    "        \n",
    "        # Add scores to evaluation_sample for later comparison\n",
    "        evaluation_sample['base_answer_score'] = baseline_judge_df[\"answer_score\"].tolist()\n",
    "        evaluation_sample['base_reasoning_score'] = baseline_judge_df[\"reasoning_score\"].tolist()\n",
    "        evaluation_sample['base_code_score'] = baseline_judge_df[\"code_score\"].tolist()\n",
    "        \n",
    "        # Log aggregate metrics\n",
    "        log_metrics = {\n",
    "            \"base_avg_answer_score\": base_avg_answer,\n",
    "            \"base_avg_reasoning_score\": base_avg_reasoning,\n",
    "        }\n",
    "        if base_avg_code is not None:\n",
    "            log_metrics[\"base_avg_code_score\"] = base_avg_code\n",
    "        mlflow.log_metrics(log_metrics)\n",
    "        \n",
    "        # Log comparison table\n",
    "        mlflow.log_table(\n",
    "            data=baseline_judge_df,\n",
    "            artifact_file=\"baseline_llm_judge_results.json\"\n",
    "        )\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"âœ“ LLM-as-Judge Evaluation Complete (Baseline)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"\\nðŸ“Š BASELINE MODEL AGGREGATE METRICS:\")\n",
    "        print(f\"  Average Answer Score:    {base_avg_answer:.2f}/5\")\n",
    "        print(f\"  Average Reasoning Score: {base_avg_reasoning:.2f}/5\")\n",
    "        if base_avg_code is not None:\n",
    "            print(f\"  Average Code Score:      {base_avg_code:.2f}/5 ({len(code_scores_numeric)} samples with code)\")\n",
    "        else:\n",
    "            print(f\"  Average Code Score:      N/A (no samples with tool calling)\")\n",
    "        print(f\"\\n  Run ID: {run.info.run_id}\")\n",
    "        print(f\"  View detailed results in MLflow UI at: http://localhost:5000\")\n",
    "            \n",
    "else:\n",
    "    print(\"âš  Skipping LLM-as-Judge evaluation (GEMINI_API_KEY not set)\")\n",
    "    print(\"  Set GEMINI_API_KEY in your .env file to enable quality evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: GRPO Fine-Tuning\n",
    "\n",
    "## Functional Design\n",
    "\n",
    "**GRPO (Group Relative Policy Optimization)** is a reinforcement learning technique that:\n",
    "- Samples multiple completions for each prompt\n",
    "- Computes relative rewards within each group\n",
    "- Updates the policy to favor higher-reward completions\n",
    "\n",
    "We train the model to improve:\n",
    "1. **Format Adherence**: Correct use of `<think>`, `<answer>` tags\n",
    "2. **Reasoning Quality**: Clear, step-by-step financial reasoning\n",
    "3. **Answer Accuracy**: Numerical correctness compared to ground truth\n",
    "\n",
    "## Technical Design\n",
    "\n",
    "**Reward Functions:**\n",
    "We define custom reward functions that evaluate different aspects:\n",
    "\n",
    "| Reward | Weight | Description |\n",
    "|--------|--------|-------------|\n",
    "| `format_reward` | 0.3 | Checks for proper tag structure |\n",
    "| `accuracy_reward` | 0.7 | Compares answer to ground truth |\n",
    "\n",
    "**Training Configuration:**\n",
    "- **LoRA adapters**: Efficient parameter updates (only ~1% of weights)\n",
    "- **Gradient accumulation**: Effective batch size of 4\n",
    "- **MLflow logging**: Track all training metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Note: GRPO Reward Design\n",
    "\n",
    "The reward functions below implement a **multi-objective** training signal:\n",
    "- **Format adherence** ensures the model learns our structured output format\n",
    "- **Accuracy reward** drives correctness of the final answer\n",
    "- Both rewards are combined with configurable weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define Reward Functions\n",
    "\n",
    "Reward functions are the core of GRPO training. They evaluate each generated completion and return a scalar reward that guides the model toward desired behaviors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Process Reward Model (PRM) functions defined\n",
      "  - format_reward: Checks output structure (20%)\n",
      "  - reasoning_reward: Rewards intermediate steps (30%)\n",
      "  - accuracy_reward: Rewards correct final answer (50%)\n",
      "  - process_reward: Combined PRM reward\n",
      "\n",
      "Testing reward functions:\n",
      "  Format reward: [1.0]\n",
      "  Reasoning reward: [1.0]\n",
      "  Accuracy reward: [1.0]\n",
      "  Process reward (combined): [1.0]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# REWARD FUNCTIONS FOR GRPO - PROCESS REWARD MODEL (PRM)\n",
    "# ============================================================================\n",
    "# These reward functions implement a Process Reward Model approach that\n",
    "# rewards intermediate reasoning steps, not just the final answer.\n",
    "\n",
    "def format_reward(completions: list, **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Reward for proper response formatting (20% of total reward).\n",
    "    \n",
    "    Checks for:\n",
    "    - Presence of <think> tags with actual content (reasoning)\n",
    "    - Presence of <answer> tags (final answer)\n",
    "    - Bonus: Python code blocks for computation\n",
    "    \n",
    "    Args:\n",
    "        completions: List of model completions, each is a list of message dicts\n",
    "        \n",
    "    Returns:\n",
    "        List of float rewards (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        # Extract the content from the completion\n",
    "        content = completion[0]['content'] if isinstance(completion, list) else str(completion)\n",
    "        \n",
    "        reward = 0.0\n",
    "        \n",
    "        # Check for <think> tags with actual content (not just empty tags)\n",
    "        think_match = re.search(r'<think>(.*?)</think>', content, re.DOTALL)\n",
    "        if think_match:\n",
    "            thinking = think_match.group(1).strip()\n",
    "            if len(thinking) > 50:  # Require substantial reasoning\n",
    "                reward += 0.4\n",
    "            elif len(thinking) > 10:\n",
    "                reward += 0.2\n",
    "        \n",
    "        # Check for <answer> tags with content\n",
    "        answer_match = re.search(r'<answer>(.*?)</answer>', content, re.DOTALL)\n",
    "        if answer_match and len(answer_match.group(1).strip()) > 0:\n",
    "            reward += 0.4\n",
    "        \n",
    "        # Bonus for Python code (shows computational reasoning)\n",
    "        if '```python' in content and '```' in content:\n",
    "            reward += 0.2\n",
    "        \n",
    "        rewards.append(min(reward, 1.0))\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def reasoning_reward(completions: list, steps: list = None, **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Process Reward Model: rewards correct intermediate reasoning steps (30% of total).\n",
    "    \n",
    "    This function checks if the model's reasoning trace contains:\n",
    "    - Key numbers from the ground truth steps\n",
    "    - Intermediate results that match the step calculations\n",
    "    - Mathematical operations mentioned\n",
    "    \n",
    "    Args:\n",
    "        completions: List of model completions\n",
    "        steps: List of ground truth step lists (from dataset)\n",
    "        \n",
    "    Returns:\n",
    "        List of float rewards (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    # Handle case where steps is not provided\n",
    "    if steps is None:\n",
    "        steps = [[] for _ in completions]\n",
    "    \n",
    "    for completion, gold_steps in zip(completions, steps):\n",
    "        content = completion[0]['content'] if isinstance(completion, list) else str(completion)\n",
    "        \n",
    "        # Extract thinking trace\n",
    "        think_match = re.search(r'<think>(.*?)</think>', content, re.DOTALL)\n",
    "        thinking = think_match.group(1) if think_match else content\n",
    "        \n",
    "        reward = 0.0\n",
    "        \n",
    "        if not gold_steps:\n",
    "            # No steps to compare - give partial credit for having any reasoning\n",
    "            if think_match and len(thinking.strip()) > 50:\n",
    "                reward = 0.5\n",
    "            rewards.append(reward)\n",
    "            continue\n",
    "        \n",
    "        # Count how many step components appear in the reasoning\n",
    "        total_checks = 0\n",
    "        passed_checks = 0\n",
    "        \n",
    "        for step in gold_steps:\n",
    "            if not isinstance(step, dict):\n",
    "                continue\n",
    "            \n",
    "            arg1 = str(step.get('arg1', ''))\n",
    "            arg2 = str(step.get('arg2', ''))\n",
    "            res = str(step.get('res', ''))\n",
    "            \n",
    "            # Check if key values appear in reasoning (skip references like #0)\n",
    "            if arg1 and not arg1.startswith('#'):\n",
    "                total_checks += 1\n",
    "                # Normalize for comparison (remove % and commas)\n",
    "                arg1_normalized = arg1.replace('%', '').replace(',', '').strip()\n",
    "                if arg1_normalized in thinking or arg1 in thinking:\n",
    "                    passed_checks += 1\n",
    "            \n",
    "            if arg2 and not arg2.startswith('#'):\n",
    "                total_checks += 1\n",
    "                arg2_normalized = arg2.replace('%', '').replace(',', '').strip()\n",
    "                if arg2_normalized in thinking or arg2 in thinking:\n",
    "                    passed_checks += 1\n",
    "            \n",
    "            # Check for intermediate/final results\n",
    "            if res:\n",
    "                total_checks += 1\n",
    "                res_normalized = res.replace('%', '').replace(',', '').strip()\n",
    "                if res_normalized in thinking or res in thinking:\n",
    "                    passed_checks += 1\n",
    "        \n",
    "        # Calculate reward based on proportion of checks passed\n",
    "        if total_checks > 0:\n",
    "            reward = passed_checks / total_checks\n",
    "        elif think_match and len(thinking.strip()) > 50:\n",
    "            reward = 0.3  # Some reasoning but no steps to check\n",
    "        \n",
    "        rewards.append(reward)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def accuracy_reward(completions: list, answer: list, **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Reward for answer accuracy (50% of total reward).\n",
    "    \n",
    "    Uses the normalize_answer and answers_match functions for robust comparison\n",
    "    that handles different formats (percentages, decimals, etc.)\n",
    "    \n",
    "    Args:\n",
    "        completions: List of model completions\n",
    "        answer: List of ground truth answers\n",
    "        \n",
    "    Returns:\n",
    "        List of float rewards (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for completion, gold_answer in zip(completions, answer):\n",
    "        # Extract content\n",
    "        content = completion[0]['content'] if isinstance(completion, list) else str(completion)\n",
    "        \n",
    "        # Extract answer from tags\n",
    "        answer_match = re.search(r'<answer>(.*?)</answer>', content, re.DOTALL)\n",
    "        if answer_match:\n",
    "            predicted = answer_match.group(1).strip()\n",
    "        else:\n",
    "            # Fallback: try to extract the last number from the content\n",
    "            numbers = re.findall(r'-?\\d+\\.?\\d*%?', content)\n",
    "            predicted = numbers[-1] if numbers else \"\"\n",
    "        \n",
    "        gold = str(gold_answer).strip()\n",
    "        \n",
    "        # Use the robust answer matching function\n",
    "        if answers_match(predicted, gold, tolerance=0.02):\n",
    "            rewards.append(1.0)\n",
    "        elif answers_match(predicted, gold, tolerance=0.05):\n",
    "            rewards.append(0.8)  # Close but not exact\n",
    "        elif answers_match(predicted, gold, tolerance=0.10):\n",
    "            rewards.append(0.5)  # Somewhat close\n",
    "        else:\n",
    "            # Check for partial string match as fallback\n",
    "            pred_lower = predicted.lower()\n",
    "            gold_lower = gold.lower()\n",
    "            if gold_lower in pred_lower or pred_lower in gold_lower:\n",
    "                rewards.append(0.3)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "\n",
    "def process_reward(completions: list, answer: list, steps: list = None, **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Combined Process Reward Model (PRM) function.\n",
    "    \n",
    "    Weights:\n",
    "    - Format (structure): 20%\n",
    "    - Reasoning (intermediate steps): 30%  \n",
    "    - Accuracy (final answer): 50%\n",
    "    \n",
    "    This encourages the model to:\n",
    "    1. Follow the expected output format\n",
    "    2. Show correct reasoning steps\n",
    "    3. Arrive at the correct final answer\n",
    "    \n",
    "    Args:\n",
    "        completions: List of model completions\n",
    "        answer: List of ground truth answers\n",
    "        steps: List of ground truth reasoning steps (optional)\n",
    "    \n",
    "    Returns:\n",
    "        List of float rewards (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    format_scores = format_reward(completions, **kwargs)\n",
    "    reasoning_scores = reasoning_reward(completions, steps=steps, **kwargs)\n",
    "    accuracy_scores = accuracy_reward(completions, answer=answer, **kwargs)\n",
    "    \n",
    "    # Weighted combination: format (20%) + reasoning (30%) + accuracy (50%)\n",
    "    combined = [\n",
    "        0.2 * f + 0.3 * r + 0.5 * a \n",
    "        for f, r, a in zip(format_scores, reasoning_scores, accuracy_scores)\n",
    "    ]\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "print(\"âœ“ Process Reward Model (PRM) functions defined\")\n",
    "print(\"  - format_reward: Checks output structure (20%)\")\n",
    "print(\"  - reasoning_reward: Rewards intermediate steps (30%)\")\n",
    "print(\"  - accuracy_reward: Rewards correct final answer (50%)\")\n",
    "print(\"  - process_reward: Combined PRM reward\")\n",
    "\n",
    "# Test reward functions\n",
    "test_completion = [[{\"content\": \"\"\"<think>\n",
    "To answer this question, I need to calculate the percentage change.\n",
    "From the data: old value = 100, new value = 125\n",
    "Step 1: Difference = 125 - 100 = 25\n",
    "Step 2: Percentage = (25 / 100) * 100 = 25%\n",
    "</think>\n",
    "\n",
    "```python\n",
    "old_value = 100\n",
    "new_value = 125\n",
    "result = ((new_value - old_value) / old_value) * 100\n",
    "print(f\"{result}%\")\n",
    "```\n",
    "\n",
    "<answer>25%</answer>\"\"\"}]]\n",
    "test_answer = [\"25%\"]\n",
    "test_steps = [[\n",
    "    {\"op\": \"subtract\", \"arg1\": \"125\", \"arg2\": \"100\", \"res\": \"25\"},\n",
    "    {\"op\": \"divide\", \"arg1\": \"#0\", \"arg2\": \"100\", \"res\": \"25%\"}\n",
    "]]\n",
    "\n",
    "print(\"\\nTesting reward functions:\")\n",
    "print(f\"  Format reward: {format_reward(test_completion)}\")\n",
    "print(f\"  Reasoning reward: {reasoning_reward(test_completion, test_steps)}\")\n",
    "print(f\"  Accuracy reward: {accuracy_reward(test_completion, test_answer)}\")\n",
    "print(f\"  Process reward (combined): {process_reward(test_completion, test_answer, test_steps)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Configure GRPO Training\n",
    "\n",
    "We use the TRL library's `GRPOTrainer` with Unsloth optimizations. Key settings:\n",
    "- **LoRA**: Only trains ~1% of parameters for efficiency\n",
    "- **Gradient accumulation**: Simulates larger batch sizes with limited memory\n",
    "- **Standard generation**: Using native HuggingFace generation (vLLM optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: UnslothDPOTrainer is already patched.\n",
      "Unsloth: UnslothGRPOTrainer is already patched.\n",
      "Unsloth: UnslothRewardTrainer is already patched.\n",
      "Unsloth: UnslothRLOOTrainer is already patched.\n",
      "Unsloth: UnslothSFTTrainer is already patched.\n",
      "âš  PatchFastRL failed: could not get source code\n",
      "  This may cause issues with GRPO training.\n",
      "  Try updating unsloth and trl: pip install --upgrade unsloth trl\n",
      "Training dataset prepared:\n",
      "  Samples: 3017 (evaluation samples excluded)\n",
      "  Columns: ['prompt', 'answer', 'steps']\n",
      "  âš ï¸ Note: 20 evaluation samples are NOT in training set\n",
      "\n",
      "ðŸ“Š Sample has 2 reasoning steps for PRM training\n",
      "\n",
      "âœ“ GRPO training configuration:\n",
      "  Learning rate: 5e-06\n",
      "  Batch size: 1\n",
      "  Gradient accumulation: 4\n",
      "  Effective batch size: 4\n",
      "  Max steps: 1000\n",
      "  Generations per prompt: 4\n",
      "  Max completion length: 1024 tokens\n",
      "  Max completion length: 1024 tokens\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURE GRPO TRAINING\n",
    "# ============================================================================\n",
    "# First, patch Unsloth for GRPO support\n",
    "# This must be done BEFORE importing GRPOTrainer\n",
    "from unsloth import PatchFastRL\n",
    "\n",
    "try:\n",
    "    PatchFastRL(\"GRPO\", FastLanguageModel)\n",
    "    print(\"âœ“ Unsloth patched for GRPO support\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  PatchFastRL failed: {e}\")\n",
    "    print(\"  This may cause issues with GRPO training.\")\n",
    "    print(\"  Try updating unsloth and trl: pip install --upgrade unsloth trl\")\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# Prepare training dataset (EXCLUDES evaluation samples)\n",
    "# The dataset needs 'prompt', 'answer', and 'steps' columns for PRM rewards\n",
    "# Using training_df which was created earlier with evaluation samples removed\n",
    "train_dataset = Dataset.from_pandas(training_df[['prompt', 'answer', 'steps']])\n",
    "\n",
    "print(\"Training dataset prepared:\")\n",
    "print(f\"  Samples: {len(train_dataset)} (evaluation samples excluded)\")\n",
    "print(f\"  Columns: {train_dataset.column_names}\")\n",
    "print(f\"  âš ï¸ Note: {len(evaluation_df)} evaluation samples are NOT in training set\")\n",
    "\n",
    "# Show sample with steps for verification\n",
    "sample_steps = training_df.iloc[0].get('steps', [])\n",
    "print(f\"\\nðŸ“Š Sample has {len(sample_steps) if sample_steps else 0} reasoning steps for PRM training\")\n",
    "\n",
    "# GRPO Configuration\n",
    "training_args = GRPOConfig(\n",
    "    # Output settings\n",
    "    output_dir=config.OUTPUT_DIR,\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    per_device_train_batch_size=config.BATCH_SIZE,\n",
    "    gradient_accumulation_steps=config.GRADIENT_ACCUMULATION_STEPS,\n",
    "    max_steps=config.MAX_TRAINING_STEPS,\n",
    "    \n",
    "    # GRPO-specific settings\n",
    "    num_generations=4,           # Number of completions per prompt for relative comparison\n",
    "    max_completion_length=1024,  # Increased to allow longer reasoning traces\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=config.LOGGING_STEPS,\n",
    "    report_to=\"mlflow\",          # Log metrics to MLflow\n",
    "    \n",
    "    # Disable vLLM (not installed) - use standard generation\n",
    "    use_vllm=False,\n",
    "    \n",
    "    # Save settings\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ GRPO training configuration:\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Max steps: {training_args.max_steps}\")\n",
    "print(f\"  Generations per prompt: {training_args.num_generations}\")\n",
    "print(f\"  Max completion length: {training_args.max_completion_length} tokens\")\n",
    "print(f\"  Max completion length: {training_args.max_completion_length} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Run GRPO Training\n",
    "\n",
    "This cell executes the GRPO training loop. Training metrics are automatically logged to MLflow, including:\n",
    "- Reward curves (format, accuracy, combined)\n",
    "- Policy loss\n",
    "- KL divergence from reference model\n",
    "\n",
    "**Note**: Training may take several hours depending on hardware. Progress is displayed and logged every step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING GRPO TRAINING\n",
      "================================================================================\n",
      "  Model: unsloth/DeepSeek-R1-Distill-Qwen-7B\n",
      "  Reward functions: format_reward, reasoning_reward, accuracy_reward (PRM)\n",
      "  Training samples: 3017\n",
      "  Max steps: 1000\n",
      "  Output dir: /workspace/models/checkpoints/deepseek-r1-fin-agent\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 3,017 | Num Epochs = 1 | Total steps = 1,000\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 35:04:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>train</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>tools / call_frequency</th>\n",
       "      <th>tools / failure_frequency</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>cispo_clip_ratio</th>\n",
       "      <th>rewards / format_reward / mean</th>\n",
       "      <th>rewards / format_reward / std</th>\n",
       "      <th>rewards / reasoning_reward / mean</th>\n",
       "      <th>rewards / reasoning_reward / std</th>\n",
       "      <th>rewards / accuracy_reward / mean</th>\n",
       "      <th>rewards / accuracy_reward / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.105000</td>\n",
       "      <td>0.460384</td>\n",
       "      <td>0</td>\n",
       "      <td>554.600000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>848.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>402.991675</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>531.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.145343</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.257735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333117</td>\n",
       "      <td>0.413395</td>\n",
       "      <td>No Log</td>\n",
       "      <td>488.600000</td>\n",
       "      <td>287.300000</td>\n",
       "      <td>775.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>457.183334</td>\n",
       "      <td>287.300000</td>\n",
       "      <td>692.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.187174</td>\n",
       "      <td>0.513117</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.241574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348214</td>\n",
       "      <td>0.456436</td>\n",
       "      <td>No Log</td>\n",
       "      <td>521.500000</td>\n",
       "      <td>309.900000</td>\n",
       "      <td>785.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>500.308337</td>\n",
       "      <td>309.900000</td>\n",
       "      <td>728.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0.425714</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.197791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.433482</td>\n",
       "      <td>No Log</td>\n",
       "      <td>502.150000</td>\n",
       "      <td>237.400000</td>\n",
       "      <td>817.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>414.425000</td>\n",
       "      <td>237.400000</td>\n",
       "      <td>638.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.229756</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.145388</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.146188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.409444</td>\n",
       "      <td>0.400015</td>\n",
       "      <td>No Log</td>\n",
       "      <td>571.175000</td>\n",
       "      <td>309.400000</td>\n",
       "      <td>829.900000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>511.091669</td>\n",
       "      <td>309.400000</td>\n",
       "      <td>729.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.202184</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.100649</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.305266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.340818</td>\n",
       "      <td>No Log</td>\n",
       "      <td>548.225000</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>817.300000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>470.966672</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>657.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.174866</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.146188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.079643</td>\n",
       "      <td>0.480999</td>\n",
       "      <td>No Log</td>\n",
       "      <td>494.375000</td>\n",
       "      <td>224.600000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>432.166669</td>\n",
       "      <td>224.600000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.196833</td>\n",
       "      <td>0.322143</td>\n",
       "      <td>0.135520</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.258315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021429</td>\n",
       "      <td>0.383966</td>\n",
       "      <td>No Log</td>\n",
       "      <td>575.675000</td>\n",
       "      <td>329.100000</td>\n",
       "      <td>864.800000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>537.416669</td>\n",
       "      <td>329.100000</td>\n",
       "      <td>758.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.178091</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.110437</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.326038</td>\n",
       "      <td>No Log</td>\n",
       "      <td>580.275000</td>\n",
       "      <td>315.700000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>496.675003</td>\n",
       "      <td>315.700000</td>\n",
       "      <td>714.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.184315</td>\n",
       "      <td>0.230714</td>\n",
       "      <td>0.136317</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.140415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.107500</td>\n",
       "      <td>0.371282</td>\n",
       "      <td>No Log</td>\n",
       "      <td>556.025000</td>\n",
       "      <td>321.400000</td>\n",
       "      <td>789.700000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>517.216669</td>\n",
       "      <td>321.400000</td>\n",
       "      <td>740.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.170660</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.220580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210714</td>\n",
       "      <td>0.361425</td>\n",
       "      <td>No Log</td>\n",
       "      <td>533.725000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>802.100000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>481.750000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>702.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.219143</td>\n",
       "      <td>0.490714</td>\n",
       "      <td>0.085956</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.266188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.092024</td>\n",
       "      <td>0.261479</td>\n",
       "      <td>No Log</td>\n",
       "      <td>582.875000</td>\n",
       "      <td>314.800000</td>\n",
       "      <td>868.600000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>550.216667</td>\n",
       "      <td>314.800000</td>\n",
       "      <td>758.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.203282</td>\n",
       "      <td>0.349524</td>\n",
       "      <td>0.059482</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.119641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.373864</td>\n",
       "      <td>0.369056</td>\n",
       "      <td>No Log</td>\n",
       "      <td>503.250000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>471.866669</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.441364</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.239862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.195000</td>\n",
       "      <td>0.453145</td>\n",
       "      <td>No Log</td>\n",
       "      <td>509.450000</td>\n",
       "      <td>279.600000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>415.975000</td>\n",
       "      <td>279.600000</td>\n",
       "      <td>565.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.179638</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.109385</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.302075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117143</td>\n",
       "      <td>0.398928</td>\n",
       "      <td>No Log</td>\n",
       "      <td>506.300000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>774.700000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>493.975000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>738.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.219638</td>\n",
       "      <td>0.417143</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.198655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467500</td>\n",
       "      <td>0.380943</td>\n",
       "      <td>No Log</td>\n",
       "      <td>474.300000</td>\n",
       "      <td>261.100000</td>\n",
       "      <td>687.400000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>449.741669</td>\n",
       "      <td>261.100000</td>\n",
       "      <td>628.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.196352</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.130696</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.199031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>No Log</td>\n",
       "      <td>517.425000</td>\n",
       "      <td>291.700000</td>\n",
       "      <td>731.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>464.350000</td>\n",
       "      <td>291.700000</td>\n",
       "      <td>632.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.208091</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.133305</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.236794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.108571</td>\n",
       "      <td>0.344845</td>\n",
       "      <td>No Log</td>\n",
       "      <td>466.350000</td>\n",
       "      <td>282.400000</td>\n",
       "      <td>746.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>383.050003</td>\n",
       "      <td>282.400000</td>\n",
       "      <td>506.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.142757</td>\n",
       "      <td>0.458571</td>\n",
       "      <td>0.149675</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.185359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.358604</td>\n",
       "      <td>0.375951</td>\n",
       "      <td>No Log</td>\n",
       "      <td>541.200000</td>\n",
       "      <td>316.300000</td>\n",
       "      <td>789.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>497.916672</td>\n",
       "      <td>316.300000</td>\n",
       "      <td>693.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.501104</td>\n",
       "      <td>0.142549</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.560873</td>\n",
       "      <td>No Log</td>\n",
       "      <td>472.925000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>765.200000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>427.175003</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>635.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.185168</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.183516</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.300741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290714</td>\n",
       "      <td>0.389031</td>\n",
       "      <td>No Log</td>\n",
       "      <td>547.075000</td>\n",
       "      <td>295.500000</td>\n",
       "      <td>838.400000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>519.383334</td>\n",
       "      <td>295.500000</td>\n",
       "      <td>779.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.177358</td>\n",
       "      <td>0.420714</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.175348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271071</td>\n",
       "      <td>0.339870</td>\n",
       "      <td>No Log</td>\n",
       "      <td>495.200000</td>\n",
       "      <td>275.700000</td>\n",
       "      <td>725.600000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>462.283337</td>\n",
       "      <td>275.700000</td>\n",
       "      <td>667.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.258279</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0.093671</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.124747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.147857</td>\n",
       "      <td>0.407077</td>\n",
       "      <td>No Log</td>\n",
       "      <td>510.650000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>751.600000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>470.691669</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.195862</td>\n",
       "      <td>0.312857</td>\n",
       "      <td>0.133666</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.170790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.185000</td>\n",
       "      <td>0.488757</td>\n",
       "      <td>No Log</td>\n",
       "      <td>492.625000</td>\n",
       "      <td>253.800000</td>\n",
       "      <td>724.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>447.433337</td>\n",
       "      <td>253.800000</td>\n",
       "      <td>632.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.215103</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.128040</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.316366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.359877</td>\n",
       "      <td>No Log</td>\n",
       "      <td>587.775000</td>\n",
       "      <td>363.100000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>492.800006</td>\n",
       "      <td>363.100000</td>\n",
       "      <td>625.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.160120</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.159347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.295859</td>\n",
       "      <td>No Log</td>\n",
       "      <td>525.950000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>468.225006</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>604.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.090056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.165357</td>\n",
       "      <td>0.405120</td>\n",
       "      <td>No Log</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>700.400000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>457.558337</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>625.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.207409</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>0.120676</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.192735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.269167</td>\n",
       "      <td>0.553980</td>\n",
       "      <td>No Log</td>\n",
       "      <td>434.225000</td>\n",
       "      <td>240.300000</td>\n",
       "      <td>719.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>373.691672</td>\n",
       "      <td>240.300000</td>\n",
       "      <td>544.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.214973</td>\n",
       "      <td>0.544167</td>\n",
       "      <td>0.216969</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.282900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969722</td>\n",
       "      <td>0.271312</td>\n",
       "      <td>No Log</td>\n",
       "      <td>556.475000</td>\n",
       "      <td>294.600000</td>\n",
       "      <td>829.800000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>444.250000</td>\n",
       "      <td>294.600000</td>\n",
       "      <td>626.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.178128</td>\n",
       "      <td>0.382222</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.124490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.044881</td>\n",
       "      <td>0.405795</td>\n",
       "      <td>No Log</td>\n",
       "      <td>626.425000</td>\n",
       "      <td>380.200000</td>\n",
       "      <td>900.100000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>546.708340</td>\n",
       "      <td>380.200000</td>\n",
       "      <td>759.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.228461</td>\n",
       "      <td>0.407381</td>\n",
       "      <td>0.134089</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>0.605780</td>\n",
       "      <td>No Log</td>\n",
       "      <td>549.325000</td>\n",
       "      <td>318.700000</td>\n",
       "      <td>800.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>475.425003</td>\n",
       "      <td>318.700000</td>\n",
       "      <td>639.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.212706</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.108798</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.370319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.244286</td>\n",
       "      <td>0.458752</td>\n",
       "      <td>No Log</td>\n",
       "      <td>526.475000</td>\n",
       "      <td>294.400000</td>\n",
       "      <td>769.700000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>486.675000</td>\n",
       "      <td>294.400000</td>\n",
       "      <td>705.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>0.359286</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.229941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.078214</td>\n",
       "      <td>0.629366</td>\n",
       "      <td>No Log</td>\n",
       "      <td>572.275000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>805.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>505.925006</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>672.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.233570</td>\n",
       "      <td>0.270714</td>\n",
       "      <td>0.232376</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.307170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.197500</td>\n",
       "      <td>0.332818</td>\n",
       "      <td>No Log</td>\n",
       "      <td>516.325000</td>\n",
       "      <td>290.400000</td>\n",
       "      <td>797.400000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>466.425000</td>\n",
       "      <td>290.400000</td>\n",
       "      <td>676.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.169612</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.129113</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.100580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>No Log</td>\n",
       "      <td>569.625000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>880.500000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>471.608334</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>677.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.232732</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.159515</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.301050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.059286</td>\n",
       "      <td>0.345762</td>\n",
       "      <td>No Log</td>\n",
       "      <td>471.175000</td>\n",
       "      <td>290.700000</td>\n",
       "      <td>645.800000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>460.625000</td>\n",
       "      <td>290.700000</td>\n",
       "      <td>620.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.206708</td>\n",
       "      <td>0.304286</td>\n",
       "      <td>0.124280</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.127735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906071</td>\n",
       "      <td>0.250411</td>\n",
       "      <td>No Log</td>\n",
       "      <td>573.475000</td>\n",
       "      <td>288.600000</td>\n",
       "      <td>844.400000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>495.891669</td>\n",
       "      <td>288.600000</td>\n",
       "      <td>725.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.182430</td>\n",
       "      <td>0.223571</td>\n",
       "      <td>0.061784</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908409</td>\n",
       "      <td>0.397141</td>\n",
       "      <td>No Log</td>\n",
       "      <td>481.750000</td>\n",
       "      <td>240.300000</td>\n",
       "      <td>743.300000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>453.866669</td>\n",
       "      <td>240.300000</td>\n",
       "      <td>699.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.118404</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.119610</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.206244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.395374</td>\n",
       "      <td>No Log</td>\n",
       "      <td>544.100000</td>\n",
       "      <td>288.500000</td>\n",
       "      <td>812.700000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>494.775006</td>\n",
       "      <td>288.500000</td>\n",
       "      <td>716.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.235682</td>\n",
       "      <td>0.231429</td>\n",
       "      <td>0.091522</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.195334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.197143</td>\n",
       "      <td>0.377630</td>\n",
       "      <td>No Log</td>\n",
       "      <td>515.250000</td>\n",
       "      <td>287.200000</td>\n",
       "      <td>768.900000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>368.166669</td>\n",
       "      <td>184.800000</td>\n",
       "      <td>549.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.193428</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.107689</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.009318</td>\n",
       "      <td>0.331559</td>\n",
       "      <td>No Log</td>\n",
       "      <td>481.900000</td>\n",
       "      <td>279.900000</td>\n",
       "      <td>763.500000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>433.750003</td>\n",
       "      <td>279.900000</td>\n",
       "      <td>638.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.199312</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>0.103329</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.204905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.257500</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>No Log</td>\n",
       "      <td>486.925000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>685.500000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>474.475000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>649.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.176520</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.125594</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.292735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.132500</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>No Log</td>\n",
       "      <td>516.550000</td>\n",
       "      <td>256.600000</td>\n",
       "      <td>762.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>494.183337</td>\n",
       "      <td>256.600000</td>\n",
       "      <td>737.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.246732</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.155018</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.148033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.405223</td>\n",
       "      <td>No Log</td>\n",
       "      <td>444.650000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>688.800000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>429.041669</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>638.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.195144</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.124641</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.207225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.107857</td>\n",
       "      <td>0.438470</td>\n",
       "      <td>No Log</td>\n",
       "      <td>469.825000</td>\n",
       "      <td>258.300000</td>\n",
       "      <td>781.800000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>417.966672</td>\n",
       "      <td>258.300000</td>\n",
       "      <td>647.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.229077</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.191660</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.319905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.288571</td>\n",
       "      <td>0.543153</td>\n",
       "      <td>No Log</td>\n",
       "      <td>433.225000</td>\n",
       "      <td>248.300000</td>\n",
       "      <td>703.200000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>388.691672</td>\n",
       "      <td>248.300000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.152430</td>\n",
       "      <td>0.388571</td>\n",
       "      <td>0.150620</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.348895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978929</td>\n",
       "      <td>0.424171</td>\n",
       "      <td>No Log</td>\n",
       "      <td>563.375000</td>\n",
       "      <td>341.100000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>505.483334</td>\n",
       "      <td>341.100000</td>\n",
       "      <td>680.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.209062</td>\n",
       "      <td>0.231429</td>\n",
       "      <td>0.112850</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.154905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>0.458434</td>\n",
       "      <td>No Log</td>\n",
       "      <td>563.550000</td>\n",
       "      <td>267.900000</td>\n",
       "      <td>822.300000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>449.225000</td>\n",
       "      <td>267.900000</td>\n",
       "      <td>644.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.254111</td>\n",
       "      <td>0.239286</td>\n",
       "      <td>0.136850</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.210950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885942</td>\n",
       "      <td>0.338752</td>\n",
       "      <td>No Log</td>\n",
       "      <td>550.675000</td>\n",
       "      <td>266.900000</td>\n",
       "      <td>877.300000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>470.441669</td>\n",
       "      <td>266.900000</td>\n",
       "      <td>679.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.179446</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.131654</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.182067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.411758</td>\n",
       "      <td>No Log</td>\n",
       "      <td>498.700000</td>\n",
       "      <td>261.700000</td>\n",
       "      <td>745.800000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>453.966669</td>\n",
       "      <td>261.700000</td>\n",
       "      <td>691.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.222179</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.139473</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.190606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.444091</td>\n",
       "      <td>0.390938</td>\n",
       "      <td>No Log</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>710.800000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>409.583334</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.449091</td>\n",
       "      <td>0.140418</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>No Log</td>\n",
       "      <td>519.100000</td>\n",
       "      <td>231.800000</td>\n",
       "      <td>786.300000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>418.891672</td>\n",
       "      <td>231.800000</td>\n",
       "      <td>631.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.244332</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.133055</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.165470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.333944</td>\n",
       "      <td>No Log</td>\n",
       "      <td>481.575000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>741.800000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>415.358334</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.208763</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.160486</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.384286</td>\n",
       "      <td>0.449204</td>\n",
       "      <td>No Log</td>\n",
       "      <td>413.250000</td>\n",
       "      <td>204.100000</td>\n",
       "      <td>658.400000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>352.500000</td>\n",
       "      <td>204.100000</td>\n",
       "      <td>577.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.484286</td>\n",
       "      <td>0.089452</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.348150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.034286</td>\n",
       "      <td>0.425229</td>\n",
       "      <td>No Log</td>\n",
       "      <td>467.300000</td>\n",
       "      <td>259.100000</td>\n",
       "      <td>731.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>467.300000</td>\n",
       "      <td>259.100000</td>\n",
       "      <td>731.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.185458</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>0.064947</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.284252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.378862</td>\n",
       "      <td>No Log</td>\n",
       "      <td>559.050000</td>\n",
       "      <td>346.300000</td>\n",
       "      <td>754.800000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>488.058337</td>\n",
       "      <td>346.300000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.185693</td>\n",
       "      <td>0.391818</td>\n",
       "      <td>0.109882</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.142735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013409</td>\n",
       "      <td>0.365688</td>\n",
       "      <td>No Log</td>\n",
       "      <td>508.575000</td>\n",
       "      <td>316.600000</td>\n",
       "      <td>793.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>433.425006</td>\n",
       "      <td>316.600000</td>\n",
       "      <td>598.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.253808</td>\n",
       "      <td>0.303409</td>\n",
       "      <td>0.110887</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.230911</td>\n",
       "      <td>No Log</td>\n",
       "      <td>444.675000</td>\n",
       "      <td>235.100000</td>\n",
       "      <td>698.900000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>405.916669</td>\n",
       "      <td>235.100000</td>\n",
       "      <td>595.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.187017</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.167871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.552857</td>\n",
       "      <td>0.558630</td>\n",
       "      <td>No Log</td>\n",
       "      <td>420.125000</td>\n",
       "      <td>269.800000</td>\n",
       "      <td>594.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.125000</td>\n",
       "      <td>269.800000</td>\n",
       "      <td>594.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.169481</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.198907</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.317735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.398922</td>\n",
       "      <td>No Log</td>\n",
       "      <td>614.275000</td>\n",
       "      <td>360.100000</td>\n",
       "      <td>859.600000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>562.800006</td>\n",
       "      <td>360.100000</td>\n",
       "      <td>746.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.250883</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.039795</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939643</td>\n",
       "      <td>0.372315</td>\n",
       "      <td>No Log</td>\n",
       "      <td>566.325000</td>\n",
       "      <td>311.700000</td>\n",
       "      <td>823.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>505.158337</td>\n",
       "      <td>311.700000</td>\n",
       "      <td>710.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.153043</td>\n",
       "      <td>0.347143</td>\n",
       "      <td>0.171665</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.266082</td>\n",
       "      <td>No Log</td>\n",
       "      <td>544.325000</td>\n",
       "      <td>251.400000</td>\n",
       "      <td>835.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>466.608337</td>\n",
       "      <td>251.400000</td>\n",
       "      <td>682.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.198432</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.352024</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>No Log</td>\n",
       "      <td>518.950000</td>\n",
       "      <td>285.100000</td>\n",
       "      <td>812.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>466.433340</td>\n",
       "      <td>285.100000</td>\n",
       "      <td>701.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.241099</td>\n",
       "      <td>0.447024</td>\n",
       "      <td>0.146202</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.267321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>0.464266</td>\n",
       "      <td>No Log</td>\n",
       "      <td>447.900000</td>\n",
       "      <td>204.700000</td>\n",
       "      <td>703.300000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>391.541669</td>\n",
       "      <td>204.700000</td>\n",
       "      <td>577.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.150829</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.242735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>0.251508</td>\n",
       "      <td>No Log</td>\n",
       "      <td>498.900000</td>\n",
       "      <td>213.100000</td>\n",
       "      <td>741.100000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>455.625000</td>\n",
       "      <td>213.100000</td>\n",
       "      <td>687.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.143094</td>\n",
       "      <td>0.179286</td>\n",
       "      <td>0.110597</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.150161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>0.421532</td>\n",
       "      <td>No Log</td>\n",
       "      <td>493.525000</td>\n",
       "      <td>247.200000</td>\n",
       "      <td>755.900000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>399.916669</td>\n",
       "      <td>247.200000</td>\n",
       "      <td>548.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.198552</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.125862</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.198787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952955</td>\n",
       "      <td>0.435121</td>\n",
       "      <td>No Log</td>\n",
       "      <td>507.575000</td>\n",
       "      <td>276.400000</td>\n",
       "      <td>749.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>419.808337</td>\n",
       "      <td>276.400000</td>\n",
       "      <td>582.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.197045</td>\n",
       "      <td>0.340455</td>\n",
       "      <td>0.169242</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.289643</td>\n",
       "      <td>0.453856</td>\n",
       "      <td>No Log</td>\n",
       "      <td>414.625000</td>\n",
       "      <td>258.100000</td>\n",
       "      <td>631.800000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>397.833334</td>\n",
       "      <td>258.100000</td>\n",
       "      <td>571.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.205612</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.145520</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.200470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.196429</td>\n",
       "      <td>0.340626</td>\n",
       "      <td>No Log</td>\n",
       "      <td>490.600000</td>\n",
       "      <td>262.100000</td>\n",
       "      <td>793.700000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>448.091672</td>\n",
       "      <td>262.100000</td>\n",
       "      <td>712.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.203743</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.107735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.344464</td>\n",
       "      <td>No Log</td>\n",
       "      <td>358.575000</td>\n",
       "      <td>205.700000</td>\n",
       "      <td>583.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>322.041669</td>\n",
       "      <td>205.700000</td>\n",
       "      <td>475.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.111808</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.155885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111071</td>\n",
       "      <td>0.415579</td>\n",
       "      <td>No Log</td>\n",
       "      <td>476.425000</td>\n",
       "      <td>198.400000</td>\n",
       "      <td>801.400000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>388.233337</td>\n",
       "      <td>198.400000</td>\n",
       "      <td>607.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.221109</td>\n",
       "      <td>0.353571</td>\n",
       "      <td>0.162247</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.132735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.011250</td>\n",
       "      <td>0.269279</td>\n",
       "      <td>No Log</td>\n",
       "      <td>433.150000</td>\n",
       "      <td>235.600000</td>\n",
       "      <td>660.300000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>395.800000</td>\n",
       "      <td>235.600000</td>\n",
       "      <td>592.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.176544</td>\n",
       "      <td>0.323750</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.109853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.446048</td>\n",
       "      <td>No Log</td>\n",
       "      <td>572.400000</td>\n",
       "      <td>397.400000</td>\n",
       "      <td>799.200000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>521.925006</td>\n",
       "      <td>397.400000</td>\n",
       "      <td>699.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.232732</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.080486</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.649643</td>\n",
       "      <td>0.426010</td>\n",
       "      <td>No Log</td>\n",
       "      <td>399.650000</td>\n",
       "      <td>220.400000</td>\n",
       "      <td>665.900000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>384.475000</td>\n",
       "      <td>220.400000</td>\n",
       "      <td>609.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.171682</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.196983</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.154986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002500</td>\n",
       "      <td>0.322108</td>\n",
       "      <td>No Log</td>\n",
       "      <td>506.150000</td>\n",
       "      <td>260.200000</td>\n",
       "      <td>751.700000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>441.008337</td>\n",
       "      <td>260.200000</td>\n",
       "      <td>676.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.169807</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.125825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.373573</td>\n",
       "      <td>No Log</td>\n",
       "      <td>469.500000</td>\n",
       "      <td>296.200000</td>\n",
       "      <td>669.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>427.975000</td>\n",
       "      <td>296.200000</td>\n",
       "      <td>604.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.220859</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.096449</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.153923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.168409</td>\n",
       "      <td>0.248269</td>\n",
       "      <td>No Log</td>\n",
       "      <td>362.950000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>600.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>331.833337</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>522.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.182406</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.105000</td>\n",
       "      <td>0.411967</td>\n",
       "      <td>No Log</td>\n",
       "      <td>552.775000</td>\n",
       "      <td>337.100000</td>\n",
       "      <td>768.300000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>495.383340</td>\n",
       "      <td>337.100000</td>\n",
       "      <td>653.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.200503</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.261658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.157500</td>\n",
       "      <td>0.441934</td>\n",
       "      <td>No Log</td>\n",
       "      <td>473.700000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>715.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>455.275000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.166716</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.140687</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.269352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.353929</td>\n",
       "      <td>0.466842</td>\n",
       "      <td>No Log</td>\n",
       "      <td>362.525000</td>\n",
       "      <td>233.200000</td>\n",
       "      <td>568.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>327.733337</td>\n",
       "      <td>233.200000</td>\n",
       "      <td>443.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.218377</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.166721</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.257426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.036786</td>\n",
       "      <td>0.280457</td>\n",
       "      <td>No Log</td>\n",
       "      <td>405.125000</td>\n",
       "      <td>181.800000</td>\n",
       "      <td>644.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>405.125000</td>\n",
       "      <td>181.800000</td>\n",
       "      <td>644.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.190624</td>\n",
       "      <td>0.344286</td>\n",
       "      <td>0.072124</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.112321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.186786</td>\n",
       "      <td>0.417135</td>\n",
       "      <td>No Log</td>\n",
       "      <td>426.200000</td>\n",
       "      <td>210.400000</td>\n",
       "      <td>680.400000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>376.008334</td>\n",
       "      <td>210.400000</td>\n",
       "      <td>566.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.167240</td>\n",
       "      <td>0.279286</td>\n",
       "      <td>0.151795</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.197170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.012500</td>\n",
       "      <td>0.381609</td>\n",
       "      <td>No Log</td>\n",
       "      <td>462.700000</td>\n",
       "      <td>231.400000</td>\n",
       "      <td>738.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>437.800003</td>\n",
       "      <td>231.400000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.197044</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.166838</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.150580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.313411</td>\n",
       "      <td>No Log</td>\n",
       "      <td>486.550000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>762.900000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>439.166672</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>639.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.180527</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.106569</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.085580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.499740</td>\n",
       "      <td>0.479911</td>\n",
       "      <td>No Log</td>\n",
       "      <td>480.675000</td>\n",
       "      <td>291.200000</td>\n",
       "      <td>731.600000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>424.166669</td>\n",
       "      <td>291.200000</td>\n",
       "      <td>569.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.164710</td>\n",
       "      <td>0.519740</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.347640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887143</td>\n",
       "      <td>0.346475</td>\n",
       "      <td>No Log</td>\n",
       "      <td>493.200000</td>\n",
       "      <td>241.900000</td>\n",
       "      <td>699.100000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>389.983337</td>\n",
       "      <td>241.900000</td>\n",
       "      <td>554.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.213977</td>\n",
       "      <td>0.182143</td>\n",
       "      <td>0.041547</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.217735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.262500</td>\n",
       "      <td>0.383062</td>\n",
       "      <td>No Log</td>\n",
       "      <td>397.100000</td>\n",
       "      <td>221.800000</td>\n",
       "      <td>590.700000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>351.808334</td>\n",
       "      <td>221.800000</td>\n",
       "      <td>503.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.175612</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.102376</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.195606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250714</td>\n",
       "      <td>0.425058</td>\n",
       "      <td>No Log</td>\n",
       "      <td>408.950000</td>\n",
       "      <td>233.400000</td>\n",
       "      <td>622.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>408.950000</td>\n",
       "      <td>233.400000</td>\n",
       "      <td>622.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.113094</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.137377</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.247610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.415620</td>\n",
       "      <td>No Log</td>\n",
       "      <td>426.100000</td>\n",
       "      <td>273.100000</td>\n",
       "      <td>665.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>397.483334</td>\n",
       "      <td>273.100000</td>\n",
       "      <td>576.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.144902</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.207321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268067</td>\n",
       "      <td>No Log</td>\n",
       "      <td>415.475000</td>\n",
       "      <td>238.400000</td>\n",
       "      <td>562.600000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>366.800000</td>\n",
       "      <td>238.400000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.167735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156429</td>\n",
       "      <td>0.372986</td>\n",
       "      <td>No Log</td>\n",
       "      <td>430.650000</td>\n",
       "      <td>259.500000</td>\n",
       "      <td>658.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>430.650000</td>\n",
       "      <td>259.500000</td>\n",
       "      <td>658.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.086188</td>\n",
       "      <td>0.396429</td>\n",
       "      <td>0.147184</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.200161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.485956</td>\n",
       "      <td>No Log</td>\n",
       "      <td>423.450000</td>\n",
       "      <td>276.400000</td>\n",
       "      <td>646.700000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>394.383334</td>\n",
       "      <td>276.400000</td>\n",
       "      <td>574.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.217923</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.134472</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.215470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.287500</td>\n",
       "      <td>0.495941</td>\n",
       "      <td>No Log</td>\n",
       "      <td>461.650000</td>\n",
       "      <td>275.200000</td>\n",
       "      <td>660.600000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>434.908334</td>\n",
       "      <td>275.200000</td>\n",
       "      <td>624.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.199143</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.141210</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.262640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.553214</td>\n",
       "      <td>0.479686</td>\n",
       "      <td>No Log</td>\n",
       "      <td>483.975000</td>\n",
       "      <td>279.800000</td>\n",
       "      <td>724.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>432.533337</td>\n",
       "      <td>279.800000</td>\n",
       "      <td>622.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.169149</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.300580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217500</td>\n",
       "      <td>0.294588</td>\n",
       "      <td>No Log</td>\n",
       "      <td>442.875000</td>\n",
       "      <td>272.300000</td>\n",
       "      <td>621.600000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>425.350000</td>\n",
       "      <td>272.300000</td>\n",
       "      <td>605.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.124445</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.105010</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>0.419843</td>\n",
       "      <td>No Log</td>\n",
       "      <td>470.425000</td>\n",
       "      <td>240.600000</td>\n",
       "      <td>781.700000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>366.016669</td>\n",
       "      <td>240.600000</td>\n",
       "      <td>541.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.222039</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.104026</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.207735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.388333</td>\n",
       "      <td>0.342043</td>\n",
       "      <td>No Log</td>\n",
       "      <td>378.175000</td>\n",
       "      <td>222.600000</td>\n",
       "      <td>610.900000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>360.525000</td>\n",
       "      <td>222.600000</td>\n",
       "      <td>555.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.188377</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.088812</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.266672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.055000</td>\n",
       "      <td>0.455954</td>\n",
       "      <td>No Log</td>\n",
       "      <td>420.550000</td>\n",
       "      <td>207.100000</td>\n",
       "      <td>623.800000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>412.416669</td>\n",
       "      <td>207.100000</td>\n",
       "      <td>621.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.167240</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.198598</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.252871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100268</td>\n",
       "      <td>0.282773</td>\n",
       "      <td>No Log</td>\n",
       "      <td>442.575000</td>\n",
       "      <td>214.400000</td>\n",
       "      <td>688.200000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>411.825000</td>\n",
       "      <td>214.400000</td>\n",
       "      <td>653.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.197005</td>\n",
       "      <td>0.397768</td>\n",
       "      <td>0.051968</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.160056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026591</td>\n",
       "      <td>0.297143</td>\n",
       "      <td>No Log</td>\n",
       "      <td>405.750000</td>\n",
       "      <td>236.400000</td>\n",
       "      <td>666.100000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>350.008334</td>\n",
       "      <td>236.400000</td>\n",
       "      <td>483.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.188629</td>\n",
       "      <td>0.329091</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN GRPO TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize the GRPO Trainer\n",
    "# Using Process Reward Model (PRM) functions for better step-level feedback\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        format_reward,      # Structure/formatting reward (checks <think> and <answer> tags)\n",
    "        reasoning_reward,   # Step-level reasoning reward (NEW - uses steps column)\n",
    "        accuracy_reward,    # Final answer accuracy reward (uses normalized comparison)\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING GRPO TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Model: {config.MODEL_NAME}\")\n",
    "print(f\"  Reward functions: format_reward, reasoning_reward, accuracy_reward (PRM)\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Max steps: {training_args.max_steps}\")\n",
    "print(f\"  Output dir: {training_args.output_dir}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Train the model\n",
    "# MLflow automatically logs training metrics via report_to=\"mlflow\"\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model saved to: /workspace/models/checkpoints/deepseek-r1-fin-agent\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE THE FINE-TUNED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "# Save the model locally\n",
    "model.save_pretrained(config.OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(config.OUTPUT_DIR)\n",
    "\n",
    "print(f\"âœ“ Model saved to: {config.OUTPUT_DIR}\")\n",
    "\n",
    "# Optionally save to HuggingFace Hub\n",
    "# if config.HF_TOKEN:\n",
    "#     model.push_to_hub(\"your-username/qwen3-fin-agent\", token=config.HF_TOKEN)\n",
    "#     tokenizer.push_to_hub(\"your-username/qwen3-fin-agent\", token=config.HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Tuned Model Evaluation & Comparison\n",
    "\n",
    "## Functional Design\n",
    "\n",
    "After training, we evaluate the fine-tuned model using:\n",
    "1. **Same Agent Structure**: Ensures fair comparison with baseline\n",
    "2. **Same Validation Questions**: Direct before/after comparison\n",
    "3. **LLM-as-Judge Evaluation**: Gemini evaluates reasoning quality beyond simple accuracy\n",
    "\n",
    "## Technical Design\n",
    "\n",
    "**LLM-as-Judge (Gemini)**\n",
    "\n",
    "We use Google's Gemini as an impartial judge to evaluate aspects that can't be measured by simple string matching:\n",
    "- **Reasoning Quality**: Is the thinking trace clear and logical?\n",
    "- **Code Correctness**: Is the Python code syntactically correct and semantically appropriate?\n",
    "- **Answer Presentation**: Is the final answer well-formatted and complete?\n",
    "\n",
    "**MLflow Evaluation Integration**\n",
    "\n",
    "MLflow's `make_genai_metric` creates custom LLM-based metrics that:\n",
    "- Score each response on a defined scale\n",
    "- Provide rationale for each score\n",
    "- Log results as artifacts viewable in the MLflow UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Run Tuned Model Evaluation\n",
    "\n",
    "We evaluate the fine-tuned model on the same validation questions, using the same agent structure. This ensures a fair comparison with the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tuned agent built\n",
      "\n",
      "================================================================================\n",
      "TUNED MODEL EVALUATION\n",
      "================================================================================\n",
      "Evaluating on 20 questions (same as baseline, excluded from training)\n",
      "\n",
      "================================================================================\n",
      "QUESTION 1/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent change in net expense in interest and penalties between 2008 and 2009?\n",
      "\n",
      "âœ… Ground Truth: -36%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 2/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage reduction in the segment 2019s backlog from 2006 to 2007\n",
      "\n",
      "âœ… Ground Truth: -18.8%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 3/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage difference in the number of shares to be issued if the stock price closes at $ 11 compared to if it closes at $ 20?\n",
      "\n",
      "âœ… Ground Truth: 278%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Extracted number: 2155.5555555555554%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 2155.5555555555554%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 4/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage decrease from 2007 for 2009 for the cmg balance?\n",
      "\n",
      "âœ… Ground Truth: 1.47%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 5/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in cash from operations between 2008 and 2009?\n",
      "\n",
      "âœ… Ground Truth: 35%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/13 01:28:33 WARNING mlflow.tracing.export.mlflow_v3: Failed to send trace to MLflow backend: Yaml file '/workspace/notebooks/agents/mlruns/585105050822408217/traces/tr-151c5ca10168748cfe9c0153ed3b2e1b/trace_info.yaml' exists as '/workspace/notebooks/agents/mlruns/585105050822408217/traces/tr-151c5ca10168748cfe9c0153ed3b2e1b/trace_info.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 6/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 121.7\n",
      "new_value = 155.8\n",
      "result = ((new_value - old_value) / old_valu...\n",
      "  â”‚    â””â”€ Result: Code executed successfully (no output)\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: Code executed successfully (no output)\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 121.7\n",
      "new_value = 155.8\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "\n",
      "ðŸ¤– Agent Answer: Code executed successfully (no output)\n",
      "\n",
      "================================================================================\n",
      "QUESTION 7/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in earnings per share from 2005 to 2006?\n",
      "\n",
      "âœ… Ground Truth: 22%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 3.49\n",
      "new_value = 4.27\n",
      "result = ((new_value - old_value) / old_value)...\n",
      "  â”‚    â””â”€ Result: 22.349570200573048%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 22.349570200573048%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 3.49\n",
      "new_value = 4.27\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 22.349570200573048%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 8/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much did the quarterly dividend yield change from 2010 to 2012 for applied materials?\n",
      "\n",
      "âœ… Ground Truth: the dividend yield increased 0.04% from 2010 to 2012\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 9/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent of the increase in the operating income from 2010 to 2011\n",
      "\n",
      "âœ… Ground Truth: 10.1%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Parsed from tags: 10.02%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 10.02%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 10/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what percent of the net change in revenue between 2007 and 2008 was due to volume/weather?\n",
      "\n",
      "âœ… Ground Truth: 76.5%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 11/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in gross unpaid losses from 2008 to 2009?\n",
      "\n",
      "âœ… Ground Truth: 1.63%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 12/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the net tax expense for the 3 years ended 2005 related to the change in financial derivatives ( in millions? )\n",
      "\n",
      "âœ… Ground Truth: -8.2\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 13/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in total operating expenses in 2012?\n",
      "\n",
      "âœ… Ground Truth: 1.4%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 14/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much has cash equivalents and marketable securities decreased from 2014 to 2016?\n",
      "\n",
      "âœ… Ground Truth: 33.9% decrease\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 15/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage increase in the property and equipment net from 2004 to 2005\n",
      "\n",
      "âœ… Ground Truth: 52.2%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 2273356\n",
      "new_value = 3460526\n",
      "result = ((new_value - old_value) / old_...\n",
      "  â”‚    â””â”€ Result: 52.221033573272294%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 52.221033573272294%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 2273356\n",
      "new_value = 3460526\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 52.221033573272294%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 16/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â”œâ”€ Found code: old_value = 218.6\n",
      "new_value = 312.4\n",
      "result = ((new_value - old_value) / old_valu...\n",
      "  â”‚    â””â”€ Result: 42.90942360475754%\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Using tool output: 42.90942360475754%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "old_value = 218.6\n",
      "new_value = 312.4\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ¤– Agent Answer: 42.90942360475754%\n",
      "\n",
      "================================================================================\n",
      "QUESTION 17/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the net income margin for 2018?\n",
      "\n",
      "âœ… Ground Truth: 3.3%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Could not extract answer, returning N/A\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: N/A\n",
      "\n",
      "================================================================================\n",
      "QUESTION 18/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the total intrinsic value of options exercised during 2007 , 2006 and 2005 in millions?\n",
      "\n",
      "âœ… Ground Truth: 194\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Extracted number: 92\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 92\n",
      "\n",
      "================================================================================\n",
      "QUESTION 19/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "âœ… Ground Truth: \n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Parsed from tags: $2,040 million\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: $2,040 million\n",
      "\n",
      "================================================================================\n",
      "QUESTION 20/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage total return for delphi automotive plc for the three years ended december 31 2013?\\\\n\n",
      "\n",
      "âœ… Ground Truth: 185.81%\n",
      "  â”œâ”€ ðŸ§  [Think] Generating reasoning...\n",
      "  â”œâ”€ ðŸ”¢ [Calculate] Checking for Python code...\n",
      "  â”‚    â””â”€ No code found, skipping calculation\n",
      "  â”œâ”€ âœ… [Finalize] Extracting final answer...\n",
      "  â”‚    â””â”€ Extracted number: 185.81%\n",
      "\n",
      "ðŸ§  Thinking:\n",
      "(none)\n",
      "\n",
      "ðŸ’» Code Generated:\n",
      "(none)\n",
      "\n",
      "ðŸ¤– Agent Answer: 185.81%\n",
      "\n",
      "================================================================================\n",
      "âœ“ Tuned evaluation complete\n",
      "================================================================================\n",
      "  Total time: 42.32s\n",
      "  Avg per question: 2.12s\n",
      "  Run ID: 36d5fe8b87074e6b9ded2cb98ce65ceb\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BUILD TUNED AGENT & RUN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Create wrapper for the tuned model\n",
    "# Note: The model weights were updated in-place by the trainer\n",
    "tuned_engine = UnslothModelWrapper(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=config.MAX_NEW_TOKENS\n",
    ")\n",
    "\n",
    "# Build the agent with the tuned model\n",
    "tuned_agent = build_financial_agent(tuned_engine, verbose=True)\n",
    "print(\"âœ“ Tuned agent built\")\n",
    "\n",
    "# Run tuned model evaluation on the same evaluation sample (not used in training)\n",
    "tuned_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNED MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Evaluating on {len(evaluation_sample)} questions (same as baseline, excluded from training)\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Tuned_Model_Eval\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": config.MODEL_NAME,\n",
    "        \"model_type\": \"tuned\",\n",
    "        \"evaluation_samples\": len(evaluation_sample),\n",
    "        \"max_new_tokens\": config.MAX_NEW_TOKENS,\n",
    "        \"training_steps\": config.MAX_TRAINING_STEPS,\n",
    "        \"random_seed\": config.RANDOM_SEED,\n",
    "    })\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, row in evaluation_sample.iterrows():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"QUESTION {idx + 1}/{len(evaluation_sample)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\\nðŸ“‹ Question:\\n{row['question']}\")\n",
    "        print(f\"\\nâœ… Ground Truth: {row['answer']}\")\n",
    "        \n",
    "        try:\n",
    "            # Invoke the agent\n",
    "            result = tuned_agent.invoke({\n",
    "                \"query\": row['question'],\n",
    "                \"context\": row['context'],\n",
    "                \"model_output\": \"\",\n",
    "                \"tool_output\": \"\",\n",
    "                \"final_answer\": \"\",\n",
    "                \"thinking\": \"\",\n",
    "                \"code_generated\": \"\",\n",
    "            })\n",
    "            \n",
    "            agent_answer = result.get('final_answer', 'N/A')\n",
    "            thinking = result.get('thinking', '')\n",
    "            code_generated = result.get('code_generated', '')\n",
    "            full_output = result.get('model_output', '')\n",
    "            \n",
    "            # Print full output (no truncation)\n",
    "            print(f\"\\nðŸ§  Thinking:\\n{thinking if thinking else '(none)'}\")\n",
    "            print(f\"\\nðŸ’» Code Generated:\\n{code_generated if code_generated else '(none)'}\")\n",
    "            print(f\"\\nðŸ¤– Agent Answer: {agent_answer}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error: {e}\")\n",
    "            agent_answer = f\"Error: {str(e)}\"\n",
    "            thinking = \"\"\n",
    "            code_generated = \"\"\n",
    "            full_output = \"\"\n",
    "            result = {\"final_answer\": agent_answer, \"model_output\": \"\"}\n",
    "        \n",
    "        # Store full results (no truncation)\n",
    "        tuned_results.append({\n",
    "            \"question\": row['question'],\n",
    "            \"context\": row['context'],\n",
    "            \"ground_truth\": row['answer'],\n",
    "            \"agent_answer\": agent_answer,\n",
    "            \"thinking\": thinking,\n",
    "            \"code_generated\": code_generated,\n",
    "            \"full_output\": full_output,\n",
    "        })\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Add results to evaluation sample\n",
    "    evaluation_sample['tuned_agent_answer'] = [r['agent_answer'] for r in tuned_results]\n",
    "    evaluation_sample['tuned_thinking'] = [r['thinking'] for r in tuned_results]\n",
    "    evaluation_sample['tuned_code'] = [r['code_generated'] for r in tuned_results]\n",
    "    evaluation_sample['tuned_full_output'] = [r['full_output'] for r in tuned_results]\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"total_time_seconds\", elapsed_time)\n",
    "    mlflow.log_metric(\"avg_time_per_question\", elapsed_time / len(evaluation_sample))\n",
    "    \n",
    "    # Log the results table\n",
    "    mlflow.log_table(\n",
    "        data=pd.DataFrame(tuned_results),\n",
    "        artifact_file=\"tuned_results.json\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ“ Tuned evaluation complete\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Total time: {elapsed_time:.2f}s\")\n",
    "    print(f\"  Avg per question: {elapsed_time / len(evaluation_sample):.2f}s\")\n",
    "    print(f\"  Run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Run LLM-as-Judge Evaluation (Tuned Model)\n",
    "\n",
    "We use the **same LLM-as-Judge metrics** defined earlier (in Phase 3) to evaluate the tuned model. This enables direct comparison with baseline scores. Results are logged to MLflow and viewable in the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LLM-AS-JUDGE EVALUATION (Tuned Model)\n",
      "================================================================================\n",
      "Using MLflow make_judge with model: gemini/gemini-2.5-pro\n",
      "\n",
      "Evaluating 20 tuned model responses with LLM-as-Judge...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[1/20] QUESTION:\n",
      "what was the percent change in net expense in interest and penalties between 2008 and 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -36%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent was unable to answer the question, responding with 'N/A'. The expected answer was a specific numerical value (-36%), indicating that the information was likely available. Therefore, the agent's response is incorrect as it failed to perform the required calculation or data extraction.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and returned 'N/A' as the answer. This indicates a complete failure to address the query. There is no attempt to identify relevant numbers, apply a formula, or perform any calculation.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[2/20] QUESTION:\n",
      "what was the percentage reduction in the segment 2019s backlog from 2006 to 2007\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -18.8%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's response is 'N/A', which means it did not provide an answer to the question. The expected answer is a specific numerical value, -18.8%. Since the agent failed to provide any answer, let alone the correct one, the response is wrong.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and no answer, simply stating 'N/A'. This represents a complete failure to address the user's question. There is no reasoning to evaluate, rendering the response incorrect and unhelpful.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[3/20] QUESTION:\n",
      "what is the percentage difference in the number of shares to be issued if the stock price closes at $ 11 compared to if it closes at $ 20?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 278%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 2155.5555555555554%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is numerically incorrect. The expected answer is 278%, while the agent provided an answer of 2155.56%. This is a significant discrepancy, indicating a clear failure to correctly calculate or retrieve the required information.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user has not provided the agent's thinking process. The evaluation requires an assessment of the reasoning, clarity, and logical steps. Without the thinking process, it is impossible to evaluate how the agent arrived at its answer. The final answer provided (2155.56%) is also highly suspect and seems mathematically incorrect for a standard interpretation of the question. For a fixed amount of capital to be raised, the percentage difference in shares issued between a $20 price and an $11 price would be approximately 81.8% more shares at the lower price. The agent's answer is off by a significant margin, and with no reasoning provided, the submission is considered incorrect and unevaluable.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[4/20] QUESTION:\n",
      "what was the percentage decrease from 2007 for 2009 for the cmg balance?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.47%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, which is incorrect. The expected answer is a specific numerical value (1.47%), indicating a percentage decrease. The agent completely failed to answer the user's question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and failed to answer the question, responding with 'N/A'. A correct response would involve identifying the CMG balance for 2007 and 2009 and then calculating the percentage decrease. The agent's response shows a complete failure to engage with the query.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[5/20] QUESTION:\n",
      "what was the percentage change in cash from operations between 2008 and 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 35%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, which is incorrect. The expected answer is '35%'. The agent failed to provide any numerical value or calculation for the percentage change.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent failed to provide any thinking process or a valid answer. The response 'N/A' indicates a complete inability to address the query. There is no evidence of identifying relevant numbers, applying a formula, or any form of logical breakdown.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[6/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: Code executed successfully (no output)\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 121.7\n",
      "new_value = 155.8\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent did not provide an answer. It only returned a status message indicating that its code executed without producing any output. This is not a valid or useful response to a user's query.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The provided context is empty. There is no question, no thinking process from the agent, and no final answer. Therefore, it is impossible to evaluate the agent's performance on any of the specified criteria (clarity, correctness, logical breakdown, mathematical reasoning). The submission is completely blank.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly implements the standard formula for calculating the percentage change between two values. The variable names (`old_value`, `new_value`, `result`) are clear, descriptive, and appropriate for the calculation being performed.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[7/20] QUESTION:\n",
      "what was the percentage change in earnings per share from 2005 to 2006?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 22%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 22.349570200573048%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 3.49\n",
      "new_value = 4.27\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided a more precise and accurate answer than the expected answer. The expected answer of 22% is a rounded version of the agent's calculated 22.349...%. The agent's response is factually correct and exceeds the precision of the expected answer.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent did not provide any thinking process. The evaluation requires an assessment of the clarity of thinking, identification of relevant numbers and formulas, a logical step-by-step breakdown, and sound mathematical reasoning. Without the agent's thought process, it is impossible to evaluate any of these criteria. The response only contains a final numerical answer, which cannot be verified or assessed for its reasoning quality.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and will run without errors. It correctly implements the standard formula for percentage change: ((new_value - old_value) / old_value) * 100. The variable names 'old_value', 'new_value', and 'result' are clear and appropriate for the calculation being performed. The output correctly reflects the result of the calculation.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[8/20] QUESTION:\n",
      "how much did the quarterly dividend yield change from 2010 to 2012 for applied materials?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: the dividend yield increased 0.04% from 2010 to 2012\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent returned 'N/A', indicating it could not answer the question. This is a complete failure to address the user's query, whereas a correct answer with a specific numerical value was expected.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no answer and no reasoning or thought process. It completely failed to address the user's question.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[9/20] QUESTION:\n",
      "what was the percent of the increase in the operating income from 2010 to 2011\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 10.1%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 10.02%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer of 10.02% is extremely close to the expected answer of 10.1%. The minor discrepancy is likely due to rounding differences. The agent's response is more precise and demonstrates a correct understanding and calculation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The model only provides the final answer without any supporting information or reasoning. It fails to show the key figures (operating income for 2010 and 2011) and does not outline the calculation (the percentage change formula) used to arrive at the answer. Therefore, it is impossible to verify the accuracy of the result or evaluate the quality of the financial reasoning.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[10/20] QUESTION:\n",
      "what percent of the net change in revenue between 2007 and 2008 was due to volume/weather?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 76.5%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' instead of the correct numerical answer. The expected answer was 76.5%. The agent failed to answer the question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and no answer, simply stating 'N/A'. This is a complete failure to address the user's question. There is no reasoning to evaluate, so the performance is rated as 'wrong'.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[11/20] QUESTION:\n",
      "what is the percentage change in gross unpaid losses from 2008 to 2009?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.63%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent failed to answer the question, responding with 'N/A' instead of the expected numerical value. This indicates a complete failure to retrieve or calculate the required information.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent did not provide any thinking process or an answer to the question. The response 'N/A' indicates a complete failure to address the query. There is no reasoning to evaluate.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[12/20] QUESTION:\n",
      "what was the net tax expense for the 3 years ended 2005 related to the change in financial derivatives ( in millions? )\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: -8.2\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' as the answer, indicating it could not find the information. However, the expected answer is a specific numerical value, -8.2. This means the agent failed to extract the correct information from the source material.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and simply outputted 'N/A' as the answer. This indicates a complete failure to address the user's question. There is no reasoning, no identification of relevant data, and no attempt to solve the problem.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[13/20] QUESTION:\n",
      "what is the percentage change in total operating expenses in 2012?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 1.4%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent provided 'N/A' which indicates it could not find or calculate the answer. The expected answer is a specific numerical value (1.4%), so the agent completely failed to answer the question.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process or answer. The response is 'N/A', indicating a complete failure to address the query. There is no reasoning to evaluate.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[14/20] QUESTION:\n",
      "how much has cash equivalents and marketable securities decreased from 2014 to 2016?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 33.9% decrease\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent failed to answer the question, responding with 'N/A'. The question requires a specific calculation of the percentage decrease for a financial metric between two given years. The agent did not provide any calculation or numerical answer, thus it is completely incorrect.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no thinking process and no answer, simply returning 'N/A'. This represents a complete failure to address the user's question. There is no reasoning to evaluate.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[15/20] QUESTION:\n",
      "what was the percentage increase in the property and equipment net from 2004 to 2005\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 52.2%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 52.221033573272294%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 2273356\n",
      "new_value = 3460526\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is correct. It is a more precise version of the expected answer. When the agent's answer (52.2210...) is rounded to one decimal place, it matches the expected answer (52.2%) perfectly.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The model's thinking process is not provided. The output only contains a final numerical answer without any explanation, breakdown of steps, or identification of the source numbers (e.g., Property and Equipment Net for 2004 and 2005). It is impossible to evaluate the clarity, logic, or mathematical soundness of the reasoning when no reasoning is present.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code correctly implements the formula for percentage increase. The variables `old_value` and `new_value` are appropriately named and assigned. The calculation `((new_value - old_value) / old_value) * 100` is the correct way to determine the percentage change. The code is clean, efficient, and directly answers the user's question.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[16/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 42.90942360475754%\n",
      "\n",
      "ðŸ’» CODE:\n",
      "old_value = 218.6\n",
      "new_value = 312.4\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      5/5\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The evaluation context is incomplete. The 'Question' and 'Expected Answer' fields are empty. Without the question and the correct answer, it is impossible to assess the agent's provided numerical answer.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user did not provide the question or the agent's thinking process. Only a numerical answer was given. It is impossible to evaluate the quality of financial reasoning without the context of the problem and the steps taken by the agent to arrive at the solution. The submission is incomplete and therefore cannot be judged.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "The code is syntactically correct and runs without errors. It correctly implements the standard formula for percentage change. The variable names `old_value`, `new_value`, and `result` are clear and appropriate. The final output is accurate based on the given inputs.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[17/20] QUESTION:\n",
      "what is the net income margin for 2018?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 3.3%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is 'N/A' while the expected answer is '3.3%'. The agent failed to provide the correct numerical value for the net income margin in 2018.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided no reasoning or answer to the question. The thinking process is empty, and the final answer is 'N/A'. It failed to identify the necessary components to answer the question, such as the formula for net income margin (Net Income / Revenue) and the relevant financial figures for 2018. There is a complete absence of any logical or mathematical steps.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[18/20] QUESTION:\n",
      "what was the total intrinsic value of options exercised during 2007 , 2006 and 2005 in millions?\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 194\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 92\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    1/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer of 92 is incorrect. The expected answer is 194. The value provided by the agent is less than half of the correct value, indicating a significant error in either data retrieval or calculation.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided a numerical answer without any supporting thinking process, calculations, or reference to data. The core task is to evaluate the reasoning, and since no reasoning was provided, the response is fundamentally flawed and unverifiable. It is impossible to assess clarity, logic, or mathematical soundness without the underlying steps.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[19/20] QUESTION:\n",
      "\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: \n",
      "\n",
      "ðŸ¤– AGENT ANSWER: $2,040 million\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    2/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The evaluation cannot be performed because the core context is missing. The 'Question' and 'Expected Answer' fields are empty. Without knowing what was asked and what the correct answer should be, it is impossible to assess the correctness, relevance, or completeness of the agent's provided answer.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The user did not provide the question or the agent's thinking process. Without this crucial information, it is impossible to evaluate the clarity, correctness, logic, or mathematical soundness of the agent's reasoning. The answer of '$2,040 million' cannot be verified or assessed in any meaningful way.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[20/20] QUESTION:\n",
      "what was the percentage total return for delphi automotive plc for the three years ended december 31 2013?\\\\n\n",
      "\n",
      "ðŸ“Œ EXPECTED ANSWER: 185.81%\n",
      "\n",
      "ðŸ¤– AGENT ANSWER: 185.81%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ“Š LLM-AS-JUDGE SCORES:\n",
      "  Answer Score:    5/5\n",
      "  Reasoning Score: 1/5\n",
      "  Code Score:      N/A\n",
      "\n",
      "ðŸ“ ANSWER EVALUATION:\n",
      "The agent's answer is a perfect match to the expected answer, indicating accurate retrieval of the requested financial data.\n",
      "\n",
      "ðŸ“ REASONING EVALUATION:\n",
      "The agent provided only a final answer without any of the underlying thinking process, calculations, or assumptions. It is impossible to evaluate the reasoning quality based on the provided output. The core task is to judge the agent's reasoning, and since none was provided, the response fails completely. Additionally, the final answer of 185.81% appears to be incorrect. Delphi Automotive PLC's IPO was in November 2011, so a three-year return is ambiguous. Calculating the return from the IPO date to Dec 31, 2013, yields a total return of approximately 244%. Calculating from the start of 2012 to the end of 2013 yields a return of approximately 199%. The agent's answer does not align with standard calculation methods.\n",
      "\n",
      "ðŸ“ CODE EVALUATION:\n",
      "No code/tool calling in this response\n",
      "\n",
      "================================================================================\n",
      "âœ“ LLM-as-Judge Evaluation Complete (Tuned Model)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š TUNED MODEL AGGREGATE METRICS:\n",
      "  Average Answer Score:    1.85/5\n",
      "  Average Reasoning Score: 1.00/5\n",
      "  Average Code Score:      5.00/5 (4 samples with code)\n",
      "\n",
      "ðŸ“ˆ COMPARISON WITH BASELINE:\n",
      "  Answer Score:    1.80 â†’ 1.85 (Î” +0.05)\n",
      "  Reasoning Score: 1.00 â†’ 1.00 (Î” +0.00)\n",
      "  Code Score:      5.00 â†’ 5.00 (Î” +0.00)\n",
      "\n",
      "  Run ID: 59128eba50174633bc6da436e9f4b074\n",
      "  View detailed results in MLflow UI at: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN LLM-AS-JUDGE EVALUATION (TUNED MODEL)\n",
    "# ============================================================================\n",
    "# Using MLflow's make_judge API for template-based LLM evaluation\n",
    "# Each response is evaluated and assessments are logged per-trace\n",
    "\n",
    "if config.GEMINI_API_KEY:\n",
    "    print(\"=\"*80)\n",
    "    print(\"LLM-AS-JUDGE EVALUATION (Tuned Model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Using MLflow make_judge with model: gemini/{config.GEMINI_MODEL}\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"Tuned_Model_LLM_Judge\") as run:\n",
    "        print(f\"\\nEvaluating {len(evaluation_sample)} tuned model responses with LLM-as-Judge...\")\n",
    "        \n",
    "        # Store evaluation results\n",
    "        tuned_judge_results = []\n",
    "        \n",
    "        for idx, row in evaluation_sample.iterrows():\n",
    "            question = row['question']\n",
    "            ground_truth = row['answer']\n",
    "            agent_output = row.get('tuned_agent_answer', '')\n",
    "            thinking = row.get('tuned_thinking', '')\n",
    "            code = row.get('tuned_code', '')\n",
    "            full_output = row.get('tuned_full_output', '')\n",
    "            \n",
    "            print(f\"\\n{'â”€'*80}\")\n",
    "            print(f\"[{idx+1}/{len(evaluation_sample)}] QUESTION:\")\n",
    "            print(f\"{question}\")\n",
    "            print(f\"\\nðŸ“Œ EXPECTED ANSWER: {ground_truth}\")\n",
    "            print(f\"\\nðŸ¤– AGENT ANSWER: {agent_output}\")\n",
    "            \n",
    "            if thinking:\n",
    "                print(f\"\\nðŸ’­ THINKING:\")\n",
    "                print(thinking)\n",
    "            \n",
    "            if code:\n",
    "                print(f\"\\nðŸ’» CODE:\")\n",
    "                print(code)\n",
    "            \n",
    "            # Run LLM-as-Judge evaluation (pass thinking and code separately)\n",
    "            evaluation = evaluate_response(\n",
    "                agent_answer=agent_output,\n",
    "                ground_truth=ground_truth,\n",
    "                question=question,\n",
    "                thinking=thinking,\n",
    "                code=code\n",
    "            )\n",
    "            \n",
    "            # Store full results (no truncation)\n",
    "            tuned_judge_results.append({\n",
    "                \"question\": question,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"agent_output\": agent_output,\n",
    "                \"thinking\": thinking,\n",
    "                \"code\": code,\n",
    "                \"full_output\": full_output,\n",
    "                \"answer_score\": evaluation[\"answer_score\"],\n",
    "                \"reasoning_score\": evaluation[\"reasoning_score\"],\n",
    "                \"code_score\": evaluation[\"code_score\"],\n",
    "                \"answer_explanation\": evaluation[\"answer_explanation\"],\n",
    "                \"reasoning_explanation\": evaluation[\"reasoning_explanation\"],\n",
    "                \"code_explanation\": evaluation[\"code_explanation\"],\n",
    "            })\n",
    "            \n",
    "            # Print full evaluation results (no truncation)\n",
    "            code_score_display = evaluation['code_score'] if evaluation['code_score'] != \"N/A\" else \"N/A\"\n",
    "            print(f\"\\n{'â”€'*40}\")\n",
    "            print(f\"ðŸ“Š LLM-AS-JUDGE SCORES:\")\n",
    "            print(f\"  Answer Score:    {evaluation['answer_score']}/5\")\n",
    "            print(f\"  Reasoning Score: {evaluation['reasoning_score']}/5\")\n",
    "            print(f\"  Code Score:      {code_score_display}{'/5' if code_score_display != 'N/A' else ''}\")\n",
    "            \n",
    "            print(f\"\\nðŸ“ ANSWER EVALUATION:\")\n",
    "            print(evaluation['answer_explanation'])\n",
    "            \n",
    "            print(f\"\\nðŸ“ REASONING EVALUATION:\")\n",
    "            print(evaluation['reasoning_explanation'])\n",
    "            \n",
    "            print(f\"\\nðŸ“ CODE EVALUATION:\")\n",
    "            print(evaluation['code_explanation'])\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        tuned_judge_df = pd.DataFrame(tuned_judge_results)\n",
    "        \n",
    "        # Calculate aggregate metrics (handle N/A for code scores)\n",
    "        tuned_avg_answer = tuned_judge_df[\"answer_score\"].mean()\n",
    "        tuned_avg_reasoning = tuned_judge_df[\"reasoning_score\"].mean()\n",
    "        \n",
    "        # Filter out N/A values for code score average\n",
    "        tuned_code_scores_numeric = [s for s in tuned_judge_df[\"code_score\"] if s != \"N/A\"]\n",
    "        tuned_avg_code = sum(tuned_code_scores_numeric) / len(tuned_code_scores_numeric) if tuned_code_scores_numeric else None\n",
    "        \n",
    "        # Add scores to evaluation_sample for comparison\n",
    "        evaluation_sample['tuned_answer_score'] = tuned_judge_df[\"answer_score\"].tolist()\n",
    "        evaluation_sample['tuned_reasoning_score'] = tuned_judge_df[\"reasoning_score\"].tolist()\n",
    "        evaluation_sample['tuned_code_score'] = tuned_judge_df[\"code_score\"].tolist()\n",
    "        \n",
    "        # Log aggregate metrics\n",
    "        log_metrics = {\n",
    "            \"tuned_avg_answer_score\": tuned_avg_answer,\n",
    "            \"tuned_avg_reasoning_score\": tuned_avg_reasoning,\n",
    "        }\n",
    "        if tuned_avg_code is not None:\n",
    "            log_metrics[\"tuned_avg_code_score\"] = tuned_avg_code\n",
    "        mlflow.log_metrics(log_metrics)\n",
    "        \n",
    "        # Log comparison table\n",
    "        mlflow.log_table(\n",
    "            data=tuned_judge_df,\n",
    "            artifact_file=\"tuned_llm_judge_results.json\"\n",
    "        )\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"âœ“ LLM-as-Judge Evaluation Complete (Tuned Model)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"\\nðŸ“Š TUNED MODEL AGGREGATE METRICS:\")\n",
    "        print(f\"  Average Answer Score:    {tuned_avg_answer:.2f}/5\")\n",
    "        print(f\"  Average Reasoning Score: {tuned_avg_reasoning:.2f}/5\")\n",
    "        if tuned_avg_code is not None:\n",
    "            print(f\"  Average Code Score:      {tuned_avg_code:.2f}/5 ({len(tuned_code_scores_numeric)} samples with code)\")\n",
    "        else:\n",
    "            print(f\"  Average Code Score:      N/A (no samples with tool calling)\")\n",
    "        \n",
    "        # Compare with baseline if available\n",
    "        if 'base_answer_score' in evaluation_sample.columns:\n",
    "            print(\"\\nðŸ“ˆ COMPARISON WITH BASELINE:\")\n",
    "            print(f\"  Answer Score:    {base_avg_answer:.2f} â†’ {tuned_avg_answer:.2f} (Î” {tuned_avg_answer - base_avg_answer:+.2f})\")\n",
    "            print(f\"  Reasoning Score: {base_avg_reasoning:.2f} â†’ {tuned_avg_reasoning:.2f} (Î” {tuned_avg_reasoning - base_avg_reasoning:+.2f})\")\n",
    "            if base_avg_code is not None and tuned_avg_code is not None:\n",
    "                print(f\"  Code Score:      {base_avg_code:.2f} â†’ {tuned_avg_code:.2f} (Î” {tuned_avg_code - base_avg_code:+.2f})\")\n",
    "            elif tuned_avg_code is not None:\n",
    "                print(f\"  Code Score:      N/A â†’ {tuned_avg_code:.2f}\")\n",
    "            else:\n",
    "                print(f\"  Code Score:      N/A (no samples with tool calling)\")\n",
    "        \n",
    "        print(f\"\\n  Run ID: {run.info.run_id}\")\n",
    "        print(f\"  View detailed results in MLflow UI at: http://localhost:5000\")\n",
    "            \n",
    "else:\n",
    "    print(\"âš  Skipping LLM-as-Judge evaluation (GEMINI_API_KEY not set)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Calculate Accuracy Metrics\n",
    "\n",
    "We compute accuracy metrics comparing predicted answers to ground truth for both base and tuned models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy:\n",
      "  exact_match: 5.0%\n",
      "  numeric_match: 10.0%\n",
      "  partial_match: 20.0%\n",
      "\n",
      "Tuned Model Accuracy:\n",
      "  exact_match: 5.0%\n",
      "  numeric_match: 15.0%\n",
      "  partial_match: 20.0%\n",
      "\n",
      "============================================================\n",
      "IMPROVEMENT (Tuned vs Base)\n",
      "============================================================\n",
      "  exact_match: â†’ 0.0pp (5.0% â†’ 5.0%)\n",
      "  numeric_match: â†‘ 5.0pp (10.0% â†’ 15.0%)\n",
      "  partial_match: â†’ 0.0pp (20.0% â†’ 20.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CALCULATE ACCURACY METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_accuracy(predictions: list, ground_truths: list) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate accuracy metrics comparing predictions to ground truth.\n",
    "    \n",
    "    Returns dict with:\n",
    "    - exact_match: Percentage of exact string matches\n",
    "    - numeric_match: Percentage of matching numeric values (within 1%)\n",
    "    - partial_match: Percentage of partial matches\n",
    "    \"\"\"\n",
    "    exact = 0\n",
    "    numeric = 0\n",
    "    partial = 0\n",
    "    total = len(predictions)\n",
    "    \n",
    "    for pred, truth in zip(predictions, ground_truths):\n",
    "        pred_str = str(pred).strip().lower()\n",
    "        truth_str = str(truth).strip().lower()\n",
    "        \n",
    "        # Exact match\n",
    "        if pred_str == truth_str:\n",
    "            exact += 1\n",
    "            numeric += 1\n",
    "            partial += 1\n",
    "            continue\n",
    "        \n",
    "        # Partial match\n",
    "        if truth_str in pred_str or pred_str in truth_str:\n",
    "            partial += 1\n",
    "        \n",
    "        # Numeric match\n",
    "        try:\n",
    "            pred_nums = re.findall(r'-?\\d+\\.?\\d*', pred_str)\n",
    "            truth_nums = re.findall(r'-?\\d+\\.?\\d*', truth_str)\n",
    "            \n",
    "            if pred_nums and truth_nums:\n",
    "                pred_val = float(pred_nums[-1])\n",
    "                truth_val = float(truth_nums[-1])\n",
    "                \n",
    "                if abs(pred_val - truth_val) / (abs(truth_val) + 1e-10) < 0.01:\n",
    "                    numeric += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return {\n",
    "        \"exact_match\": exact / total * 100,\n",
    "        \"numeric_match\": numeric / total * 100,\n",
    "        \"partial_match\": partial / total * 100,\n",
    "    }\n",
    "\n",
    "# Calculate metrics for base model\n",
    "if 'base_agent_answer' in evaluation_sample.columns:\n",
    "    base_metrics = calculate_accuracy(\n",
    "        evaluation_sample['base_agent_answer'].tolist(),\n",
    "        evaluation_sample['answer'].tolist()\n",
    "    )\n",
    "    print(\"Base Model Accuracy:\")\n",
    "    for metric, value in base_metrics.items():\n",
    "        print(f\"  {metric}: {value:.1f}%\")\n",
    "else:\n",
    "    base_metrics = {\"exact_match\": 0, \"numeric_match\": 0, \"partial_match\": 0}\n",
    "\n",
    "# Calculate metrics for tuned model\n",
    "if 'tuned_agent_answer' in evaluation_sample.columns:\n",
    "    tuned_metrics = calculate_accuracy(\n",
    "        evaluation_sample['tuned_agent_answer'].tolist(),\n",
    "        evaluation_sample['answer'].tolist()\n",
    "    )\n",
    "    print(\"\\nTuned Model Accuracy:\")\n",
    "    for metric, value in tuned_metrics.items():\n",
    "        print(f\"  {metric}: {value:.1f}%\")\n",
    "else:\n",
    "    tuned_metrics = {\"exact_match\": 0, \"numeric_match\": 0, \"partial_match\": 0}\n",
    "\n",
    "# Calculate improvement\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVEMENT (Tuned vs Base)\")\n",
    "print(\"=\"*60)\n",
    "for metric in [\"exact_match\", \"numeric_match\", \"partial_match\"]:\n",
    "    base_val = base_metrics.get(metric, 0)\n",
    "    tuned_val = tuned_metrics.get(metric, 0)\n",
    "    diff = tuned_val - base_val\n",
    "    arrow = \"â†‘\" if diff > 0 else \"â†“\" if diff < 0 else \"â†’\"\n",
    "    print(f\"  {metric}: {arrow} {abs(diff):.1f}pp ({base_val:.1f}% â†’ {tuned_val:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Visualize Results\n",
    "\n",
    "Generate comparison visualizations showing the improvement from base to tuned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Figure saved to: /workspace/outputs/financial_agent_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy Comparison Bar Chart\n",
    "ax1 = axes[0]\n",
    "metrics = ['Exact Match', 'Numeric Match', 'Partial Match']\n",
    "base_values = [base_metrics['exact_match'], base_metrics['numeric_match'], base_metrics['partial_match']]\n",
    "tuned_values = [tuned_metrics['exact_match'], tuned_metrics['numeric_match'], tuned_metrics['partial_match']]\n",
    "\n",
    "x = range(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar([i - width/2 for i in x], base_values, width, label='Base Model', color='#ff6b6b', alpha=0.8)\n",
    "bars2 = ax1.bar([i + width/2 for i in x], tuned_values, width, label='Tuned Model', color='#4ecdc4', alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Improvement Summary\n",
    "ax2 = axes[1]\n",
    "improvements = [tuned_metrics[m.lower().replace(' ', '_')] - base_metrics[m.lower().replace(' ', '_')] \n",
    "                for m in ['exact_match', 'numeric_match', 'partial_match']]\n",
    "\n",
    "colors = ['#2ecc71' if imp > 0 else '#e74c3c' for imp in improvements]\n",
    "bars3 = ax2.bar(metrics, improvements, color=colors, alpha=0.8)\n",
    "\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_ylabel('Improvement (pp)', fontsize=12)\n",
    "ax2.set_title('Fine-Tuning Improvement', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for bar, imp in zip(bars3, improvements):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{imp:+.1f}pp',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3 if height >= 0 else -15),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom' if height >= 0 else 'top', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "output_path = PROJECT_ROOT / \"outputs\" / \"financial_agent_comparison.png\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"âœ“ Figure saved to: {output_path}\")\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"Comparison_Visualization\"):\n",
    "    mlflow.log_artifact(str(output_path))\n",
    "    mlflow.log_metrics({\n",
    "        \"base_exact_match\": base_metrics['exact_match'],\n",
    "        \"base_numeric_match\": base_metrics['numeric_match'],\n",
    "        \"tuned_exact_match\": tuned_metrics['exact_match'],\n",
    "        \"tuned_numeric_match\": tuned_metrics['numeric_match'],\n",
    "        \"improvement_exact\": tuned_metrics['exact_match'] - base_metrics['exact_match'],\n",
    "        \"improvement_numeric\": tuned_metrics['numeric_match'] - base_metrics['numeric_match'],\n",
    "    })\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Side-by-Side Comparison\n",
    "\n",
    "Display detailed side-by-side comparison of base vs tuned model responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SIDE-BY-SIDE COMPARISON: Base vs Tuned Model\n",
      "================================================================================\n",
      "Showing all 20 evaluation examples\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 1/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent change in net expense in interest and penalties between 2008 and 2009?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: -36%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage reduction in the segment 2019s backlog from 2006 to 2007\n",
      "\n",
      "ðŸŽ¯ Ground Truth: -18.8%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 18.75%\n",
      "\n",
      "Code:\n",
      "old_backlog = 3200000000\n",
      "new_backlog = 2600000000\n",
      "result = ((old_backlog - new_backlog) / old_backlog) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 4/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 3/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage difference in the number of shares to be issued if the stock price closes at $ 11 compared to if it closes at $ 20?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 278%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 2155.5555555555554%\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 4/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage decrease from 2007 for 2009 for the cmg balance?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 1.47%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 5/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in cash from operations between 2008 and 2009?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 35%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 6/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "ðŸŽ¯ Ground Truth: \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 9.333333333333341%\n",
      "\n",
      "Code:\n",
      "old_value = 142.5  # 2006 total interest costs\n",
      "new_value = 155.8  # 2007 total interest costs\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 2/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: Code executed successfully (no output)\n",
      "\n",
      "Code:\n",
      "old_value = 121.7\n",
      "new_value = 155.8\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 7/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage change in earnings per share from 2005 to 2006?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 22%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 22.349570200573048%\n",
      "\n",
      "Code:\n",
      "old_eps = 3.49\n",
      "new_eps = 4.27\n",
      "result = ((new_eps - old_eps) / old_eps) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 22.349570200573048%\n",
      "\n",
      "Code:\n",
      "old_value = 3.49\n",
      "new_value = 4.27\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 8/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much did the quarterly dividend yield change from 2010 to 2012 for applied materials?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: the dividend yield increased 0.04% from 2010 to 2012\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 9/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percent of the increase in the operating income from 2010 to 2011\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 10.1%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 10.02%\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 10/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what percent of the net change in revenue between 2007 and 2008 was due to volume/weather?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 76.5%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 11/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in gross unpaid losses from 2008 to 2009?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 1.63%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 0.1725%\n",
      "\n",
      "Code:\n",
      "old_value = 37112000\n",
      "new_value = 37176000\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result:.4f}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 12/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the net tax expense for the 3 years ended 2005 related to the change in financial derivatives ( in millions? )\n",
      "\n",
      "ðŸŽ¯ Ground Truth: -8.2\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 13/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the percentage change in total operating expenses in 2012?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 1.4%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 14/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "how much has cash equivalents and marketable securities decreased from 2014 to 2016?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 33.9% decrease\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 15/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage increase in the property and equipment net from 2004 to 2005\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 52.2%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 52.221033573272294%\n",
      "\n",
      "Code:\n",
      "# Extract property and equipment net for 2004 and 2005\n",
      "prop_eq_2004 = 2273356\n",
      "prop_eq_2005 = 3460526\n",
      "\n",
      "# Calculate the percentage increase\n",
      "percentage_increase = ((prop_eq_2005 - prop_eq_2004) / prop_eq_2004) * 100\n",
      "print(f\"{percentage_increase}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 52.221033573272294%\n",
      "\n",
      "Code:\n",
      "old_value = 2273356\n",
      "new_value = 3460526\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 16/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "ðŸŽ¯ Ground Truth: \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 9.63\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 42.90942360475754%\n",
      "\n",
      "Code:\n",
      "old_value = 218.6\n",
      "new_value = 312.4\n",
      "result = ((new_value - old_value) / old_value) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 17/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what is the net income margin for 2018?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 3.3%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: N/A\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 18/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the total intrinsic value of options exercised during 2007 , 2006 and 2005 in millions?\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 194\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 31\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 92\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 19/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "\n",
      "\n",
      "ðŸŽ¯ Ground Truth: \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 40%\n",
      "\n",
      "ðŸ“Š Scores - Answer: 1/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: $2,040 million\n",
      "\n",
      "ðŸ“Š Scores - Answer: 2/5, Reasoning: 1/5, Code: N/A\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 20/20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Question:\n",
      "what was the percentage total return for delphi automotive plc for the three years ended december 31 2013?\\\\n\n",
      "\n",
      "ðŸŽ¯ Ground Truth: 185.81%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BASE MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 185.81%\n",
      "\n",
      "Code:\n",
      "initial_investment = 100.00\n",
      "final_value = 285.81\n",
      "result = ((final_value - initial_investment) / initial_investment) * 100\n",
      "print(f\"{result}%\")\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: 5/5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TUNED MODEL\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Answer: 185.81%\n",
      "\n",
      "ðŸ“Š Scores - Answer: 5/5, Reasoning: 1/5, Code: N/A\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SIDE-BY-SIDE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SIDE-BY-SIDE COMPARISON: Base vs Tuned Model\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Showing all {len(evaluation_sample)} evaluation examples\")\n",
    "\n",
    "for idx in range(len(evaluation_sample)):\n",
    "    row = evaluation_sample.iloc[idx]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EXAMPLE {idx + 1}/{len(evaluation_sample)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Full question (no truncation)\n",
    "    print(f\"\\nðŸ“‹ Question:\\n{row['question']}\")\n",
    "    print(f\"\\nðŸŽ¯ Ground Truth: {row['answer']}\")\n",
    "    \n",
    "    print(f\"\\n{'â”€'*40}\")\n",
    "    print(\"BASE MODEL\")\n",
    "    print(f\"{'â”€'*40}\")\n",
    "    print(f\"Answer: {row.get('base_agent_answer', 'N/A')}\")\n",
    "    \n",
    "    # Full thinking (no truncation)\n",
    "    base_thinking = row.get('base_thinking', '')\n",
    "    if base_thinking:\n",
    "        print(f\"\\nReasoning:\\n{base_thinking}\")\n",
    "    \n",
    "    # Full code (no truncation)\n",
    "    base_code = row.get('base_code', '')\n",
    "    if base_code:\n",
    "        print(f\"\\nCode:\\n{base_code}\")\n",
    "    \n",
    "    # Show score if available\n",
    "    if 'base_answer_score' in row:\n",
    "        base_code_display = row['base_code_score'] if row['base_code_score'] != \"N/A\" else \"N/A\"\n",
    "        print(f\"\\nðŸ“Š Scores - Answer: {row['base_answer_score']}/5, \"\n",
    "              f\"Reasoning: {row['base_reasoning_score']}/5, \"\n",
    "              f\"Code: {base_code_display}{'/5' if base_code_display != 'N/A' else ''}\")\n",
    "    \n",
    "    print(f\"\\n{'â”€'*40}\")\n",
    "    print(\"TUNED MODEL\")\n",
    "    print(f\"{'â”€'*40}\")\n",
    "    print(f\"Answer: {row.get('tuned_agent_answer', 'N/A')}\")\n",
    "    \n",
    "    # Full thinking (no truncation)\n",
    "    tuned_thinking = row.get('tuned_thinking', '')\n",
    "    if tuned_thinking:\n",
    "        print(f\"\\nReasoning:\\n{tuned_thinking}\")\n",
    "    \n",
    "    # Full code (no truncation)\n",
    "    tuned_code = row.get('tuned_code', '')\n",
    "    if tuned_code:\n",
    "        print(f\"\\nCode:\\n{tuned_code}\")\n",
    "    \n",
    "    # Show score if available\n",
    "    if 'tuned_answer_score' in row:\n",
    "        tuned_code_display = row['tuned_code_score'] if row['tuned_code_score'] != \"N/A\" else \"N/A\"\n",
    "        print(f\"\\nðŸ“Š Scores - Answer: {row['tuned_answer_score']}/5, \"\n",
    "              f\"Reasoning: {row['tuned_reasoning_score']}/5, \"\n",
    "              f\"Code: {tuned_code_display}{'/5' if tuned_code_display != 'N/A' else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary & Conclusions\n",
    "\n",
    "## What We Built\n",
    "\n",
    "This notebook demonstrated a complete workflow for building a **Financial Reasoning Agent** with:\n",
    "\n",
    "### 1. **DeepSeek-R1-Distill-Qwen-7B Base Model**\n",
    "- Distilled from DeepSeek's reasoning-focused R1 model\n",
    "- Naturally produces chain-of-thought reasoning traces\n",
    "- Strong mathematical and instruction-following capabilities\n",
    "\n",
    "### 2. **\"Thinking\" Architecture**\n",
    "- Model generates explicit reasoning traces in `<think>` tags\n",
    "- Clear separation of thinking process from final answer\n",
    "- Enables debugging and understanding of model behavior\n",
    "\n",
    "### 3. **Tool-Augmented Computation**\n",
    "- Python REPL tool for precise mathematical calculations\n",
    "- Eliminates arithmetic errors common in LLM responses\n",
    "- Agent learns when and how to use tools effectively\n",
    "\n",
    "### 4. **Process Reward Model (PRM) Training**\n",
    "- **Format reward (20%)**: Checks for proper `<think>` and `<answer>` tags\n",
    "- **Reasoning reward (30%)**: Rewards correct intermediate calculation steps\n",
    "- **Accuracy reward (50%)**: Uses normalized answer comparison for robustness\n",
    "- Training uses ground truth `steps` from ConvFinQA dataset\n",
    "\n",
    "### 5. **Comprehensive Evaluation**\n",
    "- Before/after comparison with same agent structure\n",
    "- LLM-as-Judge evaluation for reasoning quality\n",
    "- Full MLflow tracing for observability\n",
    "\n",
    "## MLflow Integration\n",
    "\n",
    "All experiment data is logged to MLflow:\n",
    "\n",
    "| Artifact | Description | View In |\n",
    "|----------|-------------|---------|\n",
    "| Agent Traces | Full execution paths for each question | Traces tab |\n",
    "| Baseline Results | Base model answers and metrics | Artifacts |\n",
    "| Tuned Results | Fine-tuned model answers and metrics | Artifacts |\n",
    "| LLM-Judge Scores | Reasoning, code, answer quality scores | Evaluation tab |\n",
    "| Comparison Table | Side-by-side results | Artifacts |\n",
    "| Visualization | Accuracy comparison chart | Artifacts |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Scale Training**: Increase `MAX_TRAINING_STEPS` for better results\n",
    "2. **Expand Dataset**: Add more financial reasoning examples\n",
    "3. **Advanced Tools**: Add financial APIs, data retrieval tools\n",
    "4. **Deploy Agent**: Export to production with MLflow Model Registry\n",
    "\n",
    "## References\n",
    "\n",
    "- [DeepSeek-R1 Technical Report](https://arxiv.org/abs/2401.02954) - The base reasoning model\n",
    "- [ConvFinQA Dataset (with steps)](https://huggingface.co/datasets/MehdiHosseiniMoghadam/ConvFinQA) - Financial QA with reasoning traces\n",
    "- [ConvFinQA Paper](https://arxiv.org/abs/2210.03849) - Original ConvFinQA research\n",
    "- [Unsloth GRPO Notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
    "- [MLflow Tracing Documentation](https://mlflow.org/docs/latest/llms/tracing/index.html)\n",
    "- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)\n",
    "- [Process Reward Models for LLM Reasoning](https://arxiv.org/abs/2305.20050) - PRM approach background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NOTEBOOK EXECUTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Final Summary:\n",
      "   - Base Model Exact Match: 5.0%\n",
      "   - Tuned Model Exact Match: 5.0%\n",
      "   - Improvement: +0.0pp\n",
      "\n",
      "ðŸ“ Artifacts saved:\n",
      "   - Visualization: /workspace/outputs/financial_agent_comparison.png\n",
      "   - MLflow runs: /workspace/notebooks/agents/mlruns\n",
      "\n",
      "ðŸ”— View results in MLflow UI:\n",
      "   mlflow ui --port 5000\n",
      "   Open: http://localhost:5000\n",
      "\n",
      "âœ… All phases completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL CLEANUP & SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NOTEBOOK EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š Final Summary:\")\n",
    "print(f\"   - Base Model Exact Match: {base_metrics.get('exact_match', 0):.1f}%\")\n",
    "print(f\"   - Tuned Model Exact Match: {tuned_metrics.get('exact_match', 0):.1f}%\")\n",
    "print(f\"   - Improvement: {tuned_metrics.get('exact_match', 0) - base_metrics.get('exact_match', 0):+.1f}pp\")\n",
    "\n",
    "print(\"\\nðŸ“ Artifacts saved:\")\n",
    "print(f\"   - Visualization: {PROJECT_ROOT / 'outputs' / 'financial_agent_comparison.png'}\")\n",
    "print(f\"   - MLflow runs: {MLRUNS_DIR}\")\n",
    "\n",
    "print(\"\\nðŸ”— View results in MLflow UI:\")\n",
    "print(\"   mlflow ui --port 5000\")\n",
    "print(\"   Open: http://localhost:5000\")\n",
    "\n",
    "print(\"\\nâœ… All phases completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
